{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"reference/","title":"Reference","text":""},{"location":"reference/#code.bpf.BestParameterFinder","title":"<code>BestParameterFinder</code>","text":"Source code in <code>code/bpf.py</code> <pre><code>class BestParameterFinder():\n\tdef nInfUniform(self, voltages):\n\t\tvoltages.sort()\n\t\tuniform = np.array([x / (len(voltages) - 1) for x in range(len(voltages))])\n\n\t\treturn np.linalg.norm(abs(voltages - uniform))\n\n\tdef nInfExp(self, voltages, base=10):\n\t\tglobal dist\n\n\t\tvoltages.sort()\n\n\t\tif (len(dist) != len(voltages)):\n\t\t\tdist = np.array([np.pow(base, (x / (len(voltages) - 1)) - 1) for x in range(len(voltages))])\n\n\t\treturn np.linalg.norm(abs(voltages - dist))\n\n\tdef median(self, voltages, value=0.5):\n\t\tvoltages.sort()\n\t\treturn abs(voltages[int(len(voltages) / 2)] - value)\n\n\tdef minimum(self, voltages, value=0.1):\n\t\tvoltages.sort()\n\t\treturn abs(voltages[0] - value)\n\n\tdef minWithStd(self, voltages, value=0.1):\n\t\tvoltages.sort()\n\t\treturn abs(voltages[0] - value) / np.std(voltages)\n\n\tdef __init__(self, metric=nInfExp):\n\t\tself.metric = metric\n\n\tdef calculateFor(self, landmarks, data, c, p_g, approx=False, approx_epsilon=None, approx_iters=None):\n\t\t# print(type(data))\n\n\t\tif (isinstance(data, create_data.Data)):\n\t\t\tmeanProblem = voltage.Problem(data)\n\t\t\tmeanProblem.timeStart()\n\t\t\tmeanProblem.setKernel(meanProblem.gaussiankernel)\n\t\t\t# print(\"before\")\n\t\t\tmeanProblem.setWeights(np.exp(c))\n\t\t\t# print(\"after\")\n\t\t\t# print(meanProblem)\n\n\t\tif (isinstance(data, kmeans.Partitions)):\n\t\t\tpartitions = data\n\n\t\t\tmeanProblem = voltage.Problem(partition.centers)\n\t\t\tmeanProblem.timeStart()\n\t\t\tmeanProblem.setKernel(meanProblem.gaussiankernel)\n\t\t\tmeanProblem.setPartitionWeights(partition, np.exp(c))\n\t\t\t# print(meanProblem)\n\n\t\t# print(meanProblem)\n\n\t\tmeanProblem.addUniversalGround(np.exp(p_g))\n\t\tmeanProblem.addLandmarks(landmarks)\n\n\t\tdiff1 = meanProblem.timeEnd()\n\t\t# print(diff1)\n\n\t\tif (approx):\n\t\t\tvoltages = np.array(voltage.Solver(meanProblem).approximate_voltages(approx_epsilon, approx_iters))\n\t\telse:\n\t\t\tvoltages = np.array(voltage.Solver(meanProblem).compute_voltages())\n\n\t\tdiff2 = meanProblem.timeEnd()\n\t\t# print(diff2)\n\n\t\tif (self.metric):\n\t\t\treturn self.metric(self, voltages)\n\t\telse:\n\t\t\treturn voltages, meanProblem\n\n\tdef bestParameterFinder(self, landmarks, data, minBound=-25, maxBound=-1, granularity=5, epsilon=1, approx=None):\n\t\t\"\"\"\n\t\tFinds the best parameters (C and P_G) for a solver based on voltage distribution minimization.\n\n\t\tThis function searches for optimal parameters `C` and `P_G` by iterating over exponent values in \n\t\ta specified range, computing voltages using a solver, and minimizing some metric\n\t\tbetween the voltage distribution and a uniform distribution.\n\n\t\tParameters:\n\t\t-----------\n\t\tkernel : object\n\t\t\tThe kernel function or object used to compute partition weights.\n\t\tlandmarks : list\n\t\t\tA list of landmark points used in the solver.\n\t\tdata : object\n\t\t\tEither a data object or a partition object containing centers used in the solver.\n\t\tnInfUniform : function (list of floating point values -&gt; floating point value)\n\t\t\tA function that is used to quantify if voltages are good or bad, the smaller the better\n\t\tminBound : int, optional (default=1e-5)\n\t\t\tThe minimum value to consider for `C` and `P_g` as 10^minBound.\n\t\tmaxBound : int, optional (default=1e5)\n\t\t\tThe maximum value to consider for `C` and `P_g` as 10^maxBound.\n\n\t\tReturns:\n\t\t--------\n\t\ttuple\n\t\t\tA tuple (bestC, bestG), where:\n\t\t\t- bestC (float): The optimized value for parameter C.\n\t\t\t- bestG (float): The optimized value for parameter P_g.\n\t\t\"\"\"\n\n\t\twindow_size = (maxBound - minBound) / 2\n\n\t\tbestc = minBound + window_size\n\t\tbestg = minBound + window_size\n\n\t\tval = float('inf')\n\n\t\twhile window_size &gt; epsilon:\n\t\t\tprint(window_size, np.exp(bestc), np.exp(bestg))\n\n\t\t\tcs = [bestc + x * window_size / granularity for x in range(-granularity + 1, granularity)]\n\t\t\tgs = [bestg + x * window_size / granularity for x in range(-granularity + 1, granularity)]\n\n\t\t\tfor c in cs:\n\t\t\t\tfor g in gs:\n\t\t\t\t\t# print(c, g)\n\t\t\t\t\ttry:\n\t\t\t\t\t\tif (approx == None):\n\t\t\t\t\t\t\ttempval = self.calculateFor(landmarks, data, c, g)\n\t\t\t\t\t\telse:\n\t\t\t\t\t\t\ttempval = self.calculateFor(landmarks, data, c, g, approx=True, approx_iters=approx)\t\t\t\t\t\t\t\n\n\t\t\t\t\t\t# print(tempval)\n\t\t\t\t\t\tif (val &gt; tempval):\n\t\t\t\t\t\t\t# print(c)\n\t\t\t\t\t\t\t# print(g)\n\t\t\t\t\t\t\t# print(tempval)\n\n\t\t\t\t\t\t\tbestc = c\n\t\t\t\t\t\t\tbestg = g\n\t\t\t\t\t\t\tval = tempval\n\t\t\t\t\texcept ValueError as e:\n\t\t\t\t\t\tpass\n\t\t\t\t\t\t# print(\"Invalid\")\n\n\n\t\t\twindow_size /= granularity\n\n\t\treturn np.exp(bestc), np.exp(bestg)\n\n\tdef visualizations(self, voltages, fileStarter):\n\t\tpoints = np.array(list(map(list, zip(*voltages))))\n\n\t\t# print(points.shape)\n\n\t\t# PCA\n\t\tpca = PCA(n_components=2)\n\t\tpoints_2d = pca.fit_transform(points)\n\n\t\t# print(points_2d.shape)\n\n\t\tplt.scatter(points_2d[:, 0], points_2d[:, 1], s=10)\n\t\tplt.xlabel(\"PCA Component 1\")\n\t\tplt.ylabel(\"PCA Component 2\")\n\t\tplt.title(\"PCA Projection of Solver Outputs\")\n\n\t\tplt.savefig(fileStarter + \"_PCA.png\")\n\t\tplt.clf()\n\n\t\t# MDS\n\t\tmds = MDS(n_components=2, random_state=42)\n\t\ttransformed_points = mds.fit_transform(points)\n\n\t\tplt.figure(figsize=(8, 6))\n\t\tplt.scatter(transformed_points[:, 0], transformed_points[:, 1], c='blue', edgecolors='black')\n\n\t\tplt.xlabel(\"MDS Dimension 1\")\n\t\tplt.ylabel(\"MDS Dimension 2\")\n\t\tplt.title(\"Multidimensional Scaling (MDS) to 2D\")\n\n\t\tplt.savefig(fileStarter + \"_MDS.png\")\n\t\tplt.clf()\n</code></pre>"},{"location":"reference/#code.bpf.BestParameterFinder.bestParameterFinder","title":"<code>bestParameterFinder(landmarks, data, minBound=-25, maxBound=-1, granularity=5, epsilon=1, approx=None)</code>","text":"<p>Finds the best parameters (C and P_G) for a solver based on voltage distribution minimization.</p> <p>This function searches for optimal parameters <code>C</code> and <code>P_G</code> by iterating over exponent values in  a specified range, computing voltages using a solver, and minimizing some metric between the voltage distribution and a uniform distribution.</p>"},{"location":"reference/#code.bpf.BestParameterFinder.bestParameterFinder--parameters","title":"Parameters:","text":"<p>kernel : object         The kernel function or object used to compute partition weights. landmarks : list         A list of landmark points used in the solver. data : object         Either a data object or a partition object containing centers used in the solver. nInfUniform : function (list of floating point values -&gt; floating point value)         A function that is used to quantify if voltages are good or bad, the smaller the better minBound : int, optional (default=1e-5)         The minimum value to consider for <code>C</code> and <code>P_g</code> as 10^minBound. maxBound : int, optional (default=1e5)         The maximum value to consider for <code>C</code> and <code>P_g</code> as 10^maxBound.</p>"},{"location":"reference/#code.bpf.BestParameterFinder.bestParameterFinder--returns","title":"Returns:","text":"<p>tuple         A tuple (bestC, bestG), where:         - bestC (float): The optimized value for parameter C.         - bestG (float): The optimized value for parameter P_g.</p> Source code in <code>code/bpf.py</code> <pre><code>def bestParameterFinder(self, landmarks, data, minBound=-25, maxBound=-1, granularity=5, epsilon=1, approx=None):\n\t\"\"\"\n\tFinds the best parameters (C and P_G) for a solver based on voltage distribution minimization.\n\n\tThis function searches for optimal parameters `C` and `P_G` by iterating over exponent values in \n\ta specified range, computing voltages using a solver, and minimizing some metric\n\tbetween the voltage distribution and a uniform distribution.\n\n\tParameters:\n\t-----------\n\tkernel : object\n\t\tThe kernel function or object used to compute partition weights.\n\tlandmarks : list\n\t\tA list of landmark points used in the solver.\n\tdata : object\n\t\tEither a data object or a partition object containing centers used in the solver.\n\tnInfUniform : function (list of floating point values -&gt; floating point value)\n\t\tA function that is used to quantify if voltages are good or bad, the smaller the better\n\tminBound : int, optional (default=1e-5)\n\t\tThe minimum value to consider for `C` and `P_g` as 10^minBound.\n\tmaxBound : int, optional (default=1e5)\n\t\tThe maximum value to consider for `C` and `P_g` as 10^maxBound.\n\n\tReturns:\n\t--------\n\ttuple\n\t\tA tuple (bestC, bestG), where:\n\t\t- bestC (float): The optimized value for parameter C.\n\t\t- bestG (float): The optimized value for parameter P_g.\n\t\"\"\"\n\n\twindow_size = (maxBound - minBound) / 2\n\n\tbestc = minBound + window_size\n\tbestg = minBound + window_size\n\n\tval = float('inf')\n\n\twhile window_size &gt; epsilon:\n\t\tprint(window_size, np.exp(bestc), np.exp(bestg))\n\n\t\tcs = [bestc + x * window_size / granularity for x in range(-granularity + 1, granularity)]\n\t\tgs = [bestg + x * window_size / granularity for x in range(-granularity + 1, granularity)]\n\n\t\tfor c in cs:\n\t\t\tfor g in gs:\n\t\t\t\t# print(c, g)\n\t\t\t\ttry:\n\t\t\t\t\tif (approx == None):\n\t\t\t\t\t\ttempval = self.calculateFor(landmarks, data, c, g)\n\t\t\t\t\telse:\n\t\t\t\t\t\ttempval = self.calculateFor(landmarks, data, c, g, approx=True, approx_iters=approx)\t\t\t\t\t\t\t\n\n\t\t\t\t\t# print(tempval)\n\t\t\t\t\tif (val &gt; tempval):\n\t\t\t\t\t\t# print(c)\n\t\t\t\t\t\t# print(g)\n\t\t\t\t\t\t# print(tempval)\n\n\t\t\t\t\t\tbestc = c\n\t\t\t\t\t\tbestg = g\n\t\t\t\t\t\tval = tempval\n\t\t\t\texcept ValueError as e:\n\t\t\t\t\tpass\n\t\t\t\t\t# print(\"Invalid\")\n\n\n\t\twindow_size /= granularity\n\n\treturn np.exp(bestc), np.exp(bestg)\n</code></pre>"},{"location":"reference/#code.create_data.Data","title":"<code>Data</code>","text":"<p>Class for handling and processing data sets.</p> Source code in <code>code/create_data.py</code> <pre><code>class Data():\n\t\"\"\"Class for handling and processing data sets.\"\"\"\n\tdef __init__(self, arg=None, stream=False):\n\t\tself.stream = stream\n\n\t\tif isinstance(arg, list):\n\t\t\tself.data = np.array(arg)\n\t\t\tself.length = len(self.data)\n\t\telif isinstance(arg, str):\n\t\t\tif (stream):\n\t\t\t\tself.data = self.stream_data_json(arg)\n\t\t\t\tself.length = next(self.data)\n\t\t\t\tself.i = 0\n\t\t\telse:\n\t\t\t\tself.load_data(arg)\n\t\t\t\tself.length = len(self.data)\n\n\t\t\tself.input_file = arg\n\t\telse:\n\t\t\tself.data = arg\n\t\t\tself.length = len(self.data)\n\n\t# Len can run on Data\n\tdef __len__(self):\n\t\treturn self.length\n\n\t# Data can be get indexed\n\tdef __getitem__(self, index):\n\t\tif (self.stream):\n\t\t\tif (index &lt; self.i):\n\t\t\t\tself.data = self.stream_data_json(self.input_file)\n\t\t\t\tnext(self.data)\n\t\t\t\tself.i = 0\n\n\t\t\twhile (self.i &lt;= index):\n\t\t\t\tvalue = next(self.data)\n\t\t\t\tself.i += 1\n\n\t\t\treturn value\n\t\telse:\n\t\t\treturn self.data[index]\n\n\t# \"\"\"\n\tdef __setitem__(self, index, value):\n\t\tself.data[index] = value\n\t# \"\"\"\n\n\t# Make Data able to be for looped\n\tdef __iter__(self):\n\t\tif (hasattr(self, 'input_file')):\n\t\t\tself.streaming_data = self.stream_data_json(self.input_file)\n\t\t\tnext(self.streaming_data)\n\t\telse:\n\t\t\tself.streaming_data = 0\n\n\t\treturn self\n\n\tdef __next__(self):\n\t\ttry:\n\t\t\tif (hasattr(self, 'input_file')):\n\t\t\t\treturn np.array(next(self.streaming_data))\n\t\t\telse:\n\t\t\t\tif (self.streaming_data == self.length):\n\t\t\t\t\traise\n\t\t\t\telse:\n\t\t\t\t\treturn np.array(self.data[self.streaming_data])\n\n\t\t\t\tself.streaming_data += 1\n\t\texcept StopIteration:\n\t\t\traise\n\n\tdef getSubSet(self, indexList):\n\t\t\"\"\"Returns a subset of the data given a list of indices.\"\"\"\n\t\tsubset = []\n\t\tfor index in indexList:\n\t\t\tsubset.append(self.data[index])\n\t\treturn Data(subset)\n\n\tdef save_data_json(self, output_file):\n\t\tfg = FileGenerator()\n\t\tfg.setGenerator(fg.linear_generator)\n\t\tfg.stream_save(output_file, self.data)\n\n\tdef save_data_pickle(self, output_file):\n\t\twith open(output_file, 'wb') as f: \n\t\t\tpickle.dump(self.data, f) \n\n\tdef load_data_json(self, input_file):\n\t\twith open(input_file, 'r') as f:\n\t\t\tself.input_file = input_file\n\n\t\t\tdata = json.load(f)\n\t\t\tself.data = data[\"data\"]\n\t\t\tself.length = data[\"length\"]\n\t\t\tfor i, point in enumerate(self.data):\n\t\t\t\tself.data[i] = np.array(point)\n\n\t\t\treturn self.data\n\n\tdef load_data_pickle(self, input_file):\n\t\twith open(input_file, 'r') as f:\n\t\t\tself.input_file = input_file\n\t\t\tself.data = pickle.load(f)\n\n\t\t\treturn self.data\n\n\tdef stream_data_json(self, input_file):\n\t\t\"\"\"Stream the dataset if its saved in a json file\"\"\"\n\t\twith open(input_file, 'rb') as f:\n\t\t\tf.seek(0, 2)\n\t\t\tposition = f.tell()\n\n\t\t\tvalue = \"\"\n\t\t\tread = False\n\t\t\twhile position &gt; 0:\n\t\t\t\tposition -= 1\n\t\t\t\tf.seek(position)\n\t\t\t\tbyte = f.read(1)\n\n\t\t\t\tif byte == b' ':\n\t\t\t\t\t# print(value)\n\t\t\t\t\tyield int(value)\n\t\t\t\t\tbreak\n\n\t\t\t\tif (read):\n\t\t\t\t\tvalue = byte.decode() + value\n\n\t\t\t\tif byte == b'}':\n\t\t\t\t\tread = True\n\n\t\twith open(input_file, 'r') as f:\n\t\t\tf.readline()\n\n\t\t\tfor line in f:\n\t\t\t\tif (\"length\" in line):\n\t\t\t\t\tbreak\n\n\t\t\t\tdata = json.loads(line.strip().split(']')[0] + ']')\n\t\t\t\tyield np.array(data)\n\n\tfile_function_pairs = [[\"json\", save_data_json, load_data_json], [\"pkl\", save_data_pickle, load_data_pickle]]\n\n\tdef data_function(self, file, save_or_load):\n\t\t\"\"\"Used for saving and loading the dataset\"\"\"\n\t\tif (file == None):\n\t\t\treturn\n\n\t\tfor ffp in self.file_function_pairs:\n\t\t\tif file[-len(ffp[0]):] == ffp[0]:\n\t\t\t\tif save_or_load == 1:\n\t\t\t\t\tffp[save_or_load](self.data, file)\n\t\t\t\telse:\n\t\t\t\t\treturn ffp[save_or_load](self, file)\n\n\tdef save_data(self, output_file):\n\t\tself.data_function(output_file, 1)\n\t\treturn self\n\n\tdef load_data(self, input_file):\n\t\tself.data_function(input_file, 2)\n\t\treturn self\n\n\tdef get_random_point(self):\n\t\t\"\"\"Returns a random point from the dataset.\"\"\"\n\t\treturn select_random(self.data)\n\n\tdef plot(self, name=None):\n\t\t\"\"\"Plots the dataset.\"\"\"\n\t\tPlotter().plotPoints(self.data, name)\n\n\tdef getNumpy(self):\n\t\tif isinstance(self.data, np.ndarray):\n\t\t\t# print(self.data.shape)\n\t\t\treturn self.data\n\t\telse:\n\t\t\ttemp = []\n\t\t\tfor x in self.data:\n\t\t\t\ttemp.append(np.array(x))\n\n\t\t\t# print(np.array(temp).shape)\n\t\t\treturn np.array(temp)\n</code></pre>"},{"location":"reference/#code.create_data.Data.data_function","title":"<code>data_function(file, save_or_load)</code>","text":"<p>Used for saving and loading the dataset</p> Source code in <code>code/create_data.py</code> <pre><code>def data_function(self, file, save_or_load):\n\t\"\"\"Used for saving and loading the dataset\"\"\"\n\tif (file == None):\n\t\treturn\n\n\tfor ffp in self.file_function_pairs:\n\t\tif file[-len(ffp[0]):] == ffp[0]:\n\t\t\tif save_or_load == 1:\n\t\t\t\tffp[save_or_load](self.data, file)\n\t\t\telse:\n\t\t\t\treturn ffp[save_or_load](self, file)\n</code></pre>"},{"location":"reference/#code.create_data.Data.getSubSet","title":"<code>getSubSet(indexList)</code>","text":"<p>Returns a subset of the data given a list of indices.</p> Source code in <code>code/create_data.py</code> <pre><code>def getSubSet(self, indexList):\n\t\"\"\"Returns a subset of the data given a list of indices.\"\"\"\n\tsubset = []\n\tfor index in indexList:\n\t\tsubset.append(self.data[index])\n\treturn Data(subset)\n</code></pre>"},{"location":"reference/#code.create_data.Data.get_random_point","title":"<code>get_random_point()</code>","text":"<p>Returns a random point from the dataset.</p> Source code in <code>code/create_data.py</code> <pre><code>def get_random_point(self):\n\t\"\"\"Returns a random point from the dataset.\"\"\"\n\treturn select_random(self.data)\n</code></pre>"},{"location":"reference/#code.create_data.Data.plot","title":"<code>plot(name=None)</code>","text":"<p>Plots the dataset.</p> Source code in <code>code/create_data.py</code> <pre><code>def plot(self, name=None):\n\t\"\"\"Plots the dataset.\"\"\"\n\tPlotter().plotPoints(self.data, name)\n</code></pre>"},{"location":"reference/#code.create_data.Data.stream_data_json","title":"<code>stream_data_json(input_file)</code>","text":"<p>Stream the dataset if its saved in a json file</p> Source code in <code>code/create_data.py</code> <pre><code>def stream_data_json(self, input_file):\n\t\"\"\"Stream the dataset if its saved in a json file\"\"\"\n\twith open(input_file, 'rb') as f:\n\t\tf.seek(0, 2)\n\t\tposition = f.tell()\n\n\t\tvalue = \"\"\n\t\tread = False\n\t\twhile position &gt; 0:\n\t\t\tposition -= 1\n\t\t\tf.seek(position)\n\t\t\tbyte = f.read(1)\n\n\t\t\tif byte == b' ':\n\t\t\t\t# print(value)\n\t\t\t\tyield int(value)\n\t\t\t\tbreak\n\n\t\t\tif (read):\n\t\t\t\tvalue = byte.decode() + value\n\n\t\t\tif byte == b'}':\n\t\t\t\tread = True\n\n\twith open(input_file, 'r') as f:\n\t\tf.readline()\n\n\t\tfor line in f:\n\t\t\tif (\"length\" in line):\n\t\t\t\tbreak\n\n\t\t\tdata = json.loads(line.strip().split(']')[0] + ']')\n\t\t\tyield np.array(data)\n</code></pre>"},{"location":"reference/#code.create_data.DataCreator","title":"<code>DataCreator</code>","text":"Source code in <code>code/create_data.py</code> <pre><code>class DataCreator():\n\tdef __init__(self):\n\t\tself.fg = FileGenerator()\n\n\tdef stream_dataset_creator(self, output_file, function, seed, stream, *args):\n\t\t\"\"\"Creates a dataset by passing in generator functions, allowing for streamed and not streamed dataset creation\"\"\"\n\t\trandom.seed(seed)\n\n\t\tif (stream):\n\t\t\tself.fg.setGenerator(function)\n\t\t\tself.fg.stream_save(output_file, *args)\n\t\t\tdata = Data(output_file, stream=True)\n\t\telse:\n\t\t\tdata = []\n\n\t\t\tfor point in function(*args):\n\t\t\t\tdata.append(point)\n\n\t\t\tdata = Data(data)\n\t\t\tdata.save_data(output_file)\n\n\t\treturn data\n\n\tdef create_dataset_line(self, output_file=None, start=0, end=1, points=1000, seed=42, stream=False):\n\t\t\"\"\"Generates a dataset of a 1D line\"\"\"\n\t\treturn self.stream_dataset_creator(output_file, self.fg.line_generator, seed, stream, start, end, points)\n\n\tdef create_dataset_square_edge(self, output_file=None, p1=(0,0), p2=(1,1), points=1000, seed=42):\n\t\t\"\"\"Generates a dataset of the edge of a square\"\"\"\n\t\tdata = []\n\t\trandom.seed(seed)\n\n\t\tx_diff = p2[0] - p1[0]\n\t\ty_diff = p2[1] - p1[1]\n\n\t\tfor p in range(points):\n\t\t\tr = random.random() * 4\n\t\t\tside = int(r)\n\t\t\tvar = r - side\n\n\t\t\tx_side = side % 2\n\t\t\ty_side = side &gt;&gt; 1\n\n\t\t\tx_rev = 1 - x_side\n\t\t\ty_rev = 1 - y_side\n\n\t\t\tvariation = np.array([var * x_side * x_diff, var * x_rev * y_diff]) \t# Variations on the axis that draw the lines\n\t\t\tside = np.array([x_rev  * y_side * x_diff, x_side * y_rev * y_diff])\t# Move the line to the side it is drawing on\n\t\t\tshift = np.array([p1[0], p1[1]])\t\t\t\t\t\t\t\t\t\t# The shift to make the bottom left be p1\n\n\t\t\tdata.append(np.array(variation + side + shift))\n\n\t\tdata = Data(data)\n\t\tdata.save_data(output_file)\n\n\t\treturn data\n\n\tdef create_dataset_square_fill(self, output_file=None, p1=(0,0), p2=(1,1), points=1000, seed=42):\n\t\t\"\"\"Generates a dataset of a filled in square\"\"\"\n\t\tdata = []\n\t\trandom.seed(seed)\n\n\t\tx_diff = p2[0] - p1[0]\n\t\ty_diff = p2[1] - p1[1]\n\n\t\tfor p in range(points):\n\t\t\tx_rand = random.random()\n\t\t\ty_rand = random.random()\n\n\t\t\tdata.append(np.array([x_diff * x_rand + p1[0], y_diff * y_rand + p2[0]]))\n\n\t\tdata = Data(data)\n\t\tdata.save_data(output_file)\n\n\t\treturn data\n\n\tdef create_dataset_eigth_sphere(self, output_file=None, radius=1, x_pos=True, y_pos=True, z_pos=True, points=1000, seed=42, stream=False):\n\t\t\"\"\"Generates a dataset of an eigth sphere\"\"\"\n\t\treturn self.stream_dataset_creator(output_file, self.fg.eigth_sphere_generator, seed, stream, radius, x_pos, y_pos, z_pos, points)\n\n\tdef create_dataset_triangle(self, output_file=None, edges=[[0, 0], [1, 1], [2, 0]], points=1000, seed=42, stream=False):\n\t\t\"\"\"Generates a dataset of an eigth sphere\"\"\"\n\t\treturn self.stream_dataset_creator(output_file, self.fg.triangle_generator, seed, stream, edges, points)\n\n\tdef create_dataset_strong_clusters(self, output_file=None, internal_std=1, external_std=10, mean=[0, 0], clusters=10, points=1000, seed=42, stream=False):\n\t\t\"\"\"Generates a strongly clustered datapoint by selecting cluster centers and variance in the clusters via normal distribution\"\"\"\n\t\tdata = []\n\t\trandom.seed(seed)\n\n\t\tnp_mean = np.array(mean)\n\n\t\tcluster_centers = []\n\t\tfor c in range(clusters):\n\t\t\tcluster_centers.append(varied_point(np_mean, external_std))\n\n\t\tif (stream):\n\t\t\tself.fg.setGenerator(self.fg.strong_cluster_generator)\n\t\t\tself.fg.stream_save(output_file, internal_std, cluster_centers, points)\n\t\t\tdata = Data(output_file, stream=True)\n\t\telse:\n\t\t\tfor p in self.fg.strong_cluster_generator(internal_std, cluster_centers, points):\n\t\t\t\tdata.append(p)\n\n\t\t\tdata = Data(data)\n\t\t\tdata.save_data(output_file)\n\n\t\treturn data\n\n\tdef rotate_into_dimention(self, data, higher_dim=3, seed=42):\n\t\t\"\"\"Moves the data into a higher dimention and does rotations centered at the origin\"\"\"\n\t\trotation_matrix = np.identity(higher_dim)\n\n\t\tif (seed != -1):\n\t\t\trandom.seed(seed)\n\n\t\tfor x1 in range(0, higher_dim - 1):\n\t\t\tfor x2 in range(x1 + 1, higher_dim):\n\t\t\t\tangle = 2 * np.pi * random.random()\n\n\t\t\t\trotateOnTheseAxes = np.identity(higher_dim)\n\t\t\t\trotateOnTheseAxes[x1, x1] = np.cos(angle)\n\t\t\t\trotateOnTheseAxes[x2, x2] = np.cos(angle)\n\t\t\t\trotateOnTheseAxes[x1, x2] = np.sin(angle)\n\t\t\t\trotateOnTheseAxes[x2, x1] = -np.sin(angle)\n\n\t\t\t\trotation_matrix = np.matmul(rotation_matrix, rotateOnTheseAxes)\n\n\t\t# print(rotation_matrix)\n\n\t\tdata.data = list(data.data)\n\n\t\tfor i in range(0, len(data)):\n\t\t\textendedPoint = np.zeros(higher_dim)\n\t\t\textendedPoint[:len(data[i])] = data[i]\n\n\t\t\tdata[i] = np.matmul(rotation_matrix, extendedPoint)\n\n\t\tdata.data = np.array(data.data)\n\n\t\treturn data\n\n\tdef create_dataset_spiral(self, output_file=None, radius=1, center=[0, 0], rotations=3, height=10, points=1000, seed=42, stream=False):\n\t\treturn self.stream_dataset_creator(output_file, self.fg.spiral_generator, seed, stream, radius, center, rotations, height, points)\n</code></pre>"},{"location":"reference/#code.create_data.DataCreator.create_dataset_eigth_sphere","title":"<code>create_dataset_eigth_sphere(output_file=None, radius=1, x_pos=True, y_pos=True, z_pos=True, points=1000, seed=42, stream=False)</code>","text":"<p>Generates a dataset of an eigth sphere</p> Source code in <code>code/create_data.py</code> <pre><code>def create_dataset_eigth_sphere(self, output_file=None, radius=1, x_pos=True, y_pos=True, z_pos=True, points=1000, seed=42, stream=False):\n\t\"\"\"Generates a dataset of an eigth sphere\"\"\"\n\treturn self.stream_dataset_creator(output_file, self.fg.eigth_sphere_generator, seed, stream, radius, x_pos, y_pos, z_pos, points)\n</code></pre>"},{"location":"reference/#code.create_data.DataCreator.create_dataset_line","title":"<code>create_dataset_line(output_file=None, start=0, end=1, points=1000, seed=42, stream=False)</code>","text":"<p>Generates a dataset of a 1D line</p> Source code in <code>code/create_data.py</code> <pre><code>def create_dataset_line(self, output_file=None, start=0, end=1, points=1000, seed=42, stream=False):\n\t\"\"\"Generates a dataset of a 1D line\"\"\"\n\treturn self.stream_dataset_creator(output_file, self.fg.line_generator, seed, stream, start, end, points)\n</code></pre>"},{"location":"reference/#code.create_data.DataCreator.create_dataset_square_edge","title":"<code>create_dataset_square_edge(output_file=None, p1=(0, 0), p2=(1, 1), points=1000, seed=42)</code>","text":"<p>Generates a dataset of the edge of a square</p> Source code in <code>code/create_data.py</code> <pre><code>def create_dataset_square_edge(self, output_file=None, p1=(0,0), p2=(1,1), points=1000, seed=42):\n\t\"\"\"Generates a dataset of the edge of a square\"\"\"\n\tdata = []\n\trandom.seed(seed)\n\n\tx_diff = p2[0] - p1[0]\n\ty_diff = p2[1] - p1[1]\n\n\tfor p in range(points):\n\t\tr = random.random() * 4\n\t\tside = int(r)\n\t\tvar = r - side\n\n\t\tx_side = side % 2\n\t\ty_side = side &gt;&gt; 1\n\n\t\tx_rev = 1 - x_side\n\t\ty_rev = 1 - y_side\n\n\t\tvariation = np.array([var * x_side * x_diff, var * x_rev * y_diff]) \t# Variations on the axis that draw the lines\n\t\tside = np.array([x_rev  * y_side * x_diff, x_side * y_rev * y_diff])\t# Move the line to the side it is drawing on\n\t\tshift = np.array([p1[0], p1[1]])\t\t\t\t\t\t\t\t\t\t# The shift to make the bottom left be p1\n\n\t\tdata.append(np.array(variation + side + shift))\n\n\tdata = Data(data)\n\tdata.save_data(output_file)\n\n\treturn data\n</code></pre>"},{"location":"reference/#code.create_data.DataCreator.create_dataset_square_fill","title":"<code>create_dataset_square_fill(output_file=None, p1=(0, 0), p2=(1, 1), points=1000, seed=42)</code>","text":"<p>Generates a dataset of a filled in square</p> Source code in <code>code/create_data.py</code> <pre><code>def create_dataset_square_fill(self, output_file=None, p1=(0,0), p2=(1,1), points=1000, seed=42):\n\t\"\"\"Generates a dataset of a filled in square\"\"\"\n\tdata = []\n\trandom.seed(seed)\n\n\tx_diff = p2[0] - p1[0]\n\ty_diff = p2[1] - p1[1]\n\n\tfor p in range(points):\n\t\tx_rand = random.random()\n\t\ty_rand = random.random()\n\n\t\tdata.append(np.array([x_diff * x_rand + p1[0], y_diff * y_rand + p2[0]]))\n\n\tdata = Data(data)\n\tdata.save_data(output_file)\n\n\treturn data\n</code></pre>"},{"location":"reference/#code.create_data.DataCreator.create_dataset_strong_clusters","title":"<code>create_dataset_strong_clusters(output_file=None, internal_std=1, external_std=10, mean=[0, 0], clusters=10, points=1000, seed=42, stream=False)</code>","text":"<p>Generates a strongly clustered datapoint by selecting cluster centers and variance in the clusters via normal distribution</p> Source code in <code>code/create_data.py</code> <pre><code>def create_dataset_strong_clusters(self, output_file=None, internal_std=1, external_std=10, mean=[0, 0], clusters=10, points=1000, seed=42, stream=False):\n\t\"\"\"Generates a strongly clustered datapoint by selecting cluster centers and variance in the clusters via normal distribution\"\"\"\n\tdata = []\n\trandom.seed(seed)\n\n\tnp_mean = np.array(mean)\n\n\tcluster_centers = []\n\tfor c in range(clusters):\n\t\tcluster_centers.append(varied_point(np_mean, external_std))\n\n\tif (stream):\n\t\tself.fg.setGenerator(self.fg.strong_cluster_generator)\n\t\tself.fg.stream_save(output_file, internal_std, cluster_centers, points)\n\t\tdata = Data(output_file, stream=True)\n\telse:\n\t\tfor p in self.fg.strong_cluster_generator(internal_std, cluster_centers, points):\n\t\t\tdata.append(p)\n\n\t\tdata = Data(data)\n\t\tdata.save_data(output_file)\n\n\treturn data\n</code></pre>"},{"location":"reference/#code.create_data.DataCreator.create_dataset_triangle","title":"<code>create_dataset_triangle(output_file=None, edges=[[0, 0], [1, 1], [2, 0]], points=1000, seed=42, stream=False)</code>","text":"<p>Generates a dataset of an eigth sphere</p> Source code in <code>code/create_data.py</code> <pre><code>def create_dataset_triangle(self, output_file=None, edges=[[0, 0], [1, 1], [2, 0]], points=1000, seed=42, stream=False):\n\t\"\"\"Generates a dataset of an eigth sphere\"\"\"\n\treturn self.stream_dataset_creator(output_file, self.fg.triangle_generator, seed, stream, edges, points)\n</code></pre>"},{"location":"reference/#code.create_data.DataCreator.rotate_into_dimention","title":"<code>rotate_into_dimention(data, higher_dim=3, seed=42)</code>","text":"<p>Moves the data into a higher dimention and does rotations centered at the origin</p> Source code in <code>code/create_data.py</code> <pre><code>def rotate_into_dimention(self, data, higher_dim=3, seed=42):\n\t\"\"\"Moves the data into a higher dimention and does rotations centered at the origin\"\"\"\n\trotation_matrix = np.identity(higher_dim)\n\n\tif (seed != -1):\n\t\trandom.seed(seed)\n\n\tfor x1 in range(0, higher_dim - 1):\n\t\tfor x2 in range(x1 + 1, higher_dim):\n\t\t\tangle = 2 * np.pi * random.random()\n\n\t\t\trotateOnTheseAxes = np.identity(higher_dim)\n\t\t\trotateOnTheseAxes[x1, x1] = np.cos(angle)\n\t\t\trotateOnTheseAxes[x2, x2] = np.cos(angle)\n\t\t\trotateOnTheseAxes[x1, x2] = np.sin(angle)\n\t\t\trotateOnTheseAxes[x2, x1] = -np.sin(angle)\n\n\t\t\trotation_matrix = np.matmul(rotation_matrix, rotateOnTheseAxes)\n\n\t# print(rotation_matrix)\n\n\tdata.data = list(data.data)\n\n\tfor i in range(0, len(data)):\n\t\textendedPoint = np.zeros(higher_dim)\n\t\textendedPoint[:len(data[i])] = data[i]\n\n\t\tdata[i] = np.matmul(rotation_matrix, extendedPoint)\n\n\tdata.data = np.array(data.data)\n\n\treturn data\n</code></pre>"},{"location":"reference/#code.create_data.DataCreator.stream_dataset_creator","title":"<code>stream_dataset_creator(output_file, function, seed, stream, *args)</code>","text":"<p>Creates a dataset by passing in generator functions, allowing for streamed and not streamed dataset creation</p> Source code in <code>code/create_data.py</code> <pre><code>def stream_dataset_creator(self, output_file, function, seed, stream, *args):\n\t\"\"\"Creates a dataset by passing in generator functions, allowing for streamed and not streamed dataset creation\"\"\"\n\trandom.seed(seed)\n\n\tif (stream):\n\t\tself.fg.setGenerator(function)\n\t\tself.fg.stream_save(output_file, *args)\n\t\tdata = Data(output_file, stream=True)\n\telse:\n\t\tdata = []\n\n\t\tfor point in function(*args):\n\t\t\tdata.append(point)\n\n\t\tdata = Data(data)\n\t\tdata.save_data(output_file)\n\n\treturn data\n</code></pre>"},{"location":"reference/#code.create_data.FileGenerator","title":"<code>FileGenerator</code>","text":"<p>Generates files for saved data. Its own class because it is used by Data and DataCreator</p> Source code in <code>code/create_data.py</code> <pre><code>class FileGenerator():\n\t\"\"\"Generates files for saved data. Its own class because it is used by Data and DataCreator\"\"\"\n\tdef __init__(self):\n\t\tpass\n\n\tdef setGenerator(self, fn):\n\t\tself.data_generator = fn\n\n\tdef stream_save(self, output_file, *args):\n\t\t\"\"\"Saves data to a JSON file in a streaming manner.\"\"\"\n\t\twith open(output_file, \"w\") as f:\n\t\t\tf.write(\"{\\\"data\\\": [\\n\")\n\t\t\tfirst = True\n\t\t\tlength = 0\n\t\t\tfor array in self.data_generator(*args):\n\t\t\t\tif not first:\n\t\t\t\t\tf.write(\", \\n\")\n\t\t\t\tjson.dump(list(array), f)\n\t\t\t\tlength += 1\n\t\t\t\tfirst = False\n\t\t\tf.write(\"], \\n\\\"length\\\": \" + str(length) + \"}\")\n\n\tdef linear_generator(self, data):\n\t\t\"\"\"Yields data points one by one.\"\"\"\n\t\tfor d in data.tolist():\n\t\t\tyield d\n\n\tdef line_generator(self, start, end, points):\n\t\t\"\"\"Generates points along a line in 1D space.\"\"\"\n\t\tfor _ in range(points):\n\t\t\tyield np.array([random.random() * (end - start) + start])\n\n\tdef eigth_sphere_generator(self, radius, x_pos, y_pos, z_pos, points):\n\t\t\"\"\"Generator for points on an eigth sphere\"\"\"\n\t\tfor p in range(points):\t\t\t\n\t\t\tz = random.random()\t\t\t\t\t\t# Z value\n\t\t\tangleXY = np.pi * random.random() / 2\t# Angle in the XY plane\n\n\t\t\tyield np.array([radius * np.sqrt(1 - z**2) * np.cos(angleXY) * (2 * x_pos - 1), radius * np.sqrt(1 - z**2) * np.sin(angleXY) * (2 * y_pos - 1), radius * z * (2 * z_pos - 1)])\n\n\tdef triangle_generator(self, edges, points):\n\t\t\"\"\"Generator for points on a triangle\"\"\"\n\t\tbase = np.array(edges[0])\n\t\tedgeDiff1 = np.array(edges[1]) - base\n\t\tedgeDiff2 = np.array(edges[2]) - base\n\t\tfor p in range(points):\n\t\t\td1 = random.random()\n\t\t\td2 = random.random()\n\n\t\t\tif d1 + d2 &gt; 1:\n\t\t\t\td1 = 1 - d1\n\t\t\t\td2 = 1 - d2\n\n\t\t\tyield base + d1 * edgeDiff1 + d2 * edgeDiff2\n\n\tdef strong_cluster_generator(self, internal_std, cluster_centers, points):\n\t\t\"\"\"Generates points in a strong cluster\"\"\"\n\t\tc = -1\n\t\tfor p in range(points):\n\t\t\tif (p / points &gt;= c / 100):\n\t\t\t\tc += 1\n\t\t\t\t# print(str(c) + \"%\")\n\n\t\t\tyield varied_point(select_random(cluster_centers), internal_std)\n\n\tdef spiral_generator(self, radius, center, rotations, height, points):\n\t\tline = 2 * np.pi * rotations\n\t\theightPerRadian = height / line\n\n\t\tfor p in range(points):\n\t\t\td = random.random() * line\n\t\t\tyield np.array([np.cos(d), np.sin(d), heightPerRadian * d])\n</code></pre>"},{"location":"reference/#code.create_data.FileGenerator.eigth_sphere_generator","title":"<code>eigth_sphere_generator(radius, x_pos, y_pos, z_pos, points)</code>","text":"<p>Generator for points on an eigth sphere</p> Source code in <code>code/create_data.py</code> <pre><code>def eigth_sphere_generator(self, radius, x_pos, y_pos, z_pos, points):\n\t\"\"\"Generator for points on an eigth sphere\"\"\"\n\tfor p in range(points):\t\t\t\n\t\tz = random.random()\t\t\t\t\t\t# Z value\n\t\tangleXY = np.pi * random.random() / 2\t# Angle in the XY plane\n\n\t\tyield np.array([radius * np.sqrt(1 - z**2) * np.cos(angleXY) * (2 * x_pos - 1), radius * np.sqrt(1 - z**2) * np.sin(angleXY) * (2 * y_pos - 1), radius * z * (2 * z_pos - 1)])\n</code></pre>"},{"location":"reference/#code.create_data.FileGenerator.line_generator","title":"<code>line_generator(start, end, points)</code>","text":"<p>Generates points along a line in 1D space.</p> Source code in <code>code/create_data.py</code> <pre><code>def line_generator(self, start, end, points):\n\t\"\"\"Generates points along a line in 1D space.\"\"\"\n\tfor _ in range(points):\n\t\tyield np.array([random.random() * (end - start) + start])\n</code></pre>"},{"location":"reference/#code.create_data.FileGenerator.linear_generator","title":"<code>linear_generator(data)</code>","text":"<p>Yields data points one by one.</p> Source code in <code>code/create_data.py</code> <pre><code>def linear_generator(self, data):\n\t\"\"\"Yields data points one by one.\"\"\"\n\tfor d in data.tolist():\n\t\tyield d\n</code></pre>"},{"location":"reference/#code.create_data.FileGenerator.stream_save","title":"<code>stream_save(output_file, *args)</code>","text":"<p>Saves data to a JSON file in a streaming manner.</p> Source code in <code>code/create_data.py</code> <pre><code>def stream_save(self, output_file, *args):\n\t\"\"\"Saves data to a JSON file in a streaming manner.\"\"\"\n\twith open(output_file, \"w\") as f:\n\t\tf.write(\"{\\\"data\\\": [\\n\")\n\t\tfirst = True\n\t\tlength = 0\n\t\tfor array in self.data_generator(*args):\n\t\t\tif not first:\n\t\t\t\tf.write(\", \\n\")\n\t\t\tjson.dump(list(array), f)\n\t\t\tlength += 1\n\t\t\tfirst = False\n\t\tf.write(\"], \\n\\\"length\\\": \" + str(length) + \"}\")\n</code></pre>"},{"location":"reference/#code.create_data.FileGenerator.strong_cluster_generator","title":"<code>strong_cluster_generator(internal_std, cluster_centers, points)</code>","text":"<p>Generates points in a strong cluster</p> Source code in <code>code/create_data.py</code> <pre><code>def strong_cluster_generator(self, internal_std, cluster_centers, points):\n\t\"\"\"Generates points in a strong cluster\"\"\"\n\tc = -1\n\tfor p in range(points):\n\t\tif (p / points &gt;= c / 100):\n\t\t\tc += 1\n\t\t\t# print(str(c) + \"%\")\n\n\t\tyield varied_point(select_random(cluster_centers), internal_std)\n</code></pre>"},{"location":"reference/#code.create_data.FileGenerator.triangle_generator","title":"<code>triangle_generator(edges, points)</code>","text":"<p>Generator for points on a triangle</p> Source code in <code>code/create_data.py</code> <pre><code>def triangle_generator(self, edges, points):\n\t\"\"\"Generator for points on a triangle\"\"\"\n\tbase = np.array(edges[0])\n\tedgeDiff1 = np.array(edges[1]) - base\n\tedgeDiff2 = np.array(edges[2]) - base\n\tfor p in range(points):\n\t\td1 = random.random()\n\t\td2 = random.random()\n\n\t\tif d1 + d2 &gt; 1:\n\t\t\td1 = 1 - d1\n\t\t\td2 = 1 - d2\n\n\t\tyield base + d1 * edgeDiff1 + d2 * edgeDiff2\n</code></pre>"},{"location":"reference/#code.create_data.Plotter","title":"<code>Plotter</code>","text":"<p>Graphs the data into different formats</p> Source code in <code>code/create_data.py</code> <pre><code>class Plotter():\n\t\"\"\"Graphs the data into different formats\"\"\"\n\tdef pointFormatting(self, points):\n\t\t\"\"\"Formats points into coordinate lists for plotting.\"\"\"\n\t\tsize = len(points[0])\n\t\tx_coords = [point[0] for point in points]\n\t\tz_coords = None\n\t\tif size &gt; 1:\n\t\t\ty_coords = [point[1] for point in points]\n\t\t\tif size &gt; 2:\n\t\t\t\tz_coords = [point[2] for point in points]\n\t\telse:\n\t\t\ty_coords = [0 for point in points]\n\t\treturn (x_coords, y_coords, z_coords)\n\n\tdef plotPoints(self, points, name=None):\n\t\t\"\"\"Plots a set of points in 2D or 3D.\"\"\"\n\t\tself.plotPointSets([points], name)\n\n\tdef plotPointSets(self, sets, name=None):\n\t\t\"\"\"Plots multiple sets of points with different colors and markers.\"\"\"\n\t\tmarkers = ['o', 'v', '*']\n\t\tcolor = ['r', 'g', 'b']\n\t\tsize = len(sets[0][0])\n\t\tfig = plt.figure()\n\t\tif size == 3:\n\t\t\tax = fig.add_subplot(111, projection='3d')\n\t\telse:\n\t\t\tax = fig.add_subplot(111)\n\t\tfor i, points in enumerate(sets):\n\t\t\t(x_coords, y_coords, z_coords) = self.pointFormatting(points)\n\t\t\tif size == 3:\n\t\t\t\tax.scatter(x_coords, y_coords, z_coords, c=color[i], marker=markers[i], label='Points')\n\t\t\telse:\n\t\t\t\tax.scatter(x_coords, y_coords, c=color[i], marker=markers[i], label='Points')\n\t\tax.legend()\n\t\tif name:\n\t\t\tplt.savefig(name)\n\t\tplt.show()\n\n\tdef voltage_plot(self, solver, color='r', ax=None, show=True, label=\"\", colored=False, name=None):\n\t\tdim = len(solver.problem.data[0])\n\n\t\tif (ax == None):\n\t\t\tfig = plt.figure()\n\n\t\t\tif ((dim + (not colored)) == 3):\n\t\t\t\tax = fig.add_subplot(111, projection=\"3d\")\n\t\t\telse:\n\t\t\t\tax = fig.add_subplot(111)\n\n\t\tif (dim &gt; 3):\n\t\t\tpca = PCA(n_components=2)\n\t\t\tpoints_2d = pca.fit_transform(solver.problem.data)\n\t\t\tx_coords, y_coords, z_coords = points_2d[:, 0], points_2d[:, 1], None\n\n\t\t\tdim = 2\n\t\telse:\n\t\t\t(x_coords, y_coords, z_coords) = self.pointFormatting(solver.problem.data)\n\n\n\t\tcmap = None\n\t\tc = color\n\t\targs = [x_coords, y_coords, z_coords][:dim]\n\t\targs.append(solver.voltages)\n\t\tif colored:\n\t\t\tcmap = 'viridis'\n\t\t\tc = solver.voltages\n\t\t\targs = args[:-1]\n\n\t\t# print(c)\n\t\t# print(args)\n\t\tax.scatter(*args, c=c, cmap=cmap, marker='o', label=label)\n\n\t\tif (name):\n\t\t\tplt.savefig(name)\n\t\tif (show):\n\t\t\tplt.show()\n\n\t\treturn ax\n</code></pre>"},{"location":"reference/#code.create_data.Plotter.plotPointSets","title":"<code>plotPointSets(sets, name=None)</code>","text":"<p>Plots multiple sets of points with different colors and markers.</p> Source code in <code>code/create_data.py</code> <pre><code>def plotPointSets(self, sets, name=None):\n\t\"\"\"Plots multiple sets of points with different colors and markers.\"\"\"\n\tmarkers = ['o', 'v', '*']\n\tcolor = ['r', 'g', 'b']\n\tsize = len(sets[0][0])\n\tfig = plt.figure()\n\tif size == 3:\n\t\tax = fig.add_subplot(111, projection='3d')\n\telse:\n\t\tax = fig.add_subplot(111)\n\tfor i, points in enumerate(sets):\n\t\t(x_coords, y_coords, z_coords) = self.pointFormatting(points)\n\t\tif size == 3:\n\t\t\tax.scatter(x_coords, y_coords, z_coords, c=color[i], marker=markers[i], label='Points')\n\t\telse:\n\t\t\tax.scatter(x_coords, y_coords, c=color[i], marker=markers[i], label='Points')\n\tax.legend()\n\tif name:\n\t\tplt.savefig(name)\n\tplt.show()\n</code></pre>"},{"location":"reference/#code.create_data.Plotter.plotPoints","title":"<code>plotPoints(points, name=None)</code>","text":"<p>Plots a set of points in 2D or 3D.</p> Source code in <code>code/create_data.py</code> <pre><code>def plotPoints(self, points, name=None):\n\t\"\"\"Plots a set of points in 2D or 3D.\"\"\"\n\tself.plotPointSets([points], name)\n</code></pre>"},{"location":"reference/#code.create_data.Plotter.pointFormatting","title":"<code>pointFormatting(points)</code>","text":"<p>Formats points into coordinate lists for plotting.</p> Source code in <code>code/create_data.py</code> <pre><code>def pointFormatting(self, points):\n\t\"\"\"Formats points into coordinate lists for plotting.\"\"\"\n\tsize = len(points[0])\n\tx_coords = [point[0] for point in points]\n\tz_coords = None\n\tif size &gt; 1:\n\t\ty_coords = [point[1] for point in points]\n\t\tif size &gt; 2:\n\t\t\tz_coords = [point[2] for point in points]\n\telse:\n\t\ty_coords = [0 for point in points]\n\treturn (x_coords, y_coords, z_coords)\n</code></pre>"},{"location":"reference/#code.create_data.dimentional_variation","title":"<code>dimentional_variation(dimentions)</code>","text":"<p>Returns an np array that is full of random variables from -inf to inf based on the standard normal distribution</p> Source code in <code>code/create_data.py</code> <pre><code>def dimentional_variation(dimentions):\n\t\"\"\"Returns an np array that is full of random variables from -inf to inf based on the standard normal distribution\"\"\"\n\tz_vals = []\n\tfor d in range(dimentions):\n\t\tz_vals.append(stats.norm.ppf(random.random()))\n\n\treturn np.array(z_vals)\n</code></pre>"},{"location":"reference/#code.create_data.select_random","title":"<code>select_random(array)</code>","text":"<p>Selects a random element from an array.</p> Source code in <code>code/create_data.py</code> <pre><code>def select_random(array):\n\t\"\"\"Selects a random element from an array.\"\"\"\n\treturn array[int(len(array) * random.random())]\n</code></pre>"},{"location":"reference/#code.kmeans.Partitions","title":"<code>Partitions</code>","text":"<p>               Bases: <code>DistanceBased</code></p> <p>Using K-means to partition a large dataset</p> Source code in <code>code/kmeans.py</code> <pre><code>class Partitions(DistanceBased):\n\t\"\"\"Using K-means to partition a large dataset\"\"\"\n\tdef __init__(self, data):\n\t\tself.data = data\n\t\tsuper().__init__()\n\n\tdef k_means_plus_plus(self, k):\n\t\t# print(self.data.data)\n\t\tself.centers = [create_data.select_random(self.data)]\n\n\t\tfor i in range(k - 1):\n\t\t\tdistances = []\n\n\t\t\tfor point in self.data:\n\t\t\t\t# print(type(point))\n\t\t\t\t# print(type(self.centers[0]))\n\n\t\t\t\t# print(point)\n\t\t\t\t# print(self.centers[0])\n\n\t\t\t\td = self.distance(point, self.centers[0])\n\t\t\t\tfor center in self.centers:\n\t\t\t\t\td = min(d, self.distance(point, center))\n\n\t\t\t\tdistances.append(d)\n\n\t\t\tdistances = np.array(distances)\n\t\t\tdistances /= np.sum(distances)\n\n\t\t\tself.centers.append(weighted_random(self.data, distances))\n\n\t\treturn self.centers\n\n\tdef k_means(self, k, seed=42, savePointAssignments=False):\n\t\tif (seed == -1):\n\t\t\tkmeans = KMeans(n_clusters=k, init=\"k-means++\").fit(self.data)\n\t\telse:\n\t\t\tkmeans = KMeans(n_clusters=k, random_state=int(seed), init=\"k-means++\", n_init=1).fit(self.data)\n\n\t\tself.k = k\n\t\tself.centers = kmeans.cluster_centers_\n\t\tself.point_counts = np.bincount(kmeans.labels_).tolist()\n\n\t\tif savePointAssignments:\n\t\t\tself.point_assignments = [[] for i in range(k)]\n\t\t\tfor i, point in enumerate(data):\n\t\t\t\tlabel = kmeans.labels_[i]\n\n\t\t\t\t# print(point)\n\t\t\t\t# print(self.centers[label])\n\t\t\t\t# print(self.distance(point, self.centers[label]))\n\t\t\t\tself.point_assignments[label].append([point, self.distance(point, self.centers[label])])\n\n\t\t\t# self.point_assignments = [data[kmeans.labels_ == i] for i in range(k)]\t# k times less efficient\n\t\t# self.voronoi = Voronoi(self.centers)\n\n\tdef my_k_means(self, k, seed=42, savePointAssignments=False):\n\t\tif (seed != -1):\n\t\t\trandom.seed(seed)\n\n\t\tself.centers = self.k_means_plus_plus(k)\n\n\t\tpoint_accumulator = [np.zeros(len(self.data[0])) for i in range(k)]\n\t\tpoint_counts = [0 for i in range(k)]\n\n\t\tif (savePointAssignments):\t\t\t\t\t\t\t\t\t\t\t\t\t\t# This removes the benefit of streaming\n\t\t\tself.point_assignments = [[] for i in range(k)]\n\n\t\tfor i, point in enumerate(self.data):\n\t\t\tmin_index = 0\n\t\t\tmin_dist = self.distance(point, self.centers[0])\n\n\t\t\tfor c in range(k - 1):\n\t\t\t\tdist = self.distance(point, self.centers[c + 1])\n\t\t\t\tif (min_dist &gt; dist):\n\t\t\t\t\tmin_index = c + 1\n\t\t\t\t\tmin_dist = dist\n\n\t\t\tif (savePointAssignments):\n\t\t\t\tself.point_assignments[min_index].append([point, min_dist])\n\n\t\t\tpoint_accumulator[min_index] += point\n\t\t\tpoint_counts[min_index] += 1\n\n\t\tupdated_centers = []\n\t\tself.point_counts = []\n\n\t\tfor acc, count in zip(point_accumulator, point_counts):\n\t\t\tif (count != 0):\n\t\t\t\tupdated_centers.append(acc / count)\n\t\t\t\tself.point_counts.append(count)\n\n\t\tself.centers = updated_centers\n\t\tself.voronoi = Voronoi(self.centers)\n\n\tdef getClosestPoints(self, index):\n\t\tclosest = []\n\t\tfor i, point in enumerate(self.data):\n\t\t\tmin_index = 0\n\t\t\tmin_dist = self.distance(point, self.centers[0])\n\n\t\t\tfor c in range(len(self.centers) - 1):\n\t\t\t\tdist = self.distance(point, self.centers[c + 1])\n\t\t\t\tif (min_dist &gt; dist):\n\t\t\t\t\tmin_index = c + 1\n\t\t\t\t\tmin_dist = dist\n\n\t\t\tif (min_index == index):\n\t\t\t\tclosest.append(i)\n\n\t\treturn closest\n\n\tdef plot(self, color='r', marker='o', ax=None, name=None):\n\t\tplot = create_data.Plotter()\n\n\t\tsize = len(self.centers[0])\n\n\t\tif (ax == None):\n\t\t\tfig = plt.figure()\n\n\t\t\tif (size == 3):\n\t\t\t\tax = fig.add_subplot(111, projection='3d')\n\t\t\telse:\n\t\t\t\tax = fig.add_subplot(111)\n\n\t\tif (size == 3):\n\t\t\t(x_coords, y_coords, z_coords) = plot.pointFormatting(self.centers)\n\t\t\tax.scatter(x_coords, y_coords, z_coords, c=color, marker=marker, label='Centers')\n\t\telse:\n\t\t\t(x_coords, y_coords, z_coords) = plot.pointFormatting(self.data)\n\t\t\tax.scatter(x_coords, y_coords, c=color, marker=marker, label='Points')\n\n\t\t\t# voronoi_plot_2d(self.voronoi, ax=ax, show_vertices=False, line_colors='blue', line_width=1, line_alpha=0.6)\n\n\t\tax.legend()\n\n\t\tif (name):\n\t\t\tplt.savefig(name)\n\n\t\tplt.show()\n</code></pre>"},{"location":"reference/#code.voltage.Landmark","title":"<code>Landmark</code>","text":"<p>Defines at which index datapoint will a voltage be applied to. Indicies could be either partition centers or data points themselves</p> Source code in <code>code/voltage.py</code> <pre><code>class Landmark():\n\t\"\"\"Defines at which index datapoint will a voltage be applied to. Indicies could be either partition centers or data points themselves\"\"\"\n\tdef __init__(self, index, voltage):\n\t\tself.index = index\n\t\tself.voltage = voltage\n\n\t@staticmethod\n\tdef createLandmarkClosestTo(data, point, voltage, distanceFn=None, ignore=[]):\n\t\tif (distanceFn == None):\n\t\t\tdistanceFn = kmeans.DistanceBased()\n\n\t\tmost_central_index = 0\n\t\tmindist = distanceFn.distance(data[0], point)\n\n\t\tfor index in range(1, len(data)):\n\t\t\tif (index in ignore):\n\t\t\t\tcontinue\n\n\t\t\tdist = distanceFn.distance(data[index], point)\n\t\t\tif dist &lt; mindist:\n\t\t\t\tmost_central_index = index\n\t\t\t\tmindist = dist\n\n\t\treturn Landmark(most_central_index, voltage)\n</code></pre>"},{"location":"reference/#code.voltage.Problem","title":"<code>Problem</code>","text":"<p>               Bases: <code>DistanceBased</code></p> <p>Represents the problem that is trying to be solved</p> Source code in <code>code/voltage.py</code> <pre><code>class Problem(kmeans.DistanceBased):\n\t\"\"\"Represents the problem that is trying to be solved\"\"\"\n\tdef __init__(self, data):\n\t\tself.data = data\n\t\tself.landmarks = []\n\t\tn = len(data)\n\t\tself.weights = np.zeros([len(data), len(data)])\n\t\tself.universalGround = False\n\t\tsuper().__init__()\n\n\tdef timeStart(self):\n\t\tself.start = time.time()\n\n\tdef timeEnd(self, replace=True):\n\t\tcurTime = time.time()\n\t\tdiff = curTime - self.start\n\n\t\tif (replace):\n\t\t\tself.start = curTime\n\n\t\treturn diff\n\n\tdef setKernel(self, kernel):\n\t\tself.kernel = kernel\n\n\tdef efficientSquareDistance(self, data):\n\t\tdata_norm2 = np.sum(data**2, axis=1)\n\n\t\tx_norm2 = data_norm2.reshape(-1, 1)\t\t\t\t# shape: (n, 1)\n\t\ty_norm2 = data_norm2.reshape(1, -1)\t\t\t\t# shape: (1, n)\n\t\treturn x_norm2 + y_norm2 - 2 * data @ data.T\t# shape: (n, n)\n\n\tdef radialkernel(self, data, r):\n\t\tdist2 = self.efficientSquareDistance(data)\n\t\treturn (dist2 &lt;= r**2).astype(float)\n\n\tdef gaussiankernel(self, data, std):\n\t\tdist2 = self.efficientSquareDistance(data)\n\t\treturn np.exp(-dist2 / (2 * std**2))\n\n\tdef setWeights(self, *c):\n\t\tn = len(self.data)\n\n\t\tdata = self.data.getNumpy()\n\n\t\t# print(data.shape)\n\n\t\tself.weights[:n, :n] = self.kernel(data, *c)\n\n\t\tself.normalizeWeights()\n\n\t\treturn self.weights\n\n\tdef normalizeWeights(self):\n\t\tself.weights = self.weights / self.weights.sum(axis=1, keepdims=True)\n\n\t\tif np.isnan(self.weights).any():\n\t\t\traise ValueError(\"Array contains NaN values!\")\n\n\tdef setPartitionWeights(self, partition, *c):\n\t\tn = len(partition.centers)\n\t\tcenters = np.array(partition.centers)\n\t\tcounts = np.array(partition.point_counts).reshape(-1, 1)\n\n\t\tK = self.kernel(centers[:, None], centers[None, :], *c)\n\n\t\tW = K * (counts @ counts.T)\n\n\t\tself.weights[:n, :n] = W\n\t\tself.normalizeWeights()\n\t\treturn self.weights\n\n\tdef addUniversalGround(self, p_g=0.01):\n\t\tif (self.universalGround):\n\t\t\tn = self.weights.shape[0] - 1\n\n\t\t\tfor x in range(n):\t\t\t\t# W[g, g] = 0\n\t\t\t\tself.weights[x][n] = p_g / n\n\t\t\t\tself.weights[n][x] = p_g / n\n\n\t\telse:\n\t\t\tself.universalGround = True\n\n\t\t\tn = self.weights.shape[0]\n\t\t\tnewW = np.zeros([n + 1, n + 1])\n\n\t\t\tnewW[0:n,0:n] = self.weights\n\n\t\t\tfor x in range(0, n):\t\t\t# W[g, g] = 0\n\t\t\t\tnewW[x][n] = p_g / n\n\t\t\t\tnewW[n][x] = p_g / n\n\n\t\t\tself.weights = newW\n\t\t\tself.addLandmark(Landmark(n, 0))\n\n\t\tself.normalizeWeights()\n\n\t\treturn self.weights\n\n\tdef addLandmark(self, landmark):\n\t\tself.landmarks.append(landmark)\n\n\tdef addLandmarks(self, landmarks):\n\t\tself.landmarks += landmarks\n\n\tdef addLandmarksInRange(self, minRange, maxRange, voltage):\n\t\tadding = []\n\t\tfor index, point in enumerate(data):\n\t\t\tif np.all(point &gt;= minRange) and np.all(point &lt;= maxRange):\n\t\t\t\tadding.append(Landmark(index, voltage))\n\n\t\tself.addLandmarks(adding)\n\t\treturn adding\n</code></pre>"},{"location":"reference/#code.voltage.Solver","title":"<code>Solver</code>","text":"<p>               Bases: <code>DistanceBased</code></p> <p>Solves a given Problem</p> Source code in <code>code/voltage.py</code> <pre><code>class Solver(kmeans.DistanceBased):\n\t\"\"\"Solves a given Problem\"\"\"\n\tdef __init__(self, problem):\n\t\tself.problem = problem\n\t\tsuper().__init__()\n\n\tdef compute_voltages(self):\n\t\tn = self.problem.weights.shape[0]\n\n\t\tconstrained_nodes =   [l.index for l in self.problem.landmarks]\n\t\tunconstrained_nodes = [i for i in range(n) if i not in constrained_nodes]\n\n\t\tb = np.zeros(n)\n\t\tfor landmark in self.problem.landmarks:\n\t\t\tfor y in range(0, n):\n\t\t\t\tb[y] += landmark.voltage * self.problem.weights[y][landmark.index]\n\n\t\tA_unconstrained = np.identity(len(unconstrained_nodes)) - self.problem.weights[np.ix_(unconstrained_nodes, unconstrained_nodes)]\n\n\t\tb_unconstrained = b[unconstrained_nodes]\n\n\t\t# print(self.problem.weights)\n\t\t# print(A_unconstrained)\n\t\t# print(b_unconstrained)\n\n\t\tv_unconstrained = solve(A_unconstrained, b_unconstrained)\n\n\t\t# print(v_unconstrained)\n\n\t\tself.voltages = np.zeros(n)\n\n\t\tfor landmark in self.problem.landmarks:\n\t\t\tself.voltages[landmark.index] = landmark.voltage\n\n\t\tself.voltages[unconstrained_nodes] = v_unconstrained\n\n\t\tif (self.problem.universalGround):\n\t\t\tself.voltages = self.voltages[:-1]\n\n\t\treturn self.voltages\n\n\tdef approximate_voltages(self, epsilon=None, max_iters=None):\n\t\tn = self.problem.weights.shape[0]\n\n\t\tif (epsilon == None):\n\t\t\tif (max_iters == None):\n\t\t\t\tepsilon = 1 / n\n\n\t\tconstrained_nodes =\t\t[l.index for l in self.problem.landmarks]\n\t\tconstraints = \t\t\t[l.voltage for l in self.problem.landmarks]\n\t\tunconstrained_nodes =\t[i for i in range(n) if i not in constrained_nodes]\n\n\t\tself.voltages = np.zeros(n)\n\t\tvoltages = np.zeros(n)\n\n\t\tfor landmark in self.problem.landmarks:\n\t\t\tself.voltages[landmark.index] = landmark.voltage\n\n\t\tdist = self.distance(self.voltages, voltages)\n\t\tprev_dist = float('inf')\n\n\t\titerations = 0\n\n\t\twhile (((epsilon != None and dist &gt; epsilon * len(self.problem.data)) or (max_iters != None and iterations &lt; max_iters)) and dist &lt; prev_dist):\n\t\t\tvoltages = np.matmul(self.problem.weights, self.voltages)\n\t\t\tvoltages[constrained_nodes] = constraints\n\t\t\tprev_dist = dist\n\t\t\tdist = self.distance(self.voltages, voltages)\n\n\t\t\t# print(prev_dist, dist)\n\n\t\t\tself.voltages = voltages\n\t\t\titerations += 1\n\n\t\t# print(iterations)\n\n\t\tif (self.problem.universalGround):\n\t\t\tself.voltages = self.voltages[:-1]\n\n\t\treturn self.voltages\n\n\tdef localSolver(self, partitions, c):\n\t\tvoltages = [0 for i in range(len(self.problem.data))]\n\n\t\tfor index in range(partitions.k):\n\t\t\tclosestIndicies = partitions.getClosestPoints(index)\n\t\t\tcloseproblem.LandmarksIndicies = []\n\n\t\t\tfor pair in partitions.voronoi.ridge_points:\n\t\t\t\tif pair[0] == index:\n\t\t\t\t\tcloseproblem.LandmarksIndicies.append(pair[1])\n\t\t\t\tif pair[1] == index:\n\t\t\t\t\tcloseproblem.LandmarksIndicies.append(pair[0])\n\n\t\t\tcloseproblem.Landmarks = []\n\t\t\tfor cli in closeproblem.LandmarksIndicies:\n\t\t\t\tcloseproblem.Landmarks.append(Landmark(cli, self.voltages[cli]))\n\n\t\t\tlocalSolver = Solver(self.problem.data.getSubSet(closestIndicies))\n\t\t\tlocalSolver.setKernel(self.problem.gaussiankernel)\n\t\t\tlocalSolver.setWeights(c)\n\t\t\tlocalSolver.addproblem.Landmarks(closeproblem.Landmarks)\n\t\t\tlocalVoltages = localSolver.compute_voltages()\n\n\t\t\tfor i, v in zip(closestIndicies, localVoltages):\n\t\t\t\tvoltages[i] = v\n\n\t\treturn voltages\n</code></pre>"}]}