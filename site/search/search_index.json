{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"reference/","title":"Reference","text":""},{"location":"reference/#clean_code.kmeans.Reader","title":"<code>Reader</code>","text":"<p>Reads a text file containing vectors line-by-line and yields batches of vectors and labels.</p> Each line in the file should be in the format <p>word val1 val2 val3 ...</p> <p>Attributes:</p> Name Type Description <code>file</code> <code>TextIO</code> <p>Opened file handle.</p> <code>counter</code> <code>int</code> <p>Number of vectors successfully read.</p> Source code in <code>clean_code/kmeans.py</code> <pre><code>class Reader:\n    \"\"\"\n    Reads a text file containing vectors line-by-line and yields batches of vectors and labels.\n\n    Each line in the file should be in the format:\n        word val1 val2 val3 ...\n\n    Attributes:\n        file (TextIO): Opened file handle.\n        counter (int): Number of vectors successfully read.\n    \"\"\"\n\n    def __init__(self, file_path):\n        \"\"\"\n        Initializes the Reader.\n\n        Args:\n            file_path (str): Path to the input text file.\n        \"\"\"\n        self.file = open(file_path, 'r', encoding='utf-8')\n        self.counter = 0\n\n    def stream_batches(self, batch_size):\n        \"\"\"\n        Generator that yields batches of vectors and labels as NumPy arrays.\n\n        Args:\n            batch_size (int): Number of vectors to include in each batch.\n\n        Yields:\n            tuple: (np.ndarray of shape (batch_size, vector_dim), np.ndarray of shape (batch_size,))\n        \"\"\"\n        while True:\n            vectors = []\n            labels = []\n            for _ in range(batch_size):\n                label, vec = readvec(self.file)\n                if vec is not None:\n                    vectors.append(vec)\n                    labels.append(label)\n                    self.counter += 1\n                    if self.counter % 1000 == 0:\n                        print(f\"\\rRead {self.counter} vectors\", end='', flush=True)\n            if not vectors:\n                break\n            yield np.stack(vectors), np.array(labels)\n\n    def close(self):\n        \"\"\"\n        Closes the file handle.\n        \"\"\"\n        self.file.close()\n</code></pre>"},{"location":"reference/#clean_code.kmeans.Reader.__init__","title":"<code>__init__(file_path)</code>","text":"<p>Initializes the Reader.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>Path to the input text file.</p> required Source code in <code>clean_code/kmeans.py</code> <pre><code>def __init__(self, file_path):\n    \"\"\"\n    Initializes the Reader.\n\n    Args:\n        file_path (str): Path to the input text file.\n    \"\"\"\n    self.file = open(file_path, 'r', encoding='utf-8')\n    self.counter = 0\n</code></pre>"},{"location":"reference/#clean_code.kmeans.Reader.close","title":"<code>close()</code>","text":"<p>Closes the file handle.</p> Source code in <code>clean_code/kmeans.py</code> <pre><code>def close(self):\n    \"\"\"\n    Closes the file handle.\n    \"\"\"\n    self.file.close()\n</code></pre>"},{"location":"reference/#clean_code.kmeans.Reader.stream_batches","title":"<code>stream_batches(batch_size)</code>","text":"<p>Generator that yields batches of vectors and labels as NumPy arrays.</p> <p>Parameters:</p> Name Type Description Default <code>batch_size</code> <code>int</code> <p>Number of vectors to include in each batch.</p> required <p>Yields:</p> Name Type Description <code>tuple</code> <p>(np.ndarray of shape (batch_size, vector_dim), np.ndarray of shape (batch_size,))</p> Source code in <code>clean_code/kmeans.py</code> <pre><code>def stream_batches(self, batch_size):\n    \"\"\"\n    Generator that yields batches of vectors and labels as NumPy arrays.\n\n    Args:\n        batch_size (int): Number of vectors to include in each batch.\n\n    Yields:\n        tuple: (np.ndarray of shape (batch_size, vector_dim), np.ndarray of shape (batch_size,))\n    \"\"\"\n    while True:\n        vectors = []\n        labels = []\n        for _ in range(batch_size):\n            label, vec = readvec(self.file)\n            if vec is not None:\n                vectors.append(vec)\n                labels.append(label)\n                self.counter += 1\n                if self.counter % 1000 == 0:\n                    print(f\"\\rRead {self.counter} vectors\", end='', flush=True)\n        if not vectors:\n            break\n        yield np.stack(vectors), np.array(labels)\n</code></pre>"},{"location":"reference/#clean_code.kmeans.StreamingKMeansPlusPlusFAISS","title":"<code>StreamingKMeansPlusPlusFAISS</code>","text":"<p>Implements streaming k-means++ centroid selection using FAISS for efficient distance computation.</p> <p>Attributes:</p> Name Type Description <code>d</code> <code>int</code> <p>Dimensionality of vectors.</p> <code>Z</code> <code>float</code> <p>Scaling constant for sampling probability.</p> <code>max_centroids</code> <code>int</code> <p>Maximum number of centroids to retain.</p> <code>centroids</code> <code>List[ndarray]</code> <p>List of current centroids.</p> Source code in <code>clean_code/kmeans.py</code> <pre><code>class StreamingKMeansPlusPlusFAISS:\n    \"\"\"\n    Implements streaming k-means++ centroid selection using FAISS for efficient distance computation.\n\n    Attributes:\n        d (int): Dimensionality of vectors.\n        Z (float): Scaling constant for sampling probability.\n        max_centroids (int): Maximum number of centroids to retain.\n        centroids (List[np.ndarray]): List of current centroids.\n    \"\"\"\n\n    def __init__(self, d, Z):\n        \"\"\"\n        Initializes the streaming k-means++ class.\n\n        Args:\n            d (int): Vector dimensionality.\n            Z (float): Normalization constant for sampling.\n            max_centroids (int): Maximum number of centroids to store.\n        \"\"\"\n        self.centroids = []\n        self.d = d\n        self.Z = Z\n        self.max_centroids = config.params['max_centroids']\n\n    def _build_faiss_index(self):\n        \"\"\"\n        Builds a FAISS index over current centroids.\n\n        Returns:\n            faiss.IndexFlatL2: FAISS index with current centroids or None if empty.\n        \"\"\"\n        if not self.centroids:\n            return None\n        stack_centroids=np.stack(self.centroids)\n        if config.params['normalize_vecs']:\n            faiss.normalize_L2(stack_centroids)\n        index = faiss.IndexFlatL2(self.d)\n        index.add(stack_centroids)\n        return index\n\n    def _compute_distances_squared(self, X, index):\n        \"\"\"\n        Computes squared distances from X to nearest centroid in index.\n\n        Args:\n            X (np.ndarray): Batch of input vectors.\n            index (faiss.IndexFlatL2): FAISS index of centroids.\n\n        Returns:\n            np.ndarray: Squared distances for each point in X.\n        \"\"\"\n        if index is None or index.ntotal == 0:\n            return np.full(X.shape[0], np.inf, dtype=np.float32)\n        D, _ = index.search(X, 1)\n        return D[:, 0]\n\n    def update(self, X_batch):\n        \"\"\"\n        Updates centroid list with new vectors selected via probabilistic sampling.\n\n        Args:\n            X_batch (np.ndarray): Normalized batch of vectors.\n        \"\"\"\n        index = self._build_faiss_index()\n        d2 = self._compute_distances_squared(X_batch, index)\n        probs = d2 / self.Z\n        rand_vals = np.random.rand(X_batch.shape[0])\n        accept_mask = (rand_vals &lt; probs) &amp; (d2 &gt; 0)\n\n        for x in X_batch[accept_mask]:\n            if config.params['normalize_vecs']:\n                x = x / np.linalg.norm(x)\n            if len(self.centroids) &lt; self.max_centroids:\n                self.centroids.append(x.copy())\n            else:\n                break\n\n    def get_centroids(self):\n        \"\"\"\n        Returns the current list of centroids as a NumPy array.\n\n        Returns:\n            np.ndarray: Centroids of shape (num_centroids, d)\n        \"\"\"\n        centroids = np.stack(self.centroids) if self.centroids else np.empty((0, self.d), dtype=np.float32)\n        if config.params['normalize_vecs'] and centroids.shape[0] &gt; 0:\n            norms = np.linalg.norm(centroids, axis=1, keepdims=True)\n            centroids = centroids / np.maximum(norms, 1e-10)\n        return centroids\n</code></pre>"},{"location":"reference/#clean_code.kmeans.StreamingKMeansPlusPlusFAISS.__init__","title":"<code>__init__(d, Z)</code>","text":"<p>Initializes the streaming k-means++ class.</p> <p>Parameters:</p> Name Type Description Default <code>d</code> <code>int</code> <p>Vector dimensionality.</p> required <code>Z</code> <code>float</code> <p>Normalization constant for sampling.</p> required <code>max_centroids</code> <code>int</code> <p>Maximum number of centroids to store.</p> required Source code in <code>clean_code/kmeans.py</code> <pre><code>def __init__(self, d, Z):\n    \"\"\"\n    Initializes the streaming k-means++ class.\n\n    Args:\n        d (int): Vector dimensionality.\n        Z (float): Normalization constant for sampling.\n        max_centroids (int): Maximum number of centroids to store.\n    \"\"\"\n    self.centroids = []\n    self.d = d\n    self.Z = Z\n    self.max_centroids = config.params['max_centroids']\n</code></pre>"},{"location":"reference/#clean_code.kmeans.StreamingKMeansPlusPlusFAISS._build_faiss_index","title":"<code>_build_faiss_index()</code>","text":"<p>Builds a FAISS index over current centroids.</p> <p>Returns:</p> Type Description <p>faiss.IndexFlatL2: FAISS index with current centroids or None if empty.</p> Source code in <code>clean_code/kmeans.py</code> <pre><code>def _build_faiss_index(self):\n    \"\"\"\n    Builds a FAISS index over current centroids.\n\n    Returns:\n        faiss.IndexFlatL2: FAISS index with current centroids or None if empty.\n    \"\"\"\n    if not self.centroids:\n        return None\n    stack_centroids=np.stack(self.centroids)\n    if config.params['normalize_vecs']:\n        faiss.normalize_L2(stack_centroids)\n    index = faiss.IndexFlatL2(self.d)\n    index.add(stack_centroids)\n    return index\n</code></pre>"},{"location":"reference/#clean_code.kmeans.StreamingKMeansPlusPlusFAISS._compute_distances_squared","title":"<code>_compute_distances_squared(X, index)</code>","text":"<p>Computes squared distances from X to nearest centroid in index.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>Batch of input vectors.</p> required <code>index</code> <code>IndexFlatL2</code> <p>FAISS index of centroids.</p> required <p>Returns:</p> Type Description <p>np.ndarray: Squared distances for each point in X.</p> Source code in <code>clean_code/kmeans.py</code> <pre><code>def _compute_distances_squared(self, X, index):\n    \"\"\"\n    Computes squared distances from X to nearest centroid in index.\n\n    Args:\n        X (np.ndarray): Batch of input vectors.\n        index (faiss.IndexFlatL2): FAISS index of centroids.\n\n    Returns:\n        np.ndarray: Squared distances for each point in X.\n    \"\"\"\n    if index is None or index.ntotal == 0:\n        return np.full(X.shape[0], np.inf, dtype=np.float32)\n    D, _ = index.search(X, 1)\n    return D[:, 0]\n</code></pre>"},{"location":"reference/#clean_code.kmeans.StreamingKMeansPlusPlusFAISS.get_centroids","title":"<code>get_centroids()</code>","text":"<p>Returns the current list of centroids as a NumPy array.</p> <p>Returns:</p> Type Description <p>np.ndarray: Centroids of shape (num_centroids, d)</p> Source code in <code>clean_code/kmeans.py</code> <pre><code>def get_centroids(self):\n    \"\"\"\n    Returns the current list of centroids as a NumPy array.\n\n    Returns:\n        np.ndarray: Centroids of shape (num_centroids, d)\n    \"\"\"\n    centroids = np.stack(self.centroids) if self.centroids else np.empty((0, self.d), dtype=np.float32)\n    if config.params['normalize_vecs'] and centroids.shape[0] &gt; 0:\n        norms = np.linalg.norm(centroids, axis=1, keepdims=True)\n        centroids = centroids / np.maximum(norms, 1e-10)\n    return centroids\n</code></pre>"},{"location":"reference/#clean_code.kmeans.StreamingKMeansPlusPlusFAISS.update","title":"<code>update(X_batch)</code>","text":"<p>Updates centroid list with new vectors selected via probabilistic sampling.</p> <p>Parameters:</p> Name Type Description Default <code>X_batch</code> <code>ndarray</code> <p>Normalized batch of vectors.</p> required Source code in <code>clean_code/kmeans.py</code> <pre><code>def update(self, X_batch):\n    \"\"\"\n    Updates centroid list with new vectors selected via probabilistic sampling.\n\n    Args:\n        X_batch (np.ndarray): Normalized batch of vectors.\n    \"\"\"\n    index = self._build_faiss_index()\n    d2 = self._compute_distances_squared(X_batch, index)\n    probs = d2 / self.Z\n    rand_vals = np.random.rand(X_batch.shape[0])\n    accept_mask = (rand_vals &lt; probs) &amp; (d2 &gt; 0)\n\n    for x in X_batch[accept_mask]:\n        if config.params['normalize_vecs']:\n            x = x / np.linalg.norm(x)\n        if len(self.centroids) &lt; self.max_centroids:\n            self.centroids.append(x.copy())\n        else:\n            break\n</code></pre>"},{"location":"reference/#clean_code.kmeans.Streaming_Kmeans","title":"<code>Streaming_Kmeans(filepath)</code>","text":"<p>Main function to perform streaming k-means++ with FAISS.</p> Steps <ol> <li>Estimate normalization constant Z from an initial buffer.</li> <li>Select centroids incrementally using streaming batches.</li> <li>Save final centroids to a .npy file.</li> </ol> <p>parameters are passed through config.params, see listing of parameters in argparse section.</p> Source code in <code>clean_code/kmeans.py</code> <pre><code>def Streaming_Kmeans(filepath):\n\n    \"\"\"\n    Main function to perform streaming k-means++ with FAISS.\n\n    Steps:\n        1. Estimate normalization constant Z from an initial buffer.\n        2. Select centroids incrementally using streaming batches.\n        3. Save final centroids to a .npy file.\n\n    parameters are passed through config.params, see listing of parameters in argparse section.\n    \"\"\"\n    reader = Reader(filepath)\n\n    # Step 1: Read initial buffer of vectors for Z estimation\n    buffer = []\n    d = None\n    total_needed = config.params['init_size']\n    collected = 0\n    for vectors, _ in reader.stream_batches(config.params['batch_size']):\n        if d is None:\n            d = vectors.shape[1]\n        if collected + len(vectors) &gt; total_needed:\n            vectors = vectors[:total_needed - collected]\n        buffer.append(vectors)\n        collected += len(vectors)\n        if collected &gt;= total_needed:\n            break\n\n    buffer = np.vstack(buffer)\n    if config.params['normalize_vecs']:\n        faiss.normalize_L2(buffer)\n\n    # Compute all pairwise distances using FAISS and set Z to the maximal distance\n    index = faiss.IndexFlatL2(d)\n    index.add(buffer)\n    D, _ = index.search(buffer, buffer.shape[0])  # D[i, j] is the squared L2 distance from buffer[i] to buffer[j]\n    np.fill_diagonal(D, -np.inf)\n    Z = np.sqrt(np.max(D))  # Take sqrt because FAISS returns squared distances\n    print(f\"\\nEstimated Z (max pairwise distance, FAISS) = {Z:.4f}\")\n    print(f\"minimum distance in buffer = {np.sqrt(np.min(D[D &gt; 0])):.4f}\")\n\n    # Step 2: Streaming centroid selection\n    # For seeding, pick a random vector from the buffer\n    centroid = buffer[np.random.randint(len(buffer))]\n    skmeans = StreamingKMeansPlusPlusFAISS(d=d, Z=Z)\n    if config.params['normalize_vecs']:\n        centroid = centroid.reshape(1, -1)\n        faiss.normalize_L2(centroid)\n        centroid = centroid[0]\n    skmeans.centroids.append(centroid)  # seed with the first point\n\n    for vectors, _ in reader.stream_batches(config.params['batch_size']):\n        if config.params['normalize_vecs']:\n            faiss.normalize_L2(vectors)\n        skmeans.update(vectors)\n\n    reader.close()\n\n    return skmeans,D\n</code></pre>"},{"location":"reference/#clean_code.setofpoints.SetOfPoints","title":"<code>SetOfPoints</code>","text":"<p>Represents a set of points in a d-dimensional space along with associated weights.</p> <p>Attributes:</p> Name Type Description <code>points</code> <code>ndarray</code> <p>A 2D numpy array of shape (n, d), where each row is a point in d-dimensional space.</p> <code>weights</code> <code>ndarray</code> <p>A 1D numpy array of shape (n,) representing the weight for each point.</p> Source code in <code>clean_code/setofpoints.py</code> <pre><code>class SetOfPoints:\n\t\"\"\"\n\tRepresents a set of points in a d-dimensional space along with associated weights.\n\n\tAttributes:\n\t\tpoints (np.ndarray): A 2D numpy array of shape (n, d), where each row is a point in d-dimensional space.\n\t\tweights (np.ndarray): A 1D numpy array of shape (n,) representing the weight for each point.\n\t\"\"\"\n\n\tdef __init__(self, points: np.ndarray, weights: Optional[np.ndarray] = None):\n\t\t\"\"\"\n\t\tInitializes a SetOfPoints instance.\n\n\t\tArgs:\n\t\t\tpoints (np.ndarray): A (n, d) array of n points in d-dimensional space.\n\t\t\tweights (Optional[np.ndarray]): A (n,) array of weights corresponding to the points.\n\n\t\tRaises:\n\t\t\tValueError: If points and weights have incompatible shapes.\n\t\t\"\"\"\n\n\t\tif points.ndim != 2:\n\t\t\traise ValueError(\"Points array must be 2-dimensional (n, d).\")\n\n\t\t# Create weights if not given\n\t\tif weights is None:\n\t\t\tweights = np.ones(points.shape[0])\n\n\t\tweights /= np.sum(weights)        \n\n\t\tif weights.ndim != 1:\n\t\t\traise ValueError(\"Weights array must be 1-dimensional (n,).\")\n\t\tif points.shape[0] != weights.shape[0]:\n\t\t\traise ValueError(\"Number of points and number of weights must be the same.\")\n\n\t\tself.points = points\n\t\tself.shape = points.shape\n\t\tself.weights = weights\n\n\tdef get_point(self, index: int) -&gt; Tuple[np.ndarray, float]:\n\t\t\"\"\"\n\t\tReturns a specific point and its weight.\n\n\t\tArgs:\n\t\t\tindex (int): Index of the point to retrieve.\n\n\t\tReturns:\n\t\t\tTuple[np.ndarray, float]: A tuple containing the point (1D array) and its weight.\n\t\t\"\"\"\n\t\treturn self.points[index], self.weights[index]\n\n\tdef normalize_weights(self) -&gt; None:\n\t\t\"\"\"\n\t\tNormalizes the weights so that they sum to 1.\n\t\t\"\"\"\n\t\ttotal = np.sum(self.weights)\n\t\tif total == 0:\n\t\t\traise ValueError(\"Total weight is zero. Cannot normalize.\")\n\t\tself.weights = self.weights / total\n\n\tdef subset(self, indices: np.ndarray) -&gt; \"SetOfPoints\":\n\t\t\"\"\"\n\t\tReturns a new SetOfPoints object containing only the selected indices.\n\n\t\tArgs:\n\t\t\tindices (np.ndarray): An array of indices to include in the new subset.\n\n\t\tReturns:\n\t\t\tSetOfPoints: A new SetOfPoints object with selected points and weights.\n\t\t\"\"\"\n\t\treturn SetOfPoints(self.points[indices], self.weights[indices])\n\n\tdef __len__(self) -&gt; int:\n\t\t\"\"\"\n\t\tReturns the number of points in the set.\n\n\t\tReturns:\n\t\t\tint: Number of points.\n\t\t\"\"\"\n\t\treturn self.points.shape[0]\n\n\tdef __getitem__(self, index):\n\t\t\"\"\"\n\t\tAllows indexing into the dataset.\n\n\t\tArgs:\n\t\t\tindex (int): Index of the desired data point.\n\n\t\tReturns:\n\t\t\tnp.ndarray: The data point at the given index.\n\t\t\"\"\"\n\t\treturn self.points[index]\n\n\tdef __setitem__(self, index, value):\n\t\t\"\"\"\n\t\tSets a value in the dataset at a specified index.\n\n\t\tArgs:\n\t\t\tindex (int): The index to modify.\n\t\t\tvalue (Any): The new value to set.\n\t\t\"\"\"\n\t\tself.points[index] = value\n\n\tdef dimension(self) -&gt; int:\n\t\t\"\"\"\n\t\tReturns the dimensionality of the points.\n\n\t\tReturns:\n\t\t\tint: The dimension (d) of each point.\n\t\t\"\"\"\n\t\treturn self.points.shape[1]\n</code></pre>"},{"location":"reference/#clean_code.setofpoints.SetOfPoints.__getitem__","title":"<code>__getitem__(index)</code>","text":"<p>Allows indexing into the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>int</code> <p>Index of the desired data point.</p> required <p>Returns:</p> Type Description <p>np.ndarray: The data point at the given index.</p> Source code in <code>clean_code/setofpoints.py</code> <pre><code>def __getitem__(self, index):\n\t\"\"\"\n\tAllows indexing into the dataset.\n\n\tArgs:\n\t\tindex (int): Index of the desired data point.\n\n\tReturns:\n\t\tnp.ndarray: The data point at the given index.\n\t\"\"\"\n\treturn self.points[index]\n</code></pre>"},{"location":"reference/#clean_code.setofpoints.SetOfPoints.__init__","title":"<code>__init__(points, weights=None)</code>","text":"<p>Initializes a SetOfPoints instance.</p> <p>Parameters:</p> Name Type Description Default <code>points</code> <code>ndarray</code> <p>A (n, d) array of n points in d-dimensional space.</p> required <code>weights</code> <code>Optional[ndarray]</code> <p>A (n,) array of weights corresponding to the points.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If points and weights have incompatible shapes.</p> Source code in <code>clean_code/setofpoints.py</code> <pre><code>def __init__(self, points: np.ndarray, weights: Optional[np.ndarray] = None):\n\t\"\"\"\n\tInitializes a SetOfPoints instance.\n\n\tArgs:\n\t\tpoints (np.ndarray): A (n, d) array of n points in d-dimensional space.\n\t\tweights (Optional[np.ndarray]): A (n,) array of weights corresponding to the points.\n\n\tRaises:\n\t\tValueError: If points and weights have incompatible shapes.\n\t\"\"\"\n\n\tif points.ndim != 2:\n\t\traise ValueError(\"Points array must be 2-dimensional (n, d).\")\n\n\t# Create weights if not given\n\tif weights is None:\n\t\tweights = np.ones(points.shape[0])\n\n\tweights /= np.sum(weights)        \n\n\tif weights.ndim != 1:\n\t\traise ValueError(\"Weights array must be 1-dimensional (n,).\")\n\tif points.shape[0] != weights.shape[0]:\n\t\traise ValueError(\"Number of points and number of weights must be the same.\")\n\n\tself.points = points\n\tself.shape = points.shape\n\tself.weights = weights\n</code></pre>"},{"location":"reference/#clean_code.setofpoints.SetOfPoints.__len__","title":"<code>__len__()</code>","text":"<p>Returns the number of points in the set.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Number of points.</p> Source code in <code>clean_code/setofpoints.py</code> <pre><code>def __len__(self) -&gt; int:\n\t\"\"\"\n\tReturns the number of points in the set.\n\n\tReturns:\n\t\tint: Number of points.\n\t\"\"\"\n\treturn self.points.shape[0]\n</code></pre>"},{"location":"reference/#clean_code.setofpoints.SetOfPoints.__setitem__","title":"<code>__setitem__(index, value)</code>","text":"<p>Sets a value in the dataset at a specified index.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>int</code> <p>The index to modify.</p> required <code>value</code> <code>Any</code> <p>The new value to set.</p> required Source code in <code>clean_code/setofpoints.py</code> <pre><code>def __setitem__(self, index, value):\n\t\"\"\"\n\tSets a value in the dataset at a specified index.\n\n\tArgs:\n\t\tindex (int): The index to modify.\n\t\tvalue (Any): The new value to set.\n\t\"\"\"\n\tself.points[index] = value\n</code></pre>"},{"location":"reference/#clean_code.setofpoints.SetOfPoints.dimension","title":"<code>dimension()</code>","text":"<p>Returns the dimensionality of the points.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The dimension (d) of each point.</p> Source code in <code>clean_code/setofpoints.py</code> <pre><code>def dimension(self) -&gt; int:\n\t\"\"\"\n\tReturns the dimensionality of the points.\n\n\tReturns:\n\t\tint: The dimension (d) of each point.\n\t\"\"\"\n\treturn self.points.shape[1]\n</code></pre>"},{"location":"reference/#clean_code.setofpoints.SetOfPoints.get_point","title":"<code>get_point(index)</code>","text":"<p>Returns a specific point and its weight.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>int</code> <p>Index of the point to retrieve.</p> required <p>Returns:</p> Type Description <code>Tuple[ndarray, float]</code> <p>Tuple[np.ndarray, float]: A tuple containing the point (1D array) and its weight.</p> Source code in <code>clean_code/setofpoints.py</code> <pre><code>def get_point(self, index: int) -&gt; Tuple[np.ndarray, float]:\n\t\"\"\"\n\tReturns a specific point and its weight.\n\n\tArgs:\n\t\tindex (int): Index of the point to retrieve.\n\n\tReturns:\n\t\tTuple[np.ndarray, float]: A tuple containing the point (1D array) and its weight.\n\t\"\"\"\n\treturn self.points[index], self.weights[index]\n</code></pre>"},{"location":"reference/#clean_code.setofpoints.SetOfPoints.normalize_weights","title":"<code>normalize_weights()</code>","text":"<p>Normalizes the weights so that they sum to 1.</p> Source code in <code>clean_code/setofpoints.py</code> <pre><code>def normalize_weights(self) -&gt; None:\n\t\"\"\"\n\tNormalizes the weights so that they sum to 1.\n\t\"\"\"\n\ttotal = np.sum(self.weights)\n\tif total == 0:\n\t\traise ValueError(\"Total weight is zero. Cannot normalize.\")\n\tself.weights = self.weights / total\n</code></pre>"},{"location":"reference/#clean_code.setofpoints.SetOfPoints.subset","title":"<code>subset(indices)</code>","text":"<p>Returns a new SetOfPoints object containing only the selected indices.</p> <p>Parameters:</p> Name Type Description Default <code>indices</code> <code>ndarray</code> <p>An array of indices to include in the new subset.</p> required <p>Returns:</p> Name Type Description <code>SetOfPoints</code> <code>SetOfPoints</code> <p>A new SetOfPoints object with selected points and weights.</p> Source code in <code>clean_code/setofpoints.py</code> <pre><code>def subset(self, indices: np.ndarray) -&gt; \"SetOfPoints\":\n\t\"\"\"\n\tReturns a new SetOfPoints object containing only the selected indices.\n\n\tArgs:\n\t\tindices (np.ndarray): An array of indices to include in the new subset.\n\n\tReturns:\n\t\tSetOfPoints: A new SetOfPoints object with selected points and weights.\n\t\"\"\"\n\treturn SetOfPoints(self.points[indices], self.weights[indices])\n</code></pre>"},{"location":"reference/#clean_code.landmark.Landmark","title":"<code>Landmark</code>","text":"<p>Represents a location in the dataset where a voltage will be applied.</p> <p>The <code>index</code> can refer either to an individual datapoint or a partition center.</p> Source code in <code>clean_code/landmark.py</code> <pre><code>class Landmark:\n\t\"\"\"\n\tRepresents a location in the dataset where a voltage will be applied.\n\n\tThe `index` can refer either to an individual datapoint or a partition center.\n\t\"\"\"\n\n\tdef __init__(self, index: int, voltage: float) -&gt; None:\n\t\t\"\"\"\n\t\tInitializes a Landmark.\n\n\t\tArgs:\n\t\t\tindex (int): Index of the datapoint or partition center.\n\t\t\tvoltage (float): Voltage to be applied at the specified index.\n\t\t\"\"\"\n\t\tself.index = index\n\t\tself.voltage = voltage\n\n\t@staticmethod\n\tdef createLandmarkClosestTo(\n\t\tdata: List[Any],\n\t\tpoint: Any,\n\t\tvoltage: float,\n\t\tdistanceFn: Optional[object] = None,\n\t\tignore: List[int] = []\n\t) -&gt; \"Landmark\":\n\t\t\"\"\"\n\t\tCreates a Landmark at the index of the datapoint in `data` closest to `point`.\n\n\t\tArgs:\n\t\t\tdata (List[Any]): The dataset to search over.\n\t\t\tpoint (Any): The reference point to find the closest datapoint to.\n\t\t\tvoltage (float): The voltage to assign to the resulting Landmark.\n\t\t\tignore (List[int], optional): List of indices to skip during the search. Defaults to empty list.\n\n\t\tReturns:\n\t\t\tLandmark: A Landmark instance corresponding to the closest datapoint.\n\t\t\"\"\"\n\n\t\tmost_central_index = 0\n\t\tmindist = np.linalg.norm(data[0] - point)\n\n\t\tfor index in range(1, len(data)):\n\t\t\tif index in ignore:\n\t\t\t\tcontinue\n\n\t\t\tdist = np.linalg.norm(data[index] - point)\n\t\t\tif dist &lt; mindist:\n\t\t\t\tmost_central_index = index\n\t\t\t\tmindist = dist\n\n\t\treturn Landmark(most_central_index, voltage)\n</code></pre>"},{"location":"reference/#clean_code.landmark.Landmark.__init__","title":"<code>__init__(index, voltage)</code>","text":"<p>Initializes a Landmark.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>int</code> <p>Index of the datapoint or partition center.</p> required <code>voltage</code> <code>float</code> <p>Voltage to be applied at the specified index.</p> required Source code in <code>clean_code/landmark.py</code> <pre><code>def __init__(self, index: int, voltage: float) -&gt; None:\n\t\"\"\"\n\tInitializes a Landmark.\n\n\tArgs:\n\t\tindex (int): Index of the datapoint or partition center.\n\t\tvoltage (float): Voltage to be applied at the specified index.\n\t\"\"\"\n\tself.index = index\n\tself.voltage = voltage\n</code></pre>"},{"location":"reference/#clean_code.landmark.Landmark.createLandmarkClosestTo","title":"<code>createLandmarkClosestTo(data, point, voltage, distanceFn=None, ignore=[])</code>  <code>staticmethod</code>","text":"<p>Creates a Landmark at the index of the datapoint in <code>data</code> closest to <code>point</code>.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>List[Any]</code> <p>The dataset to search over.</p> required <code>point</code> <code>Any</code> <p>The reference point to find the closest datapoint to.</p> required <code>voltage</code> <code>float</code> <p>The voltage to assign to the resulting Landmark.</p> required <code>ignore</code> <code>List[int]</code> <p>List of indices to skip during the search. Defaults to empty list.</p> <code>[]</code> <p>Returns:</p> Name Type Description <code>Landmark</code> <code>Landmark</code> <p>A Landmark instance corresponding to the closest datapoint.</p> Source code in <code>clean_code/landmark.py</code> <pre><code>@staticmethod\ndef createLandmarkClosestTo(\n\tdata: List[Any],\n\tpoint: Any,\n\tvoltage: float,\n\tdistanceFn: Optional[object] = None,\n\tignore: List[int] = []\n) -&gt; \"Landmark\":\n\t\"\"\"\n\tCreates a Landmark at the index of the datapoint in `data` closest to `point`.\n\n\tArgs:\n\t\tdata (List[Any]): The dataset to search over.\n\t\tpoint (Any): The reference point to find the closest datapoint to.\n\t\tvoltage (float): The voltage to assign to the resulting Landmark.\n\t\tignore (List[int], optional): List of indices to skip during the search. Defaults to empty list.\n\n\tReturns:\n\t\tLandmark: A Landmark instance corresponding to the closest datapoint.\n\t\"\"\"\n\n\tmost_central_index = 0\n\tmindist = np.linalg.norm(data[0] - point)\n\n\tfor index in range(1, len(data)):\n\t\tif index in ignore:\n\t\t\tcontinue\n\n\t\tdist = np.linalg.norm(data[index] - point)\n\t\tif dist &lt; mindist:\n\t\t\tmost_central_index = index\n\t\t\tmindist = dist\n\n\treturn Landmark(most_central_index, voltage)\n</code></pre>"},{"location":"reference/#clean_code.problem.Problem","title":"<code>Problem</code>","text":"<p>Represents a kernel-based resistance model over a set of points with grounding.</p> <p>Attributes:</p> Name Type Description <code>points</code> <code>SetOfPoints</code> <p>The points object.</p> <code>c</code> <code>float</code> <p>Kernel width parameter used in the Gaussian kernel.</p> <code>r</code> <code>float</code> <p>Resistance to ground.</p> Source code in <code>clean_code/problem.py</code> <pre><code>class Problem:\n\t\"\"\"\n\tRepresents a kernel-based resistance model over a set of points with grounding.\n\n\tAttributes:\n\t\tpoints (SetOfPoints): The points object.\n\t\tlandmarks (List[Landmark])\n\t\tc (float): Kernel width parameter used in the Gaussian kernel.\n\t\tr (float): Resistance to ground.\n\t\"\"\"\n\n\tdef __init__(self, points: setofpoints.SetOfPoints, r: float):\n\t\t\"\"\"\n\t\tInitializes a Problem instance.\n\n\t\tArgs:\n\t\t\tpoints (np.ndarray): A (n, d) array of points.\n\t\t\tr (float): Resistance to the ground.\n\n\t\tRaises:\n\t\t\tValueError: If input dimensions are incorrect or parameters are non-positive.\n\t\t\"\"\"\n\t\tif r &lt;= 0:\n\t\t\traise ValueError(\"Ground resistance (r) must be positive.\")\n\n\t\tself.points = points\n\t\tself.r = r\n\n\tdef calcResistanceMatrix(self, k: int = 10, universalGround: bool = True) -&gt; np.ndarray:\n\t\t\"\"\"\n\t\tCalculates the (n+1)x(n+1) row-normalized resistance matrix using k-nearest neighbors.\n\n\t\tArgs:\n\t\t\tk (int): Number of nearest neighbors for sparse approximation.\n\t\t\tsparse (bool): Whether to return a sparse matrix.\n\n\t\tReturns:\n\t\t\tnp.ndarray: (n+1)x(n+1) resistance matrix with rows summing to 1.\n\t\t\"\"\"\n\n\t\tX = self.points.points\t\t\t\t\t\t\t# shape (n, d)\n\t\tn = X.shape[0]\n\n\t\t# k-NN search (k+1 because the first neighbor is the point itself)\n\t\tnbrs = NearestNeighbors(n_neighbors=k + 1, algorithm='auto').fit(X)\n\t\t_, indices = nbrs.kneighbors(X)\n\n\t\t# Dense kernel (n \u00d7 n)\n\t\tkernel = np.zeros((n, n), dtype=float)\n\t\tweight = 1.0 / k\n\n\t\tfor i in range(n):\n\t\t\tfor j in indices[i][1:]:\t\t\t\t\t# skip the point itself\n\t\t\t\tkernel[i, j] = weight * self.points.weights[i] * self.points.weights[j] \n\t\t\t\tkernel[j, i] = weight * self.points.weights[j] * self.points.weights[i]\t# keep it symmetric\n\n\t\t# Constant connection to the ground node\n\t\tif (universalGround):\n\t\t\tconnectivity = kernel.sum() / (self.r * n * n)\n\t\t\tground_col = np.full((n, 1), connectivity, dtype=float)\n\t\t\tground_row = ground_col.T\t\t\t\t\t\t# (1 \u00d7 n)\n\n\t\t\t# Assemble full (n+1) \u00d7 (n+1) matrix\n\t\t\ttop    = np.hstack((kernel, ground_col))\t\t# (n \u00d7 (n+1))\n\t\t\tbottom = np.hstack((ground_row, [[0]]))\n\t\t\tfull   = np.vstack((top, bottom))\t\t\t\t# ((n+1) \u00d7 (n+1))\n\t\telse:\n\t\t\tfull = kernel\n\n\t\t# Normalize so each row sums to 0 with diagonals 1\n\t\trow_sums = full.sum(axis=1, keepdims=True)\n\t\tweights = full / row_sums\n\t\treturn np.identity(weights.shape[0]) - weights\n\n\tdef optimize(self, \n\t\ttarget_avg_voltage: float = 0.1, \n\t\taccuracy: float = 0.1, \n\t\tradius: int = 3, \n\t\tr_min: float = 0.01, \n\t\tr_max: float = 100, \n\t\tmax_iter: int = 30):\n\t\t\"\"\"\n\t\tFinds the value of r (ground resistance) that makes the average voltage within a given radius\n\t\tas close as possible to the target average voltage, using binary search.\n\n\t\tArgs:\n\t\t\ttarget_avg_voltage (float): The target average voltage in the neighborhood.\n\t\t\taccuracy (float): Relative accuracy for stopping criterion.\n\t\t\tradius (int): Number of graph hops within which to compute the average voltage.\n\t\t\tr_min (float): Minimum r value to consider.\n\t\t\tr_max (float): Maximum r value to consider.\n\t\t\tmax_iter (int): Maximum number of binary search iterations.\n\t\t\"\"\"\n\t\t# Build resistance graph once (exclude ground node)\n\t\tR = self.calcResistanceMatrix()\n\t\tG = nx.from_numpy_array(R[:-1, :-1])  # Exclude ground node for graph connectivity\n\n\t\t# Find all nodes within 'radius' hops of the landmark\n\t\tindices = []\n\t\tfor landmark in self.landmarks:\n\t\t\tlengths = nx.single_source_shortest_path_length(G, landmark.index, cutoff=radius)\n\t\t\tindices.extend(list(lengths.keys()))\n\n\t\tindices = np.array(indices)\n\n\t\tbest_r = None\n\t\tbest_loss = float('inf')\n\t\tleft, right = r_min, r_max\n\n\t\tfor i in range(max_iter):\n\t\t\tr_try = np.exp((np.log(left) + np.log(right)) / 2)\n\t\t\tself.r = r_try  # Update problem resistance\n\n\t\t\tvolt_solver = solver.Solver(self)\n\t\t\tvoltages = volt_solver.compute_voltages(self.landmarks)\n\t\t\tneighborhood_avg = np.mean(voltages[indices])\n\t\t\trel_error = abs(neighborhood_avg - target_avg_voltage) / abs(target_avg_voltage)\n\n\t\t\tif rel_error &lt; best_loss:\n\t\t\t\tbest_loss = rel_error\n\t\t\t\tbest_r = r_try\n\n\t\t\tif rel_error &lt; accuracy:\n\t\t\t\tbreak\n\n\t\t\tif neighborhood_avg &gt; target_avg_voltage:\n\t\t\t\tleft = r_try\n\t\t\telse:\n\t\t\t\tright = r_try\n\n\t\tself.r = best_r\n</code></pre>"},{"location":"reference/#clean_code.problem.Problem.__init__","title":"<code>__init__(points, r)</code>","text":"<p>Initializes a Problem instance.</p> <p>Parameters:</p> Name Type Description Default <code>points</code> <code>ndarray</code> <p>A (n, d) array of points.</p> required <code>r</code> <code>float</code> <p>Resistance to the ground.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If input dimensions are incorrect or parameters are non-positive.</p> Source code in <code>clean_code/problem.py</code> <pre><code>def __init__(self, points: setofpoints.SetOfPoints, r: float):\n\t\"\"\"\n\tInitializes a Problem instance.\n\n\tArgs:\n\t\tpoints (np.ndarray): A (n, d) array of points.\n\t\tr (float): Resistance to the ground.\n\n\tRaises:\n\t\tValueError: If input dimensions are incorrect or parameters are non-positive.\n\t\"\"\"\n\tif r &lt;= 0:\n\t\traise ValueError(\"Ground resistance (r) must be positive.\")\n\n\tself.points = points\n\tself.r = r\n</code></pre>"},{"location":"reference/#clean_code.problem.Problem.calcResistanceMatrix","title":"<code>calcResistanceMatrix(k=10, universalGround=True)</code>","text":"<p>Calculates the (n+1)x(n+1) row-normalized resistance matrix using k-nearest neighbors.</p> <p>Parameters:</p> Name Type Description Default <code>k</code> <code>int</code> <p>Number of nearest neighbors for sparse approximation.</p> <code>10</code> <code>sparse</code> <code>bool</code> <p>Whether to return a sparse matrix.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: (n+1)x(n+1) resistance matrix with rows summing to 1.</p> Source code in <code>clean_code/problem.py</code> <pre><code>def calcResistanceMatrix(self, k: int = 10, universalGround: bool = True) -&gt; np.ndarray:\n\t\"\"\"\n\tCalculates the (n+1)x(n+1) row-normalized resistance matrix using k-nearest neighbors.\n\n\tArgs:\n\t\tk (int): Number of nearest neighbors for sparse approximation.\n\t\tsparse (bool): Whether to return a sparse matrix.\n\n\tReturns:\n\t\tnp.ndarray: (n+1)x(n+1) resistance matrix with rows summing to 1.\n\t\"\"\"\n\n\tX = self.points.points\t\t\t\t\t\t\t# shape (n, d)\n\tn = X.shape[0]\n\n\t# k-NN search (k+1 because the first neighbor is the point itself)\n\tnbrs = NearestNeighbors(n_neighbors=k + 1, algorithm='auto').fit(X)\n\t_, indices = nbrs.kneighbors(X)\n\n\t# Dense kernel (n \u00d7 n)\n\tkernel = np.zeros((n, n), dtype=float)\n\tweight = 1.0 / k\n\n\tfor i in range(n):\n\t\tfor j in indices[i][1:]:\t\t\t\t\t# skip the point itself\n\t\t\tkernel[i, j] = weight * self.points.weights[i] * self.points.weights[j] \n\t\t\tkernel[j, i] = weight * self.points.weights[j] * self.points.weights[i]\t# keep it symmetric\n\n\t# Constant connection to the ground node\n\tif (universalGround):\n\t\tconnectivity = kernel.sum() / (self.r * n * n)\n\t\tground_col = np.full((n, 1), connectivity, dtype=float)\n\t\tground_row = ground_col.T\t\t\t\t\t\t# (1 \u00d7 n)\n\n\t\t# Assemble full (n+1) \u00d7 (n+1) matrix\n\t\ttop    = np.hstack((kernel, ground_col))\t\t# (n \u00d7 (n+1))\n\t\tbottom = np.hstack((ground_row, [[0]]))\n\t\tfull   = np.vstack((top, bottom))\t\t\t\t# ((n+1) \u00d7 (n+1))\n\telse:\n\t\tfull = kernel\n\n\t# Normalize so each row sums to 0 with diagonals 1\n\trow_sums = full.sum(axis=1, keepdims=True)\n\tweights = full / row_sums\n\treturn np.identity(weights.shape[0]) - weights\n</code></pre>"},{"location":"reference/#clean_code.problem.Problem.optimize","title":"<code>optimize(target_avg_voltage=0.1, accuracy=0.1, radius=3, r_min=0.01, r_max=100, max_iter=30)</code>","text":"<p>Finds the value of r (ground resistance) that makes the average voltage within a given radius as close as possible to the target average voltage, using binary search.</p> <p>Parameters:</p> Name Type Description Default <code>target_avg_voltage</code> <code>float</code> <p>The target average voltage in the neighborhood.</p> <code>0.1</code> <code>accuracy</code> <code>float</code> <p>Relative accuracy for stopping criterion.</p> <code>0.1</code> <code>radius</code> <code>int</code> <p>Number of graph hops within which to compute the average voltage.</p> <code>3</code> <code>r_min</code> <code>float</code> <p>Minimum r value to consider.</p> <code>0.01</code> <code>r_max</code> <code>float</code> <p>Maximum r value to consider.</p> <code>100</code> <code>max_iter</code> <code>int</code> <p>Maximum number of binary search iterations.</p> <code>30</code> Source code in <code>clean_code/problem.py</code> <pre><code>def optimize(self, \n\ttarget_avg_voltage: float = 0.1, \n\taccuracy: float = 0.1, \n\tradius: int = 3, \n\tr_min: float = 0.01, \n\tr_max: float = 100, \n\tmax_iter: int = 30):\n\t\"\"\"\n\tFinds the value of r (ground resistance) that makes the average voltage within a given radius\n\tas close as possible to the target average voltage, using binary search.\n\n\tArgs:\n\t\ttarget_avg_voltage (float): The target average voltage in the neighborhood.\n\t\taccuracy (float): Relative accuracy for stopping criterion.\n\t\tradius (int): Number of graph hops within which to compute the average voltage.\n\t\tr_min (float): Minimum r value to consider.\n\t\tr_max (float): Maximum r value to consider.\n\t\tmax_iter (int): Maximum number of binary search iterations.\n\t\"\"\"\n\t# Build resistance graph once (exclude ground node)\n\tR = self.calcResistanceMatrix()\n\tG = nx.from_numpy_array(R[:-1, :-1])  # Exclude ground node for graph connectivity\n\n\t# Find all nodes within 'radius' hops of the landmark\n\tindices = []\n\tfor landmark in self.landmarks:\n\t\tlengths = nx.single_source_shortest_path_length(G, landmark.index, cutoff=radius)\n\t\tindices.extend(list(lengths.keys()))\n\n\tindices = np.array(indices)\n\n\tbest_r = None\n\tbest_loss = float('inf')\n\tleft, right = r_min, r_max\n\n\tfor i in range(max_iter):\n\t\tr_try = np.exp((np.log(left) + np.log(right)) / 2)\n\t\tself.r = r_try  # Update problem resistance\n\n\t\tvolt_solver = solver.Solver(self)\n\t\tvoltages = volt_solver.compute_voltages(self.landmarks)\n\t\tneighborhood_avg = np.mean(voltages[indices])\n\t\trel_error = abs(neighborhood_avg - target_avg_voltage) / abs(target_avg_voltage)\n\n\t\tif rel_error &lt; best_loss:\n\t\t\tbest_loss = rel_error\n\t\t\tbest_r = r_try\n\n\t\tif rel_error &lt; accuracy:\n\t\t\tbreak\n\n\t\tif neighborhood_avg &gt; target_avg_voltage:\n\t\t\tleft = r_try\n\t\telse:\n\t\t\tright = r_try\n\n\tself.r = best_r\n</code></pre>"},{"location":"reference/#clean_code.solver.Solver","title":"<code>Solver</code>","text":"<p>Solves for voltage distributions across a set of points in a resistance network.</p> <p>Given a problem with defined resistances and a set of landmarks with fixed voltages, this class computes the approximate voltages at all other points.</p> <p>Attributes:</p> Name Type Description <code>problem</code> <code>Problem</code> <p>The resistance network model.</p> Source code in <code>clean_code/solver.py</code> <pre><code>class Solver:\n\t\"\"\"\n\tSolves for voltage distributions across a set of points in a resistance network.\n\n\tGiven a problem with defined resistances and a set of landmarks with fixed voltages,\n\tthis class computes the approximate voltages at all other points.\n\n\tAttributes:\n\t\tproblem (Problem): The resistance network model.\n\t\"\"\"\n\n\tdef __init__(self, problem: problem.Problem):\n\t\t\"\"\"\n\t\tInitializes the solver with a given problem.\n\n\t\tArgs:\n\t\t\tproblem (Problem): The problem instance defining the resistance matrix.\n\t\t\"\"\"\n\t\tself.problem = problem\n\n\tdef compute_voltages(self, landmarks: List[\"Landmark\"], k: int = 10, universalGround: bool = True):\n\t\t\"\"\"\n\t\tComputes and returns the voltages for the given problem\n\n\t\tArgs:\n\t\t\tlandmarks (List[\"Landmark\"]): The landmarks to consider when computing voltages\n\n\t\tReturns:\n\t\t\tvoltages (List[float]): The voltages corresponding to each point in set of points\n\t\t\"\"\"\n\n\t\tweights = self.problem.calcResistanceMatrix(k, universalGround)\n\t\tn = weights.shape[0]\n\n\t\tif (universalGround):\n\t\t\tlandmarks.append(landmark.Landmark(n - 1, 0))\n\n\t\tconstrained_nodes =   [l.index for l in landmarks]\n\t\tunconstrained_nodes = [i for i in range(n) if i not in constrained_nodes]\n\n\t\tb = np.zeros(n)\n\t\tfor lm in landmarks:\n\t\t\tfor y in range(0, n):\n\t\t\t\tb[y] -= lm.voltage * weights[y][lm.index]\n\n\t\tA_unconstrained = weights[np.ix_(unconstrained_nodes, unconstrained_nodes)]\n\t\tb_unconstrained = b[unconstrained_nodes]\n\n\t\t# print(A_unconstrained, b_unconstrained)\n\n\t\tv_unconstrained = solve(A_unconstrained, b_unconstrained)\n\n\t\tself.voltages = np.zeros(n)\n\n\t\tfor lm in landmarks:\n\t\t\tself.voltages[lm.index] = lm.voltage\n\n\t\tself.voltages[unconstrained_nodes] = v_unconstrained\n\n\t\tif (universalGround):\n\t\t\tself.voltages = self.voltages[:-1]\n\n\t\treturn self.voltages\n</code></pre>"},{"location":"reference/#clean_code.solver.Solver.__init__","title":"<code>__init__(problem)</code>","text":"<p>Initializes the solver with a given problem.</p> <p>Parameters:</p> Name Type Description Default <code>problem</code> <code>Problem</code> <p>The problem instance defining the resistance matrix.</p> required Source code in <code>clean_code/solver.py</code> <pre><code>def __init__(self, problem: problem.Problem):\n\t\"\"\"\n\tInitializes the solver with a given problem.\n\n\tArgs:\n\t\tproblem (Problem): The problem instance defining the resistance matrix.\n\t\"\"\"\n\tself.problem = problem\n</code></pre>"},{"location":"reference/#clean_code.solver.Solver.compute_voltages","title":"<code>compute_voltages(landmarks, k=10, universalGround=True)</code>","text":"<p>Computes and returns the voltages for the given problem</p> <p>Parameters:</p> Name Type Description Default <code>landmarks</code> <code>List[Landmark]</code> <p>The landmarks to consider when computing voltages</p> required <p>Returns:</p> Name Type Description <code>voltages</code> <code>List[float]</code> <p>The voltages corresponding to each point in set of points</p> Source code in <code>clean_code/solver.py</code> <pre><code>def compute_voltages(self, landmarks: List[\"Landmark\"], k: int = 10, universalGround: bool = True):\n\t\"\"\"\n\tComputes and returns the voltages for the given problem\n\n\tArgs:\n\t\tlandmarks (List[\"Landmark\"]): The landmarks to consider when computing voltages\n\n\tReturns:\n\t\tvoltages (List[float]): The voltages corresponding to each point in set of points\n\t\"\"\"\n\n\tweights = self.problem.calcResistanceMatrix(k, universalGround)\n\tn = weights.shape[0]\n\n\tif (universalGround):\n\t\tlandmarks.append(landmark.Landmark(n - 1, 0))\n\n\tconstrained_nodes =   [l.index for l in landmarks]\n\tunconstrained_nodes = [i for i in range(n) if i not in constrained_nodes]\n\n\tb = np.zeros(n)\n\tfor lm in landmarks:\n\t\tfor y in range(0, n):\n\t\t\tb[y] -= lm.voltage * weights[y][lm.index]\n\n\tA_unconstrained = weights[np.ix_(unconstrained_nodes, unconstrained_nodes)]\n\tb_unconstrained = b[unconstrained_nodes]\n\n\t# print(A_unconstrained, b_unconstrained)\n\n\tv_unconstrained = solve(A_unconstrained, b_unconstrained)\n\n\tself.voltages = np.zeros(n)\n\n\tfor lm in landmarks:\n\t\tself.voltages[lm.index] = lm.voltage\n\n\tself.voltages[unconstrained_nodes] = v_unconstrained\n\n\tif (universalGround):\n\t\tself.voltages = self.voltages[:-1]\n\n\treturn self.voltages\n</code></pre>"},{"location":"reference/#clean_code.voltagemap.VoltageMap","title":"<code>VoltageMap</code>","text":"<p>Represents a collection of voltage solutions (voltage maps), one for each landmark.</p> <p>Each voltage map corresponds to the solution from applying a Solver to a Problem with a specific Landmark.</p> Source code in <code>clean_code/voltagemap.py</code> <pre><code>class VoltageMap:\n\t\"\"\"\n\tRepresents a collection of voltage solutions (voltage maps), one for each landmark.\n\n\tEach voltage map corresponds to the solution from applying a Solver to a Problem with a specific Landmark.\n\t\"\"\"\n\n\tdef __init__(self) -&gt; None:\n\t\t\"\"\"\n\t\tInitializes an empty Map.\n\t\t\"\"\"\n\t\tself.voltage_maps: List[np.ndarray] = []\t\t# Maps landmark index to voltage array\n\t\tself.landmarks: List[landmark.Landmark] = []\t# Ordered list of landmarks\n\t\tself.shape: tuple = ()\n\n\tdef add_solution(self, landmark_index: landmark.Landmark, voltages: np.ndarray) -&gt; None:\n\t\t\"\"\"\n\t\tAdds a voltage map corresponding to a specific landmark.\n\n\t\tArgs:\n\t\t\tlandmark_index (Landmark): The landmark used in the problem.\n\t\t\tvoltages (np.ndarray): The computed voltage map for that landmark.\n\t\t\"\"\"\n\t\tself.voltage_maps.append(voltages)\n\t\tself.landmarks.append(landmark_index)\n\t\tif not self.shape:\n\t\t\tself.shape = voltages.shape\n\n\tdef get_solution(self, landmark_index: int) -&gt; np.ndarray:\n\t\t\"\"\"\n\t\tRetrieves the voltage map for a specific landmark.\n\n\t\tArgs:\n\t\t\tlandmark_index (int): Index of the desired landmark.\n\n\t\tReturns:\n\t\t\tnp.ndarray: The voltage map.\n\t\t\"\"\"\n\t\treturn self.voltage_maps[landmark_index]\n\n\tdef all_solutions(self) -&gt; np.ndarray:\n\t\t\"\"\"\n\t\tRetrieves all voltage maps as a stacked 2D array (landmarks x points).\n\n\t\tReturns:\n\t\t\tnp.ndarray: 2D array of shape (num_landmarks, num_points)\n\t\t\"\"\"\n\t\treturn np.stack([self.voltage_maps[lm] for lm in self.landmarks], axis=0)\n\n\tdef __len__(self) -&gt; int:\n\t\treturn len(self.voltage_maps)\n\n\tdef __iter__(self):\n\t\t\"\"\"\n\t\tReturns an iterator over the dataset for use in for-loops.\n\n\t\tReturns:\n\t\t\tIterator: An iterator over the dataset.\n\t\t\"\"\"\n\t\tself.index = -1\n\n\t\treturn self\n\n\tdef __next__(self):\n\t\t\"\"\"\n\t\tRetrieves the next voltage list in an iteration.\n\n\t\tReturns:\n\t\t\tList[np.ndarray]: The next voltage list.\n\n\t\tRaises:\n\t\t\tStopIteration: If the end of the map is reached.\n\t\t\"\"\"\n\t\tif (self.index + 1 == len(self.voltage_maps)):\n\t\t\traise StopIteration\n\t\telse:\n\t\t\tself.index += 1\n\t\t\treturn self.voltage_maps[self.index]\n\n\t@staticmethod\n\tdef from_problem_and_landmarks(problem: problem.Problem, landmarks: List[landmark.Landmark], solver_cls: solver.Solver) -&gt; \"Map\":\n\t\t\"\"\"\n\t\tConstructs a Map by solving the Problem for each landmark.\n\n\t\tArgs:\n\t\t\tproblem: An instance of a Problem class.\n\t\t\tlandmarks (List[Landmark]): List of Landmark instances.\n\t\t\tsolver_cls: A Solver class that takes a problem and a landmark.\n\n\t\tReturns:\n\t\t\tMap: A populated Map instance.\n\t\t\"\"\"\n\t\tvoltage_map = Map()\n\t\tfor landmark in landmarks:\n\t\t\tsolver = solver_cls(problem, landmark)\n\t\t\tvoltages = solver.approximate_voltages()\n\t\t\tvoltage_map.add_solution(landmark.index, voltages)\n\t\treturn voltage_map\n</code></pre>"},{"location":"reference/#clean_code.voltagemap.VoltageMap.__init__","title":"<code>__init__()</code>","text":"<p>Initializes an empty Map.</p> Source code in <code>clean_code/voltagemap.py</code> <pre><code>def __init__(self) -&gt; None:\n\t\"\"\"\n\tInitializes an empty Map.\n\t\"\"\"\n\tself.voltage_maps: List[np.ndarray] = []\t\t# Maps landmark index to voltage array\n\tself.landmarks: List[landmark.Landmark] = []\t# Ordered list of landmarks\n\tself.shape: tuple = ()\n</code></pre>"},{"location":"reference/#clean_code.voltagemap.VoltageMap.__iter__","title":"<code>__iter__()</code>","text":"<p>Returns an iterator over the dataset for use in for-loops.</p> <p>Returns:</p> Name Type Description <code>Iterator</code> <p>An iterator over the dataset.</p> Source code in <code>clean_code/voltagemap.py</code> <pre><code>def __iter__(self):\n\t\"\"\"\n\tReturns an iterator over the dataset for use in for-loops.\n\n\tReturns:\n\t\tIterator: An iterator over the dataset.\n\t\"\"\"\n\tself.index = -1\n\n\treturn self\n</code></pre>"},{"location":"reference/#clean_code.voltagemap.VoltageMap.__next__","title":"<code>__next__()</code>","text":"<p>Retrieves the next voltage list in an iteration.</p> <p>Returns:</p> Type Description <p>List[np.ndarray]: The next voltage list.</p> <p>Raises:</p> Type Description <code>StopIteration</code> <p>If the end of the map is reached.</p> Source code in <code>clean_code/voltagemap.py</code> <pre><code>def __next__(self):\n\t\"\"\"\n\tRetrieves the next voltage list in an iteration.\n\n\tReturns:\n\t\tList[np.ndarray]: The next voltage list.\n\n\tRaises:\n\t\tStopIteration: If the end of the map is reached.\n\t\"\"\"\n\tif (self.index + 1 == len(self.voltage_maps)):\n\t\traise StopIteration\n\telse:\n\t\tself.index += 1\n\t\treturn self.voltage_maps[self.index]\n</code></pre>"},{"location":"reference/#clean_code.voltagemap.VoltageMap.add_solution","title":"<code>add_solution(landmark_index, voltages)</code>","text":"<p>Adds a voltage map corresponding to a specific landmark.</p> <p>Parameters:</p> Name Type Description Default <code>landmark_index</code> <code>Landmark</code> <p>The landmark used in the problem.</p> required <code>voltages</code> <code>ndarray</code> <p>The computed voltage map for that landmark.</p> required Source code in <code>clean_code/voltagemap.py</code> <pre><code>def add_solution(self, landmark_index: landmark.Landmark, voltages: np.ndarray) -&gt; None:\n\t\"\"\"\n\tAdds a voltage map corresponding to a specific landmark.\n\n\tArgs:\n\t\tlandmark_index (Landmark): The landmark used in the problem.\n\t\tvoltages (np.ndarray): The computed voltage map for that landmark.\n\t\"\"\"\n\tself.voltage_maps.append(voltages)\n\tself.landmarks.append(landmark_index)\n\tif not self.shape:\n\t\tself.shape = voltages.shape\n</code></pre>"},{"location":"reference/#clean_code.voltagemap.VoltageMap.all_solutions","title":"<code>all_solutions()</code>","text":"<p>Retrieves all voltage maps as a stacked 2D array (landmarks x points).</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: 2D array of shape (num_landmarks, num_points)</p> Source code in <code>clean_code/voltagemap.py</code> <pre><code>def all_solutions(self) -&gt; np.ndarray:\n\t\"\"\"\n\tRetrieves all voltage maps as a stacked 2D array (landmarks x points).\n\n\tReturns:\n\t\tnp.ndarray: 2D array of shape (num_landmarks, num_points)\n\t\"\"\"\n\treturn np.stack([self.voltage_maps[lm] for lm in self.landmarks], axis=0)\n</code></pre>"},{"location":"reference/#clean_code.voltagemap.VoltageMap.from_problem_and_landmarks","title":"<code>from_problem_and_landmarks(problem, landmarks, solver_cls)</code>  <code>staticmethod</code>","text":"<p>Constructs a Map by solving the Problem for each landmark.</p> <p>Parameters:</p> Name Type Description Default <code>problem</code> <code>Problem</code> <p>An instance of a Problem class.</p> required <code>landmarks</code> <code>List[Landmark]</code> <p>List of Landmark instances.</p> required <code>solver_cls</code> <code>Solver</code> <p>A Solver class that takes a problem and a landmark.</p> required <p>Returns:</p> Name Type Description <code>Map</code> <code>Map</code> <p>A populated Map instance.</p> Source code in <code>clean_code/voltagemap.py</code> <pre><code>@staticmethod\ndef from_problem_and_landmarks(problem: problem.Problem, landmarks: List[landmark.Landmark], solver_cls: solver.Solver) -&gt; \"Map\":\n\t\"\"\"\n\tConstructs a Map by solving the Problem for each landmark.\n\n\tArgs:\n\t\tproblem: An instance of a Problem class.\n\t\tlandmarks (List[Landmark]): List of Landmark instances.\n\t\tsolver_cls: A Solver class that takes a problem and a landmark.\n\n\tReturns:\n\t\tMap: A populated Map instance.\n\t\"\"\"\n\tvoltage_map = Map()\n\tfor landmark in landmarks:\n\t\tsolver = solver_cls(problem, landmark)\n\t\tvoltages = solver.approximate_voltages()\n\t\tvoltage_map.add_solution(landmark.index, voltages)\n\treturn voltage_map\n</code></pre>"},{"location":"reference/#clean_code.voltagemap.VoltageMap.get_solution","title":"<code>get_solution(landmark_index)</code>","text":"<p>Retrieves the voltage map for a specific landmark.</p> <p>Parameters:</p> Name Type Description Default <code>landmark_index</code> <code>int</code> <p>Index of the desired landmark.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The voltage map.</p> Source code in <code>clean_code/voltagemap.py</code> <pre><code>def get_solution(self, landmark_index: int) -&gt; np.ndarray:\n\t\"\"\"\n\tRetrieves the voltage map for a specific landmark.\n\n\tArgs:\n\t\tlandmark_index (int): Index of the desired landmark.\n\n\tReturns:\n\t\tnp.ndarray: The voltage map.\n\t\"\"\"\n\treturn self.voltage_maps[landmark_index]\n</code></pre>"}]}