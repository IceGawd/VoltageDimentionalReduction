{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"reference/","title":"Reference","text":""},{"location":"reference/#code.bpf.BestParameterFinder","title":"<code>BestParameterFinder</code>","text":"Source code in <code>code\\bpf.py</code> <pre><code>class BestParameterFinder:\n\tdef __init__(self, metric: Optional[Callable[[\"BestParameterFinder\", np.ndarray], float]] = None):\n\t\tself.metric = metric or self.expWithStd\n\t\tself.p_g: Optional[float] = None\n\t\tself.c: Optional[float] = None\n\n\tdef nInfUniform(self, voltages: np.ndarray) -&gt; float:\n\t\tvoltages.sort()\n\t\tuniform = np.array([x / (len(voltages) - 1) for x in range(len(voltages))])\n\t\treturn np.linalg.norm(abs(voltages - uniform))\n\n\tdef nInfExp(self, voltages: np.ndarray, base: float = 10) -&gt; float:\n\t\tglobal dist\n\t\tvoltages.sort()\n\t\tif len(dist) != len(voltages):\n\t\t\tdist = np.array([np.power(base, (x / (len(voltages) - 1)) - 1) for x in range(len(voltages))])\n\t\treturn np.linalg.norm(abs(voltages - dist))\n\n\tdef median(self, voltages: np.ndarray, value: float = 0.5) -&gt; float:\n\t\tvoltages.sort()\n\t\treturn abs(voltages[int(len(voltages) / 2)] - value)\n\n\tdef minimum(self, voltages: np.ndarray, value: float = 0.1) -&gt; float:\n\t\tvoltages.sort()\n\t\treturn abs(voltages[0] - value)\n\n\tdef minWithStd(self, voltages: np.ndarray, value: float = 0.1) -&gt; float:\n\t\tvoltages.sort()\n\t\treturn abs(voltages[0] - value) / np.std(voltages)\n\n\tdef expWithStd(self, voltages: np.ndarray, base: float = 10) -&gt; float:\n\t\treturn self.nInfExp(voltages, base) / np.std(voltages)\n\n\tdef setResistanceToGround(self, p_g: float) -&gt; None:\n\t\tself.p_g = np.log(p_g)\n\n\tdef setKernelParameter(self, c: float) -&gt; None:\n\t\tself.c = np.log(c)\n\n\tdef calculateFor(\n\t\tself,\n\t\tlandmarks: List,\n\t\tdata: Union[create_data.Data, kmeans.Partitions],\n\t\tc: float,\n\t\tp_g: float,\n\t\tapprox: bool = False,\n\t\tapprox_epsilon: Optional[float] = None,\n\t\tapprox_iters: Optional[int] = None\n\t) -&gt; Union[float, tuple[np.ndarray, voltage.Problem]]:\n\n\t\tif isinstance(data, create_data.Data):\n\t\t\tmeanProblem = voltage.Problem(data)\n\t\t\tmeanProblem.timeStart()\n\t\t\tmeanProblem.setKernel(meanProblem.gaussiankernel)\n\t\t\tmeanProblem.setWeights(np.exp(c))\n\n\t\telif isinstance(data, kmeans.Partitions):\n\t\t\tpartitions = data\n\t\t\tmeanProblem = voltage.Problem(partitions.centers)\n\t\t\tmeanProblem.timeStart()\n\t\t\tmeanProblem.setKernel(meanProblem.gaussiankernel)\n\t\t\tmeanProblem.setPartitionWeights(partitions, np.exp(c))\n\n\t\telse:\n\t\t\traise ValueError(\"Unsupported data type\")\n\n\t\tmeanProblem.addUniversalGround(np.exp(p_g))\n\t\tmeanProblem.addLandmarks(landmarks)\n\n\t\tmeanProblem.timeEnd()\n\n\t\tif approx:\n\t\t\tvoltages = np.array(voltage.Solver(meanProblem).approximate_voltages(approx_epsilon, approx_iters))\n\t\telse:\n\t\t\tvoltages = np.array(voltage.Solver(meanProblem).compute_voltages())\n\n\t\tmeanProblem.timeEnd()\n\n\t\tif self.metric:\n\t\t\treturn self.metric(self, voltages)\n\t\telse:\n\t\t\treturn voltages, meanProblem\n\n\tdef bestParameterFinder(\n\t\tself,\n\t\tlandmarks: List,\n\t\tdata: Union[create_data.Data, kmeans.Partitions],\n\t\tminBound: float = -25,\n\t\tmaxBound: float = -1,\n\t\tgranularity: int = 5,\n\t\tepsilon: float = 1,\n\t\tapprox: Optional[int] = None\n\t) -&gt; tuple[float, float]:\n\t\t\"\"\"\n\t\tFinds the best parameters (C and P_G) for a solver based on voltage distribution minimization.\n\t\t\"\"\"\n\t\twindow_size = (maxBound - minBound) / 2\n\t\tbestc = minBound + window_size\n\t\tbestg = minBound + window_size\n\t\tval = float('inf')\n\n\t\twhile window_size &gt; epsilon:\n\t\t\tcs = [bestc + x * window_size / granularity for x in range(-granularity + 1, granularity)]\n\t\t\tgs = [bestg + x * window_size / granularity for x in range(-granularity + 1, granularity)]\n\n\t\t\tif self.c is not None:\n\t\t\t\tcs = [self.c]\n\t\t\tif self.p_g is not None:\n\t\t\t\tgs = [self.p_g]\n\n\t\t\tfor c in cs:\n\t\t\t\tfor g in gs:\n\t\t\t\t\ttry:\n\t\t\t\t\t\tif approx is None:\n\t\t\t\t\t\t\ttempval = self.calculateFor(landmarks, data, c, g)\n\t\t\t\t\t\telse:\n\t\t\t\t\t\t\ttempval = self.calculateFor(landmarks, data, c, g, approx=True, approx_iters=approx)\n\n\t\t\t\t\t\tif val &gt; tempval:\n\t\t\t\t\t\t\tbestc, bestg = c, g\n\t\t\t\t\t\t\tval = tempval\n\t\t\t\t\texcept ValueError:\n\t\t\t\t\t\tpass\n\n\t\t\twindow_size /= granularity\n\n\t\treturn np.exp(bestc), np.exp(bestg)\n\n\tdef visualizations(self, voltages: List[np.ndarray], fileStarter: str) -&gt; None:\n\t\tpoints = np.array(list(map(list, zip(*voltages))))\n\n\t\tpca = PCA(n_components=2)\n\t\tpoints_2d = pca.fit_transform(points)\n\n\t\tplt.scatter(points_2d[:, 0], points_2d[:, 1], s=10)\n\t\tplt.xlabel(\"PCA Component 1\")\n\t\tplt.ylabel(\"PCA Component 2\")\n\t\tplt.title(\"PCA Projection of Solver Outputs\")\n\t\tplt.savefig(fileStarter + \"_PCA.png\")\n\t\tplt.clf()\n\n\t\tmds = MDS(n_components=2, random_state=42)\n\t\ttransformed_points = mds.fit_transform(points)\n\n\t\tplt.figure(figsize=(8, 6))\n\t\tplt.scatter(transformed_points[:, 0], transformed_points[:, 1], c='blue', edgecolors='black')\n\t\tplt.xlabel(\"MDS Dimension 1\")\n\t\tplt.ylabel(\"MDS Dimension 2\")\n\t\tplt.title(\"Multidimensional Scaling (MDS) to 2D\")\n\t\tplt.savefig(fileStarter + \"_MDS.png\")\n\t\tplt.clf()\n</code></pre>"},{"location":"reference/#code.bpf.BestParameterFinder.bestParameterFinder","title":"<code>bestParameterFinder(landmarks, data, minBound=-25, maxBound=-1, granularity=5, epsilon=1, approx=None)</code>","text":"<p>Finds the best parameters (C and P_G) for a solver based on voltage distribution minimization.</p> Source code in <code>code\\bpf.py</code> <pre><code>def bestParameterFinder(\n\tself,\n\tlandmarks: List,\n\tdata: Union[create_data.Data, kmeans.Partitions],\n\tminBound: float = -25,\n\tmaxBound: float = -1,\n\tgranularity: int = 5,\n\tepsilon: float = 1,\n\tapprox: Optional[int] = None\n) -&gt; tuple[float, float]:\n\t\"\"\"\n\tFinds the best parameters (C and P_G) for a solver based on voltage distribution minimization.\n\t\"\"\"\n\twindow_size = (maxBound - minBound) / 2\n\tbestc = minBound + window_size\n\tbestg = minBound + window_size\n\tval = float('inf')\n\n\twhile window_size &gt; epsilon:\n\t\tcs = [bestc + x * window_size / granularity for x in range(-granularity + 1, granularity)]\n\t\tgs = [bestg + x * window_size / granularity for x in range(-granularity + 1, granularity)]\n\n\t\tif self.c is not None:\n\t\t\tcs = [self.c]\n\t\tif self.p_g is not None:\n\t\t\tgs = [self.p_g]\n\n\t\tfor c in cs:\n\t\t\tfor g in gs:\n\t\t\t\ttry:\n\t\t\t\t\tif approx is None:\n\t\t\t\t\t\ttempval = self.calculateFor(landmarks, data, c, g)\n\t\t\t\t\telse:\n\t\t\t\t\t\ttempval = self.calculateFor(landmarks, data, c, g, approx=True, approx_iters=approx)\n\n\t\t\t\t\tif val &gt; tempval:\n\t\t\t\t\t\tbestc, bestg = c, g\n\t\t\t\t\t\tval = tempval\n\t\t\t\texcept ValueError:\n\t\t\t\t\tpass\n\n\t\twindow_size /= granularity\n\n\treturn np.exp(bestc), np.exp(bestg)\n</code></pre>"},{"location":"reference/#code.create_data.__cached__","title":"<code>__cached__ = 'C:\\\\Users\\\\avigh\\\\Documents\\\\python\\\\VoltageDimentionalReduction\\\\code\\\\__pycache__\\\\create_data.cpython-313.pyc'</code>  <code>module</code>","text":"<p>str(object='') -&gt; str str(bytes_or_buffer[, encoding[, errors]]) -&gt; str</p> <p>Create a new string object from the given object. If encoding or errors is specified, then the object must expose a data buffer that will be decoded using the given encoding and error handler. Otherwise, returns the result of object.str() (if defined) or repr(object). encoding defaults to 'utf-8'. errors defaults to 'strict'.</p>"},{"location":"reference/#code.create_data.__file__","title":"<code>__file__ = 'C:\\\\Users\\\\avigh\\\\Documents\\\\python\\\\VoltageDimentionalReduction\\\\code\\\\create_data.py'</code>  <code>module</code>","text":"<p>str(object='') -&gt; str str(bytes_or_buffer[, encoding[, errors]]) -&gt; str</p> <p>Create a new string object from the given object. If encoding or errors is specified, then the object must expose a data buffer that will be decoded using the given encoding and error handler. Otherwise, returns the result of object.str() (if defined) or repr(object). encoding defaults to 'utf-8'. errors defaults to 'strict'.</p>"},{"location":"reference/#code.create_data.__name__","title":"<code>__name__ = 'code.create_data'</code>  <code>module</code>","text":"<p>str(object='') -&gt; str str(bytes_or_buffer[, encoding[, errors]]) -&gt; str</p> <p>Create a new string object from the given object. If encoding or errors is specified, then the object must expose a data buffer that will be decoded using the given encoding and error handler. Otherwise, returns the result of object.str() (if defined) or repr(object). encoding defaults to 'utf-8'. errors defaults to 'strict'.</p>"},{"location":"reference/#code.create_data.__package__","title":"<code>__package__ = 'code'</code>  <code>module</code>","text":"<p>str(object='') -&gt; str str(bytes_or_buffer[, encoding[, errors]]) -&gt; str</p> <p>Create a new string object from the given object. If encoding or errors is specified, then the object must expose a data buffer that will be decoded using the given encoding and error handler. Otherwise, returns the result of object.str() (if defined) or repr(object). encoding defaults to 'utf-8'. errors defaults to 'strict'.</p>"},{"location":"reference/#code.create_data.Data","title":"<code>Data</code>","text":"<p>Class for handling and processing data sets.</p>"},{"location":"reference/#code.create_data.Data.__dict__","title":"<code>__dict__ = mappingproxy({'__module__': 'code.create_data', '__firstlineno__': 111, '__doc__': 'Class for handling and processing data sets.', '__init__': &lt;function Data.__init__ at 0x000001EAA17E6CA0&gt;, '__len__': &lt;function Data.__len__ at 0x000001EAA17E6D40&gt;, '__getitem__': &lt;function Data.__getitem__ at 0x000001EAA17E6DE0&gt;, '__setitem__': &lt;function Data.__setitem__ at 0x000001EAA17E6E80&gt;, '__iter__': &lt;function Data.__iter__ at 0x000001EAA17E6F20&gt;, '__next__': &lt;function Data.__next__ at 0x000001EAA17E6FC0&gt;, 'getSubSet': &lt;function Data.getSubSet at 0x000001EAA17E7060&gt;, 'save_data_json': &lt;function Data.save_data_json at 0x000001EAA17E7100&gt;, 'save_data_pickle': &lt;function Data.save_data_pickle at 0x000001EAA17E71A0&gt;, 'load_data_json': &lt;function Data.load_data_json at 0x000001EAA17E7240&gt;, 'load_data_pickle': &lt;function Data.load_data_pickle at 0x000001EAA17E72E0&gt;, 'stream_data_json': &lt;function Data.stream_data_json at 0x000001EAA17E7380&gt;, 'file_function_pairs': [['json', &lt;function Data.save_data_json at 0x000001EAA17E7100&gt;, &lt;function Data.load_data_json at 0x000001EAA17E7240&gt;], ['pkl', &lt;function Data.save_data_pickle at 0x000001EAA17E71A0&gt;, &lt;function Data.load_data_pickle at 0x000001EAA17E72E0&gt;]], 'data_function': &lt;function Data.data_function at 0x000001EAA17E7420&gt;, 'save_data': &lt;function Data.save_data at 0x000001EAA17E74C0&gt;, 'load_data': &lt;function Data.load_data at 0x000001EAA17E7560&gt;, 'get_random_point': &lt;function Data.get_random_point at 0x000001EAA17E7600&gt;, 'plot': &lt;function Data.plot at 0x000001EAA17E76A0&gt;, 'getNumpy': &lt;function Data.getNumpy at 0x000001EAA17E7740&gt;, '__static_attributes__': ('data', 'i', 'input_file', 'length', 'stream', 'streaming_data'), '__dict__': &lt;attribute '__dict__' of 'Data' objects&gt;, '__weakref__': &lt;attribute '__weakref__' of 'Data' objects&gt;})</code>  <code>class</code>","text":"<p>Read-only proxy of a mapping.</p>"},{"location":"reference/#code.create_data.Data.__doc__","title":"<code>__doc__ = 'Class for handling and processing data sets.'</code>  <code>class</code>","text":"<p>str(object='') -&gt; str str(bytes_or_buffer[, encoding[, errors]]) -&gt; str</p> <p>Create a new string object from the given object. If encoding or errors is specified, then the object must expose a data buffer that will be decoded using the given encoding and error handler. Otherwise, returns the result of object.str() (if defined) or repr(object). encoding defaults to 'utf-8'. errors defaults to 'strict'.</p>"},{"location":"reference/#code.create_data.Data.__firstlineno__","title":"<code>__firstlineno__ = 111</code>  <code>class</code>","text":"<p>int([x]) -&gt; integer int(x, base=10) -&gt; integer</p> <p>Convert a number or string to an integer, or return 0 if no arguments are given.  If x is a number, return x.int().  For floating-point numbers, this truncates towards zero.</p> <p>If x is not a number or if base is given, then x must be a string, bytes, or bytearray instance representing an integer literal in the given base.  The literal can be preceded by '+' or '-' and be surrounded by whitespace.  The base defaults to 10.  Valid bases are 0 and 2-36. Base 0 means to interpret the base from the string as an integer literal.</p> <p>int('0b100', base=0) 4</p>"},{"location":"reference/#code.create_data.Data.__module__","title":"<code>__module__ = 'code.create_data'</code>  <code>class</code>","text":"<p>str(object='') -&gt; str str(bytes_or_buffer[, encoding[, errors]]) -&gt; str</p> <p>Create a new string object from the given object. If encoding or errors is specified, then the object must expose a data buffer that will be decoded using the given encoding and error handler. Otherwise, returns the result of object.str() (if defined) or repr(object). encoding defaults to 'utf-8'. errors defaults to 'strict'.</p>"},{"location":"reference/#code.create_data.Data.__static_attributes__","title":"<code>__static_attributes__ = ('data', 'i', 'input_file', 'length', 'stream', 'streaming_data')</code>  <code>class</code>","text":"<p>Built-in immutable sequence.</p> <p>If no argument is given, the constructor returns an empty tuple. If iterable is specified the tuple is initialized from iterable's items.</p> <p>If the argument is a tuple, the return value is the same object.</p>"},{"location":"reference/#code.create_data.Data.__weakref__","title":"<code>__weakref__</code>  <code>property</code>","text":"<p>list of weak references to the object</p>"},{"location":"reference/#code.create_data.Data.file_function_pairs","title":"<code>file_function_pairs = [['json', &lt;function Data.save_data_json at 0x000001EAA17E7100&gt;, &lt;function Data.load_data_json at 0x000001EAA17E7240&gt;], ['pkl', &lt;function Data.save_data_pickle at 0x000001EAA17E71A0&gt;, &lt;function Data.load_data_pickle at 0x000001EAA17E72E0&gt;]]</code>  <code>class</code>","text":"<p>Built-in mutable sequence.</p> <p>If no argument is given, the constructor creates a new empty list. The argument must be an iterable if specified.</p>"},{"location":"reference/#code.create_data.Data.data_function","title":"<code>data_function(file, save_or_load)</code>","text":"<p>Used for saving and loading the dataset</p>"},{"location":"reference/#code.create_data.Data.getSubSet","title":"<code>getSubSet(indexList)</code>","text":"<p>Returns a subset of the data given a list of indices.</p>"},{"location":"reference/#code.create_data.Data.get_random_point","title":"<code>get_random_point()</code>","text":"<p>Returns a random point from the dataset.</p>"},{"location":"reference/#code.create_data.Data.plot","title":"<code>plot(name=None)</code>","text":"<p>Plots the dataset.</p>"},{"location":"reference/#code.create_data.Data.stream_data_json","title":"<code>stream_data_json(input_file)</code>","text":"<p>Stream the dataset if its saved in a json file</p>"},{"location":"reference/#code.create_data.DataCreator","title":"<code>DataCreator</code>","text":""},{"location":"reference/#code.create_data.DataCreator.__dict__","title":"<code>__dict__ = mappingproxy({'__module__': 'code.create_data', '__firstlineno__': 366, '__init__': &lt;function DataCreator.__init__ at 0x000001EAA17E7D80&gt;, 'stream_dataset_creator': &lt;function DataCreator.stream_dataset_creator at 0x000001EAA17E7E20&gt;, 'create_dataset_line': &lt;function DataCreator.create_dataset_line at 0x000001EAA17E7EC0&gt;, 'create_dataset_square_edge': &lt;function DataCreator.create_dataset_square_edge at 0x000001EAA17E7F60&gt;, 'create_dataset_square_fill': &lt;function DataCreator.create_dataset_square_fill at 0x000001EAA17F4040&gt;, 'create_dataset_eigth_sphere': &lt;function DataCreator.create_dataset_eigth_sphere at 0x000001EAA17F40E0&gt;, 'create_dataset_triangle': &lt;function DataCreator.create_dataset_triangle at 0x000001EAA17F4180&gt;, 'create_dataset_strong_clusters': &lt;function DataCreator.create_dataset_strong_clusters at 0x000001EAA17F4220&gt;, 'rotate_into_dimention': &lt;function DataCreator.rotate_into_dimention at 0x000001EAA17F42C0&gt;, 'create_dataset_spiral': &lt;function DataCreator.create_dataset_spiral at 0x000001EAA17F4360&gt;, '__static_attributes__': ('fg',), '__dict__': &lt;attribute '__dict__' of 'DataCreator' objects&gt;, '__weakref__': &lt;attribute '__weakref__' of 'DataCreator' objects&gt;, '__doc__': None})</code>  <code>class</code>","text":"<p>Read-only proxy of a mapping.</p>"},{"location":"reference/#code.create_data.DataCreator.__firstlineno__","title":"<code>__firstlineno__ = 366</code>  <code>class</code>","text":"<p>int([x]) -&gt; integer int(x, base=10) -&gt; integer</p> <p>Convert a number or string to an integer, or return 0 if no arguments are given.  If x is a number, return x.int().  For floating-point numbers, this truncates towards zero.</p> <p>If x is not a number or if base is given, then x must be a string, bytes, or bytearray instance representing an integer literal in the given base.  The literal can be preceded by '+' or '-' and be surrounded by whitespace.  The base defaults to 10.  Valid bases are 0 and 2-36. Base 0 means to interpret the base from the string as an integer literal.</p> <p>int('0b100', base=0) 4</p>"},{"location":"reference/#code.create_data.DataCreator.__module__","title":"<code>__module__ = 'code.create_data'</code>  <code>class</code>","text":"<p>str(object='') -&gt; str str(bytes_or_buffer[, encoding[, errors]]) -&gt; str</p> <p>Create a new string object from the given object. If encoding or errors is specified, then the object must expose a data buffer that will be decoded using the given encoding and error handler. Otherwise, returns the result of object.str() (if defined) or repr(object). encoding defaults to 'utf-8'. errors defaults to 'strict'.</p>"},{"location":"reference/#code.create_data.DataCreator.__static_attributes__","title":"<code>__static_attributes__ = ('fg',)</code>  <code>class</code>","text":"<p>Built-in immutable sequence.</p> <p>If no argument is given, the constructor returns an empty tuple. If iterable is specified the tuple is initialized from iterable's items.</p> <p>If the argument is a tuple, the return value is the same object.</p>"},{"location":"reference/#code.create_data.DataCreator.__weakref__","title":"<code>__weakref__</code>  <code>property</code>","text":"<p>list of weak references to the object</p>"},{"location":"reference/#code.create_data.DataCreator.create_dataset_eigth_sphere","title":"<code>create_dataset_eigth_sphere(output_file=None, radius=1, x_pos=True, y_pos=True, z_pos=True, points=1000, seed=42, stream=False)</code>","text":"<p>Generates a dataset of an eigth sphere</p>"},{"location":"reference/#code.create_data.DataCreator.create_dataset_line","title":"<code>create_dataset_line(output_file=None, start=0, end=1, points=1000, seed=42, stream=False)</code>","text":"<p>Generates a dataset of a 1D line</p>"},{"location":"reference/#code.create_data.DataCreator.create_dataset_square_edge","title":"<code>create_dataset_square_edge(output_file=None, p1=(0, 0), p2=(1, 1), points=1000, seed=42)</code>","text":"<p>Generates a dataset of the edge of a square</p>"},{"location":"reference/#code.create_data.DataCreator.create_dataset_square_fill","title":"<code>create_dataset_square_fill(output_file=None, p1=(0, 0), p2=(1, 1), points=1000, seed=42)</code>","text":"<p>Generates a dataset of a filled in square</p>"},{"location":"reference/#code.create_data.DataCreator.create_dataset_strong_clusters","title":"<code>create_dataset_strong_clusters(output_file=None, internal_std=1, external_std=10, mean=[0, 0], clusters=10, points=1000, seed=42, stream=False)</code>","text":"<p>Generates a strongly clustered datapoint by selecting cluster centers and variance in the clusters via normal distribution</p>"},{"location":"reference/#code.create_data.DataCreator.create_dataset_triangle","title":"<code>create_dataset_triangle(output_file=None, edges=[[0, 0], [1, 1], [2, 0]], points=1000, seed=42, stream=False)</code>","text":"<p>Generates a dataset of an eigth sphere</p>"},{"location":"reference/#code.create_data.DataCreator.rotate_into_dimention","title":"<code>rotate_into_dimention(data, higher_dim=3, seed=42)</code>","text":"<p>Moves the data into a higher dimention and does rotations centered at the origin</p>"},{"location":"reference/#code.create_data.DataCreator.stream_dataset_creator","title":"<code>stream_dataset_creator(output_file, function, seed, stream, *args)</code>","text":"<p>Creates a dataset by passing in generator functions, allowing for streamed and not streamed dataset creation</p>"},{"location":"reference/#code.create_data.FileGenerator","title":"<code>FileGenerator</code>","text":"<p>Generates files for saved data. Its own class because it is used by Data and DataCreator</p>"},{"location":"reference/#code.create_data.FileGenerator.__dict__","title":"<code>__dict__ = mappingproxy({'__module__': 'code.create_data', '__firstlineno__': 293, '__doc__': 'Generates files for saved data. Its own class because it is used by Data and DataCreator', '__init__': &lt;function FileGenerator.__init__ at 0x000001EAA17E77E0&gt;, 'setGenerator': &lt;function FileGenerator.setGenerator at 0x000001EAA17E7880&gt;, 'stream_save': &lt;function FileGenerator.stream_save at 0x000001EAA17E7920&gt;, 'linear_generator': &lt;function FileGenerator.linear_generator at 0x000001EAA17E79C0&gt;, 'line_generator': &lt;function FileGenerator.line_generator at 0x000001EAA17E7A60&gt;, 'eigth_sphere_generator': &lt;function FileGenerator.eigth_sphere_generator at 0x000001EAA17E7B00&gt;, 'triangle_generator': &lt;function FileGenerator.triangle_generator at 0x000001EAA17E7BA0&gt;, 'strong_cluster_generator': &lt;function FileGenerator.strong_cluster_generator at 0x000001EAA17E7C40&gt;, 'spiral_generator': &lt;function FileGenerator.spiral_generator at 0x000001EAA17E7CE0&gt;, '__static_attributes__': ('data_generator',), '__dict__': &lt;attribute '__dict__' of 'FileGenerator' objects&gt;, '__weakref__': &lt;attribute '__weakref__' of 'FileGenerator' objects&gt;})</code>  <code>class</code>","text":"<p>Read-only proxy of a mapping.</p>"},{"location":"reference/#code.create_data.FileGenerator.__doc__","title":"<code>__doc__ = 'Generates files for saved data. Its own class because it is used by Data and DataCreator'</code>  <code>class</code>","text":"<p>str(object='') -&gt; str str(bytes_or_buffer[, encoding[, errors]]) -&gt; str</p> <p>Create a new string object from the given object. If encoding or errors is specified, then the object must expose a data buffer that will be decoded using the given encoding and error handler. Otherwise, returns the result of object.str() (if defined) or repr(object). encoding defaults to 'utf-8'. errors defaults to 'strict'.</p>"},{"location":"reference/#code.create_data.FileGenerator.__firstlineno__","title":"<code>__firstlineno__ = 293</code>  <code>class</code>","text":"<p>int([x]) -&gt; integer int(x, base=10) -&gt; integer</p> <p>Convert a number or string to an integer, or return 0 if no arguments are given.  If x is a number, return x.int().  For floating-point numbers, this truncates towards zero.</p> <p>If x is not a number or if base is given, then x must be a string, bytes, or bytearray instance representing an integer literal in the given base.  The literal can be preceded by '+' or '-' and be surrounded by whitespace.  The base defaults to 10.  Valid bases are 0 and 2-36. Base 0 means to interpret the base from the string as an integer literal.</p> <p>int('0b100', base=0) 4</p>"},{"location":"reference/#code.create_data.FileGenerator.__module__","title":"<code>__module__ = 'code.create_data'</code>  <code>class</code>","text":"<p>str(object='') -&gt; str str(bytes_or_buffer[, encoding[, errors]]) -&gt; str</p> <p>Create a new string object from the given object. If encoding or errors is specified, then the object must expose a data buffer that will be decoded using the given encoding and error handler. Otherwise, returns the result of object.str() (if defined) or repr(object). encoding defaults to 'utf-8'. errors defaults to 'strict'.</p>"},{"location":"reference/#code.create_data.FileGenerator.__static_attributes__","title":"<code>__static_attributes__ = ('data_generator',)</code>  <code>class</code>","text":"<p>Built-in immutable sequence.</p> <p>If no argument is given, the constructor returns an empty tuple. If iterable is specified the tuple is initialized from iterable's items.</p> <p>If the argument is a tuple, the return value is the same object.</p>"},{"location":"reference/#code.create_data.FileGenerator.__weakref__","title":"<code>__weakref__</code>  <code>property</code>","text":"<p>list of weak references to the object</p>"},{"location":"reference/#code.create_data.FileGenerator.eigth_sphere_generator","title":"<code>eigth_sphere_generator(radius, x_pos, y_pos, z_pos, points)</code>","text":"<p>Generator for points on an eigth sphere</p>"},{"location":"reference/#code.create_data.FileGenerator.line_generator","title":"<code>line_generator(start, end, points)</code>","text":"<p>Generates points along a line in 1D space.</p>"},{"location":"reference/#code.create_data.FileGenerator.linear_generator","title":"<code>linear_generator(data)</code>","text":"<p>Yields data points one by one.</p>"},{"location":"reference/#code.create_data.FileGenerator.stream_save","title":"<code>stream_save(output_file, *args)</code>","text":"<p>Saves data to a JSON file in a streaming manner.</p>"},{"location":"reference/#code.create_data.FileGenerator.strong_cluster_generator","title":"<code>strong_cluster_generator(internal_std, cluster_centers, points)</code>","text":"<p>Generates points in a strong cluster</p>"},{"location":"reference/#code.create_data.FileGenerator.triangle_generator","title":"<code>triangle_generator(edges, points)</code>","text":"<p>Generator for points on a triangle</p>"},{"location":"reference/#code.create_data.Plotter","title":"<code>Plotter</code>","text":"<p>Graphs the data into different formats</p>"},{"location":"reference/#code.create_data.Plotter.__dict__","title":"<code>__dict__ = mappingproxy({'__module__': 'code.create_data', '__firstlineno__': 30, '__doc__': 'Graphs the data into different formats', 'pointFormatting': &lt;function Plotter.pointFormatting at 0x000001EAA17E6A20&gt;, 'plotPoints': &lt;function Plotter.plotPoints at 0x000001EAA17E6AC0&gt;, 'plotPointSets': &lt;function Plotter.plotPointSets at 0x000001EAA17E6B60&gt;, 'voltage_plot': &lt;function Plotter.voltage_plot at 0x000001EAA17E6C00&gt;, '__static_attributes__': (), '__dict__': &lt;attribute '__dict__' of 'Plotter' objects&gt;, '__weakref__': &lt;attribute '__weakref__' of 'Plotter' objects&gt;})</code>  <code>class</code>","text":"<p>Read-only proxy of a mapping.</p>"},{"location":"reference/#code.create_data.Plotter.__doc__","title":"<code>__doc__ = 'Graphs the data into different formats'</code>  <code>class</code>","text":"<p>str(object='') -&gt; str str(bytes_or_buffer[, encoding[, errors]]) -&gt; str</p> <p>Create a new string object from the given object. If encoding or errors is specified, then the object must expose a data buffer that will be decoded using the given encoding and error handler. Otherwise, returns the result of object.str() (if defined) or repr(object). encoding defaults to 'utf-8'. errors defaults to 'strict'.</p>"},{"location":"reference/#code.create_data.Plotter.__firstlineno__","title":"<code>__firstlineno__ = 30</code>  <code>class</code>","text":"<p>int([x]) -&gt; integer int(x, base=10) -&gt; integer</p> <p>Convert a number or string to an integer, or return 0 if no arguments are given.  If x is a number, return x.int().  For floating-point numbers, this truncates towards zero.</p> <p>If x is not a number or if base is given, then x must be a string, bytes, or bytearray instance representing an integer literal in the given base.  The literal can be preceded by '+' or '-' and be surrounded by whitespace.  The base defaults to 10.  Valid bases are 0 and 2-36. Base 0 means to interpret the base from the string as an integer literal.</p> <p>int('0b100', base=0) 4</p>"},{"location":"reference/#code.create_data.Plotter.__module__","title":"<code>__module__ = 'code.create_data'</code>  <code>class</code>","text":"<p>str(object='') -&gt; str str(bytes_or_buffer[, encoding[, errors]]) -&gt; str</p> <p>Create a new string object from the given object. If encoding or errors is specified, then the object must expose a data buffer that will be decoded using the given encoding and error handler. Otherwise, returns the result of object.str() (if defined) or repr(object). encoding defaults to 'utf-8'. errors defaults to 'strict'.</p>"},{"location":"reference/#code.create_data.Plotter.__static_attributes__","title":"<code>__static_attributes__ = ()</code>  <code>class</code>","text":"<p>Built-in immutable sequence.</p> <p>If no argument is given, the constructor returns an empty tuple. If iterable is specified the tuple is initialized from iterable's items.</p> <p>If the argument is a tuple, the return value is the same object.</p>"},{"location":"reference/#code.create_data.Plotter.__weakref__","title":"<code>__weakref__</code>  <code>property</code>","text":"<p>list of weak references to the object</p>"},{"location":"reference/#code.create_data.Plotter.plotPointSets","title":"<code>plotPointSets(sets, name=None)</code>","text":"<p>Plots multiple sets of points with different colors and markers.</p>"},{"location":"reference/#code.create_data.Plotter.plotPoints","title":"<code>plotPoints(points, name=None)</code>","text":"<p>Plots a set of points in 2D or 3D.</p>"},{"location":"reference/#code.create_data.Plotter.pointFormatting","title":"<code>pointFormatting(points)</code>","text":"<p>Formats points into coordinate lists for plotting.</p>"},{"location":"reference/#code.create_data.dimentional_variation","title":"<code>dimentional_variation(dimentions)</code>","text":"<p>Returns an np array that is full of random variables from -inf to inf based on the standard normal distribution</p>"},{"location":"reference/#code.create_data.select_random","title":"<code>select_random(array)</code>","text":"<p>Selects a random element from an array.</p>"},{"location":"reference/#code.kmeans.Partitions","title":"<code>Partitions</code>","text":"<p>               Bases: <code>DistanceBased</code></p> <p>Using K-means to partition a large dataset</p> Source code in <code>code\\kmeans.py</code> <pre><code>class Partitions(DistanceBased):\n\t\"\"\"Using K-means to partition a large dataset\"\"\"\n\tdef __init__(self, data):\n\t\tself.data = data\n\t\tsuper().__init__()\n\n\tdef k_means_plus_plus(self, k):\n\t\t\"\"\"The old k-means++ algorithm before using sci-kit\"\"\"\n\n\t\t# print(self.data.data)\n\t\tself.centers = [create_data.select_random(self.data)]\n\n\t\tfor i in range(k - 1):\n\t\t\tdistances = []\n\n\t\t\tfor point in self.data:\n\t\t\t\t# print(type(point))\n\t\t\t\t# print(type(self.centers[0]))\n\n\t\t\t\t# print(point)\n\t\t\t\t# print(self.centers[0])\n\n\t\t\t\td = self.distance(point, self.centers[0])\n\t\t\t\tfor center in self.centers:\n\t\t\t\t\td = min(d, self.distance(point, center))\n\n\t\t\t\tdistances.append(d)\n\n\t\t\tdistances = np.array(distances)\n\t\t\tdistances /= np.sum(distances)\n\n\t\t\tself.centers.append(weighted_random(self.data, distances))\n\n\t\treturn self.centers\n\n\tdef k_means(self, k, seed=42, savePointAssignments=False):\n\t\t\"\"\"Runs k-means and saves the centers and point counts. With option to save pointAssignments for voronoi drawing\"\"\"\n\t\tif (seed == -1):\n\t\t\tkmeans = KMeans(n_clusters=k, init=\"k-means++\").fit(self.data)\n\t\telse:\n\t\t\tkmeans = KMeans(n_clusters=k, random_state=int(seed), init=\"k-means++\", n_init=1).fit(self.data)\n\n\t\tself.k = k\n\t\tself.centers = kmeans.cluster_centers_\n\t\tself.point_counts = np.bincount(kmeans.labels_).tolist()\n\n\t\tif savePointAssignments:\n\t\t\tself.point_assignments = [[] for i in range(k)]\n\t\t\tfor i, point in enumerate(data):\n\t\t\t\tlabel = kmeans.labels_[i]\n\n\t\t\t\t# print(point)\n\t\t\t\t# print(self.centers[label])\n\t\t\t\t# print(self.distance(point, self.centers[label]))\n\t\t\t\tself.point_assignments[label].append([point, self.distance(point, self.centers[label])])\n\n\t\t\t# self.point_assignments = [data[kmeans.labels_ == i] for i in range(k)]\t# k times less efficient\n\t\t# self.voronoi = Voronoi(self.centers)\n\n\tdef my_k_means(self, k, seed=42, savePointAssignments=False):\n\t\t\"\"\"The old k-means algorithm\"\"\"\n\n\t\tif (seed != -1):\n\t\t\trandom.seed(seed)\n\n\t\tself.centers = self.k_means_plus_plus(k)\n\n\t\tpoint_accumulator = [np.zeros(len(self.data[0])) for i in range(k)]\n\t\tpoint_counts = [0 for i in range(k)]\n\n\t\tif (savePointAssignments):\t\t\t\t\t\t\t\t\t\t\t\t\t\t# This removes the benefit of streaming\n\t\t\tself.point_assignments = [[] for i in range(k)]\n\n\t\tfor i, point in enumerate(self.data):\n\t\t\tmin_index = 0\n\t\t\tmin_dist = self.distance(point, self.centers[0])\n\n\t\t\tfor c in range(k - 1):\n\t\t\t\tdist = self.distance(point, self.centers[c + 1])\n\t\t\t\tif (min_dist &gt; dist):\n\t\t\t\t\tmin_index = c + 1\n\t\t\t\t\tmin_dist = dist\n\n\t\t\tif (savePointAssignments):\n\t\t\t\tself.point_assignments[min_index].append([point, min_dist])\n\n\t\t\tpoint_accumulator[min_index] += point\n\t\t\tpoint_counts[min_index] += 1\n\n\t\tupdated_centers = []\n\t\tself.point_counts = []\n\n\t\tfor acc, count in zip(point_accumulator, point_counts):\n\t\t\tif (count != 0):\n\t\t\t\tupdated_centers.append(acc / count)\n\t\t\t\tself.point_counts.append(count)\n\n\t\tself.centers = updated_centers\n\t\tself.voronoi = Voronoi(self.centers)\n\n\tdef getClosestPoints(self, index):\n\t\t\"\"\"\n\t\tFinds the points whose closest points are the point indicated by the index\n\n\t\tArgs:\n\t\t\tindex (int): the index of the point\n\n\t\tReturns:\n\t\t\tlist: All the points whose closest point is data[index]\n\n\t\t\"\"\"\n\t\tclosest = []\n\t\tfor i, point in enumerate(self.data):\n\t\t\tmin_index = 0\n\t\t\tmin_dist = self.distance(point, self.centers[0])\n\n\t\t\tfor c in range(len(self.centers) - 1):\n\t\t\t\tdist = self.distance(point, self.centers[c + 1])\n\t\t\t\tif (min_dist &gt; dist):\n\t\t\t\t\tmin_index = c + 1\n\t\t\t\t\tmin_dist = dist\n\n\t\t\tif (min_index == index):\n\t\t\t\tclosest.append(i)\n\n\t\treturn closest\n\n\tdef plot(self, color='r', marker='o', ax=None, name=None):\n\t\t\"\"\"Plot the kmeans\"\"\"\n\t\tplot = create_data.Plotter()\n\n\t\tsize = len(self.centers[0])\n\n\t\tif (ax == None):\n\t\t\tfig = plt.figure()\n\n\t\t\tif (size == 3):\n\t\t\t\tax = fig.add_subplot(111, projection='3d')\n\t\t\telse:\n\t\t\t\tax = fig.add_subplot(111)\n\n\t\tif (size == 3):\n\t\t\t(x_coords, y_coords, z_coords) = plot.pointFormatting(self.centers)\n\t\t\tax.scatter(x_coords, y_coords, z_coords, c=color, marker=marker, label='Centers')\n\t\telse:\n\t\t\t(x_coords, y_coords, z_coords) = plot.pointFormatting(self.data)\n\t\t\tax.scatter(x_coords, y_coords, c=color, marker=marker, label='Points')\n\n\t\t\t# voronoi_plot_2d(self.voronoi, ax=ax, show_vertices=False, line_colors='blue', line_width=1, line_alpha=0.6)\n\n\t\tax.legend()\n\n\t\tif (name):\n\t\t\tplt.savefig(name)\n\n\t\tplt.show()\n</code></pre>"},{"location":"reference/#code.kmeans.Partitions.getClosestPoints","title":"<code>getClosestPoints(index)</code>","text":"<p>Finds the points whose closest points are the point indicated by the index</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>int</code> <p>the index of the point</p> required <p>Returns:</p> Name Type Description <code>list</code> <p>All the points whose closest point is data[index]</p> Source code in <code>code\\kmeans.py</code> <pre><code>def getClosestPoints(self, index):\n\t\"\"\"\n\tFinds the points whose closest points are the point indicated by the index\n\n\tArgs:\n\t\tindex (int): the index of the point\n\n\tReturns:\n\t\tlist: All the points whose closest point is data[index]\n\n\t\"\"\"\n\tclosest = []\n\tfor i, point in enumerate(self.data):\n\t\tmin_index = 0\n\t\tmin_dist = self.distance(point, self.centers[0])\n\n\t\tfor c in range(len(self.centers) - 1):\n\t\t\tdist = self.distance(point, self.centers[c + 1])\n\t\t\tif (min_dist &gt; dist):\n\t\t\t\tmin_index = c + 1\n\t\t\t\tmin_dist = dist\n\n\t\tif (min_index == index):\n\t\t\tclosest.append(i)\n\n\treturn closest\n</code></pre>"},{"location":"reference/#code.kmeans.Partitions.k_means","title":"<code>k_means(k, seed=42, savePointAssignments=False)</code>","text":"<p>Runs k-means and saves the centers and point counts. With option to save pointAssignments for voronoi drawing</p> Source code in <code>code\\kmeans.py</code> <pre><code>def k_means(self, k, seed=42, savePointAssignments=False):\n\t\"\"\"Runs k-means and saves the centers and point counts. With option to save pointAssignments for voronoi drawing\"\"\"\n\tif (seed == -1):\n\t\tkmeans = KMeans(n_clusters=k, init=\"k-means++\").fit(self.data)\n\telse:\n\t\tkmeans = KMeans(n_clusters=k, random_state=int(seed), init=\"k-means++\", n_init=1).fit(self.data)\n\n\tself.k = k\n\tself.centers = kmeans.cluster_centers_\n\tself.point_counts = np.bincount(kmeans.labels_).tolist()\n\n\tif savePointAssignments:\n\t\tself.point_assignments = [[] for i in range(k)]\n\t\tfor i, point in enumerate(data):\n\t\t\tlabel = kmeans.labels_[i]\n\n\t\t\t# print(point)\n\t\t\t# print(self.centers[label])\n\t\t\t# print(self.distance(point, self.centers[label]))\n\t\t\tself.point_assignments[label].append([point, self.distance(point, self.centers[label])])\n</code></pre>"},{"location":"reference/#code.kmeans.Partitions.k_means_plus_plus","title":"<code>k_means_plus_plus(k)</code>","text":"<p>The old k-means++ algorithm before using sci-kit</p> Source code in <code>code\\kmeans.py</code> <pre><code>def k_means_plus_plus(self, k):\n\t\"\"\"The old k-means++ algorithm before using sci-kit\"\"\"\n\n\t# print(self.data.data)\n\tself.centers = [create_data.select_random(self.data)]\n\n\tfor i in range(k - 1):\n\t\tdistances = []\n\n\t\tfor point in self.data:\n\t\t\t# print(type(point))\n\t\t\t# print(type(self.centers[0]))\n\n\t\t\t# print(point)\n\t\t\t# print(self.centers[0])\n\n\t\t\td = self.distance(point, self.centers[0])\n\t\t\tfor center in self.centers:\n\t\t\t\td = min(d, self.distance(point, center))\n\n\t\t\tdistances.append(d)\n\n\t\tdistances = np.array(distances)\n\t\tdistances /= np.sum(distances)\n\n\t\tself.centers.append(weighted_random(self.data, distances))\n\n\treturn self.centers\n</code></pre>"},{"location":"reference/#code.kmeans.Partitions.my_k_means","title":"<code>my_k_means(k, seed=42, savePointAssignments=False)</code>","text":"<p>The old k-means algorithm</p> Source code in <code>code\\kmeans.py</code> <pre><code>def my_k_means(self, k, seed=42, savePointAssignments=False):\n\t\"\"\"The old k-means algorithm\"\"\"\n\n\tif (seed != -1):\n\t\trandom.seed(seed)\n\n\tself.centers = self.k_means_plus_plus(k)\n\n\tpoint_accumulator = [np.zeros(len(self.data[0])) for i in range(k)]\n\tpoint_counts = [0 for i in range(k)]\n\n\tif (savePointAssignments):\t\t\t\t\t\t\t\t\t\t\t\t\t\t# This removes the benefit of streaming\n\t\tself.point_assignments = [[] for i in range(k)]\n\n\tfor i, point in enumerate(self.data):\n\t\tmin_index = 0\n\t\tmin_dist = self.distance(point, self.centers[0])\n\n\t\tfor c in range(k - 1):\n\t\t\tdist = self.distance(point, self.centers[c + 1])\n\t\t\tif (min_dist &gt; dist):\n\t\t\t\tmin_index = c + 1\n\t\t\t\tmin_dist = dist\n\n\t\tif (savePointAssignments):\n\t\t\tself.point_assignments[min_index].append([point, min_dist])\n\n\t\tpoint_accumulator[min_index] += point\n\t\tpoint_counts[min_index] += 1\n\n\tupdated_centers = []\n\tself.point_counts = []\n\n\tfor acc, count in zip(point_accumulator, point_counts):\n\t\tif (count != 0):\n\t\t\tupdated_centers.append(acc / count)\n\t\t\tself.point_counts.append(count)\n\n\tself.centers = updated_centers\n\tself.voronoi = Voronoi(self.centers)\n</code></pre>"},{"location":"reference/#code.kmeans.Partitions.plot","title":"<code>plot(color='r', marker='o', ax=None, name=None)</code>","text":"<p>Plot the kmeans</p> Source code in <code>code\\kmeans.py</code> <pre><code>def plot(self, color='r', marker='o', ax=None, name=None):\n\t\"\"\"Plot the kmeans\"\"\"\n\tplot = create_data.Plotter()\n\n\tsize = len(self.centers[0])\n\n\tif (ax == None):\n\t\tfig = plt.figure()\n\n\t\tif (size == 3):\n\t\t\tax = fig.add_subplot(111, projection='3d')\n\t\telse:\n\t\t\tax = fig.add_subplot(111)\n\n\tif (size == 3):\n\t\t(x_coords, y_coords, z_coords) = plot.pointFormatting(self.centers)\n\t\tax.scatter(x_coords, y_coords, z_coords, c=color, marker=marker, label='Centers')\n\telse:\n\t\t(x_coords, y_coords, z_coords) = plot.pointFormatting(self.data)\n\t\tax.scatter(x_coords, y_coords, c=color, marker=marker, label='Points')\n\n\t\t# voronoi_plot_2d(self.voronoi, ax=ax, show_vertices=False, line_colors='blue', line_width=1, line_alpha=0.6)\n\n\tax.legend()\n\n\tif (name):\n\t\tplt.savefig(name)\n\n\tplt.show()\n</code></pre>"},{"location":"reference/#code.voltage.Landmark","title":"<code>Landmark</code>","text":"<p>Represents a location in the dataset where a voltage will be applied.</p> <p>The <code>index</code> can refer either to an individual datapoint or a partition center.</p> Source code in <code>code\\voltage.py</code> <pre><code>class Landmark:\n\t\"\"\"\n\tRepresents a location in the dataset where a voltage will be applied.\n\n\tThe `index` can refer either to an individual datapoint or a partition center.\n\t\"\"\"\n\n\tdef __init__(self, index: int, voltage: float) -&gt; None:\n\t\t\"\"\"\n\t\tInitializes a Landmark.\n\n\t\tArgs:\n\t\t\tindex (int): Index of the datapoint or partition center.\n\t\t\tvoltage (float): Voltage to be applied at the specified index.\n\t\t\"\"\"\n\t\tself.index = index\n\t\tself.voltage = voltage\n\n\t@staticmethod\n\tdef createLandmarkClosestTo(\n\t\tdata: List[Any],\n\t\tpoint: Any,\n\t\tvoltage: float,\n\t\tdistanceFn: Optional[object] = None,\n\t\tignore: List[int] = []\n\t) -&gt; \"Landmark\":\n\t\t\"\"\"\n\t\tCreates a Landmark at the index of the datapoint in `data` closest to `point`.\n\n\t\tArgs:\n\t\t\tdata (List[Any]): The dataset to search over.\n\t\t\tpoint (Any): The reference point to find the closest datapoint to.\n\t\t\tvoltage (float): The voltage to assign to the resulting Landmark.\n\t\t\tdistanceFn (Optional[object]): A distance function with a `.distance(a, b)` method.\n\t\t\t\t\t\t\t\t\t\t   Defaults to `kmeans.DistanceBased()` if None.\n\t\t\tignore (List[int], optional): List of indices to skip during the search. Defaults to empty list.\n\n\t\tReturns:\n\t\t\tLandmark: A Landmark instance corresponding to the closest datapoint.\n\t\t\"\"\"\n\t\tif distanceFn is None:\n\t\t\tdistanceFn = kmeans.DistanceBased()\n\n\t\tmost_central_index = 0\n\t\tmindist = distanceFn.distance(data[0], point)\n\n\t\tfor index in range(1, len(data)):\n\t\t\tif index in ignore:\n\t\t\t\tcontinue\n\n\t\t\tdist = distanceFn.distance(data[index], point)\n\t\t\tif dist &lt; mindist:\n\t\t\t\tmost_central_index = index\n\t\t\t\tmindist = dist\n\n\t\treturn Landmark(most_central_index, voltage)\n</code></pre>"},{"location":"reference/#code.voltage.Landmark.__init__","title":"<code>__init__(index, voltage)</code>","text":"<p>Initializes a Landmark.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>int</code> <p>Index of the datapoint or partition center.</p> required <code>voltage</code> <code>float</code> <p>Voltage to be applied at the specified index.</p> required Source code in <code>code\\voltage.py</code> <pre><code>def __init__(self, index: int, voltage: float) -&gt; None:\n\t\"\"\"\n\tInitializes a Landmark.\n\n\tArgs:\n\t\tindex (int): Index of the datapoint or partition center.\n\t\tvoltage (float): Voltage to be applied at the specified index.\n\t\"\"\"\n\tself.index = index\n\tself.voltage = voltage\n</code></pre>"},{"location":"reference/#code.voltage.Landmark.createLandmarkClosestTo","title":"<code>createLandmarkClosestTo(data, point, voltage, distanceFn=None, ignore=[])</code>  <code>staticmethod</code>","text":"<p>Creates a Landmark at the index of the datapoint in <code>data</code> closest to <code>point</code>.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>List[Any]</code> <p>The dataset to search over.</p> required <code>point</code> <code>Any</code> <p>The reference point to find the closest datapoint to.</p> required <code>voltage</code> <code>float</code> <p>The voltage to assign to the resulting Landmark.</p> required <code>distanceFn</code> <code>Optional[object]</code> <p>A distance function with a <code>.distance(a, b)</code> method.                                                    Defaults to <code>kmeans.DistanceBased()</code> if None.</p> <code>None</code> <code>ignore</code> <code>List[int]</code> <p>List of indices to skip during the search. Defaults to empty list.</p> <code>[]</code> <p>Returns:</p> Name Type Description <code>Landmark</code> <code>Landmark</code> <p>A Landmark instance corresponding to the closest datapoint.</p> Source code in <code>code\\voltage.py</code> <pre><code>@staticmethod\ndef createLandmarkClosestTo(\n\tdata: List[Any],\n\tpoint: Any,\n\tvoltage: float,\n\tdistanceFn: Optional[object] = None,\n\tignore: List[int] = []\n) -&gt; \"Landmark\":\n\t\"\"\"\n\tCreates a Landmark at the index of the datapoint in `data` closest to `point`.\n\n\tArgs:\n\t\tdata (List[Any]): The dataset to search over.\n\t\tpoint (Any): The reference point to find the closest datapoint to.\n\t\tvoltage (float): The voltage to assign to the resulting Landmark.\n\t\tdistanceFn (Optional[object]): A distance function with a `.distance(a, b)` method.\n\t\t\t\t\t\t\t\t\t   Defaults to `kmeans.DistanceBased()` if None.\n\t\tignore (List[int], optional): List of indices to skip during the search. Defaults to empty list.\n\n\tReturns:\n\t\tLandmark: A Landmark instance corresponding to the closest datapoint.\n\t\"\"\"\n\tif distanceFn is None:\n\t\tdistanceFn = kmeans.DistanceBased()\n\n\tmost_central_index = 0\n\tmindist = distanceFn.distance(data[0], point)\n\n\tfor index in range(1, len(data)):\n\t\tif index in ignore:\n\t\t\tcontinue\n\n\t\tdist = distanceFn.distance(data[index], point)\n\t\tif dist &lt; mindist:\n\t\t\tmost_central_index = index\n\t\t\tmindist = dist\n\n\treturn Landmark(most_central_index, voltage)\n</code></pre>"},{"location":"reference/#code.voltage.Problem","title":"<code>Problem</code>","text":"<p>               Bases: <code>DistanceBased</code></p> <p>Represents the clustering/graph problem to be solved,  extending a distance-based kernel with landmarks and weights.</p> Source code in <code>code\\voltage.py</code> <pre><code>class Problem(kmeans.DistanceBased):\n\t\"\"\"\n\tRepresents the clustering/graph problem to be solved, \n\textending a distance-based kernel with landmarks and weights.\n\t\"\"\"\n\n\tdef __init__(self, data: Any) -&gt; None:\n\t\t\"\"\"\n\t\tInitializes the Problem instance.\n\n\t\tArgs:\n\t\t\tdata: An object containing your dataset. Must support len(data) \n\t\t\t\t  and data.getNumpy() to return an (n, d) numpy array.\n\t\t\"\"\"\n\t\tsuper().__init__()\n\t\tself.data = data\n\t\tself.landmarks = []\n\t\tn = len(data)\n\t\tself.weights = np.zeros([n, n])\n\t\tself.universalGround = False\n\n\tdef timeStart(self) -&gt; None:\n\t\t\"\"\"\n\t\tRecords the current time to measure elapsed intervals.\n\t\t\"\"\"\n\t\tself.start = time.time()\n\n\tdef timeEnd(self, replace: bool = True) -&gt; float:\n\t\t\"\"\"\n\t\tComputes the elapsed time since the last timeStart().\n\n\t\tArgs:\n\t\t\treplace (bool): If True, resets the start time to now.\n\n\t\tReturns:\n\t\t\tfloat: Seconds elapsed since last start.\n\t\t\"\"\"\n\t\tcur_time = time.time()\n\t\tdiff = cur_time - self.start\n\t\tif replace:\n\t\t\tself.start = cur_time\n\t\treturn diff\n\n\tdef setKernel(self, kernel: Callable[..., np.ndarray]) -&gt; None:\n\t\t\"\"\"\n\t\tSets the kernel function to use for weight computations.\n\n\t\tArgs:\n\t\t\tkernel (callable): A function or callable object with signature\n\t\t\t\t\t\t\t   kernel(X, Y, *params) \u2192 ndarray of shape (|X|, |Y|).\n\t\t\"\"\"\n\t\tself.kernel = kernel\n\n\tdef efficientSquareDistance(self, data: np.ndarray) -&gt; np.ndarray:\n\t\t\"\"\"\n\t\tComputes the pairwise squared Euclidean distances of the rows in `data`.\n\n\t\tUses the identity \u2016x\u2212y\u2016\u00b2 = \u2016x\u2016\u00b2 + \u2016y\u2016\u00b2 \u2212 2 x\u00b7y for efficiency.\n\n\t\tArgs:\n\t\t\tdata (ndarray): Array of shape (n, d).\n\n\t\tReturns:\n\t\t\tndarray: Matrix of shape (n, n) where entry (i, j) is squared distance.\n\t\t\"\"\"\n\t\tdata_norm2 = np.sum(data**2, axis=1)\n\t\tx_norm2 = data_norm2.reshape(-1, 1)\n\t\ty_norm2 = data_norm2.reshape(1, -1)\n\t\treturn x_norm2 + y_norm2 - 2 * data @ data.T\n\n\tdef radialkernel(self, data: np.ndarray, r: float) -&gt; np.ndarray:\n\t\t\"\"\"\n\t\tBuilds a binary (0/1) radial kernel: 1 if distance \u2264 r, else 0.\n\n\t\tArgs:\n\t\t\tdata (ndarray): Array of shape (n, d).\n\t\t\tr (float): Radius threshold.\n\n\t\tReturns:\n\t\t\tndarray: Adjacency-like matrix (n\u00d7n) of 0/1 floats.\n\t\t\"\"\"\n\t\tdist2 = self.efficientSquareDistance(data)\n\t\treturn (dist2 &lt;= r**2).astype(float)\n\n\tdef gaussiankernel(self, data: np.ndarray, std: float) -&gt; np.ndarray:\n\t\t\"\"\"\n\t\tBuilds a Gaussian (RBF) kernel matrix.\n\n\t\tArgs:\n\t\t\tdata (ndarray): Array of shape (n, d).\n\t\t\tstd (float): Standard deviation parameter for the Gaussian.\n\n\t\tReturns:\n\t\t\tndarray: Kernel matrix of shape (n, n).\n\t\t\"\"\"\n\t\tdist2 = self.efficientSquareDistance(data)\n\t\treturn np.exp(-dist2 / (2 * std**2))\n\n\tdef setWeights(self, *c: Any) -&gt; np.ndarray:\n\t\t\"\"\"\n\t\tComputes and normalizes the weight matrix on the original data.\n\n\t\tArgs:\n\t\t\t*c: Parameters to pass into the currently set kernel function.\n\n\t\tReturns:\n\t\t\tndarray: The normalized weight matrix (n\u00d7n).\n\t\t\"\"\"\n\t\tdata_np = self.data.getNumpy()\n\t\tn = len(self.data)\n\t\tself.weights[:n, :n] = self.kernel(data_np, *c)\n\t\tself.normalizeWeights()\n\t\treturn self.weights\n\n\tdef normalizeWeights(self) -&gt; None:\n\t\t\"\"\"\n\t\tNormalizes each row of the weight matrix to sum to 1.\n\n\t\tRaises:\n\t\t\tValueError: If any row sums to zero, resulting in NaNs.\n\t\t\"\"\"\n\t\tself.weights = self.weights / self.weights.sum(axis=1, keepdims=True)\n\t\tif np.isnan(self.weights).any():\n\t\t\traise ValueError(\"Array contains NaN values!\")\n\n\tdef setPartitionWeights(self, partition: Any, *c: Any) -&gt; np.ndarray:\n\t\t\"\"\"\n\t\tComputes and normalizes weights based on cluster centers and sizes.\n\n\t\tArgs:\n\t\t\tpartition: An object with attributes `centers` (list of points)\n\t\t\t\t\t   and `point_counts` (counts per center).\n\t\t\t*c: Parameters to pass into the kernel function.\n\n\t\tReturns:\n\t\t\tndarray: The normalized weight matrix for the partition block.\n\t\t\"\"\"\n\t\tcenters = np.array(partition.centers)\n\t\tcounts = np.array(partition.point_counts).reshape(-1, 1)\n\t\tK = self.kernel(centers[:, None], centers[None, :], *c)\n\t\tW = K * (counts @ counts.T)\n\t\tn = len(centers)\n\t\tself.weights[:n, :n] = W\n\t\tself.normalizeWeights()\n\t\treturn self.weights\n\n\tdef addUniversalGround(self, p_g: float = 0.01) -&gt; np.ndarray:\n\t\t\"\"\"\n\t\tAdds (or updates) a 'universal ground' node connected uniformly to all others.\n\n\t\tArgs:\n\t\t\tp_g (float): Total ground connection probability to distribute.\n\n\t\tReturns:\n\t\t\tndarray: The updated normalized weight matrix including the ground node.\n\t\t\"\"\"\n\t\tif self.universalGround:\n\t\t\tn = self.weights.shape[0] - 1\n\t\t\tfor x in range(n):\n\t\t\t\tself.weights[x, n] = p_g / n\n\t\t\t\tself.weights[n, x] = p_g / n\n\t\telse:\n\t\t\tself.universalGround = True\n\t\t\tn = self.weights.shape[0]\n\t\t\tnewW = np.zeros([n + 1, n + 1])\n\t\t\tnewW[:n, :n] = self.weights\n\t\t\tfor x in range(n):\n\t\t\t\tnewW[x, n] = p_g / n\n\t\t\t\tnewW[n, x] = p_g / n\n\t\t\tself.weights = newW\n\t\t\tself.addLandmark(Landmark(n, 0))\n\t\tself.normalizeWeights()\n\t\treturn self.weights\n\n\tdef addLandmark(self, landmark: Landmark) -&gt; None:\n\t\t\"\"\"\n\t\tAdds a single Landmark to the problem.\n\n\t\tArgs:\n\t\t\tlandmark (Landmark): The landmark instance to append.\n\t\t\"\"\"\n\t\tself.landmarks.append(landmark)\n\n\tdef addLandmarks(self, landmarks: List[Landmark]) -&gt; None:\n\t\t\"\"\"\n\t\tAdds multiple Landmark instances to the problem.\n\n\t\tArgs:\n\t\t\tlandmarks (List[Landmark]): List of landmarks to append.\n\t\t\"\"\"\n\t\tself.landmarks += landmarks\n\n\tdef addLandmarksInRange(\n\t\tself, minRange: Union[List[float], np.ndarray],\n\t\tmaxRange: Union[List[float], np.ndarray],\n\t\tvoltage: float\n\t) -&gt; List[Landmark]:\n\t\t\"\"\"\n\t\tAdds landmarks for all data points within a given coordinate range.\n\n\t\tArgs:\n\t\t\tminRange (array-like): Minimum bounds per dimension.\n\t\t\tmaxRange (array-like): Maximum bounds per dimension.\n\t\t\tvoltage (float): Voltage to apply at each new landmark.\n\n\t\tReturns:\n\t\t\tList[Landmark]: The list of newly added landmarks.\n\t\t\"\"\"\n\t\tadding = []\n\t\tdata_np = self.data.getNumpy()\n\t\tfor idx, point in enumerate(data_np):\n\t\t\tif np.all(point &gt;= minRange) and np.all(point &lt;= maxRange):\n\t\t\t\tadding.append(Landmark(idx, voltage))\n\t\tself.addLandmarks(adding)\n\t\treturn adding\n</code></pre>"},{"location":"reference/#code.voltage.Problem.__init__","title":"<code>__init__(data)</code>","text":"<p>Initializes the Problem instance.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Any</code> <p>An object containing your dataset. Must support len(data)    and data.getNumpy() to return an (n, d) numpy array.</p> required Source code in <code>code\\voltage.py</code> <pre><code>def __init__(self, data: Any) -&gt; None:\n\t\"\"\"\n\tInitializes the Problem instance.\n\n\tArgs:\n\t\tdata: An object containing your dataset. Must support len(data) \n\t\t\t  and data.getNumpy() to return an (n, d) numpy array.\n\t\"\"\"\n\tsuper().__init__()\n\tself.data = data\n\tself.landmarks = []\n\tn = len(data)\n\tself.weights = np.zeros([n, n])\n\tself.universalGround = False\n</code></pre>"},{"location":"reference/#code.voltage.Problem.addLandmark","title":"<code>addLandmark(landmark)</code>","text":"<p>Adds a single Landmark to the problem.</p> <p>Parameters:</p> Name Type Description Default <code>landmark</code> <code>Landmark</code> <p>The landmark instance to append.</p> required Source code in <code>code\\voltage.py</code> <pre><code>def addLandmark(self, landmark: Landmark) -&gt; None:\n\t\"\"\"\n\tAdds a single Landmark to the problem.\n\n\tArgs:\n\t\tlandmark (Landmark): The landmark instance to append.\n\t\"\"\"\n\tself.landmarks.append(landmark)\n</code></pre>"},{"location":"reference/#code.voltage.Problem.addLandmarks","title":"<code>addLandmarks(landmarks)</code>","text":"<p>Adds multiple Landmark instances to the problem.</p> <p>Parameters:</p> Name Type Description Default <code>landmarks</code> <code>List[Landmark]</code> <p>List of landmarks to append.</p> required Source code in <code>code\\voltage.py</code> <pre><code>def addLandmarks(self, landmarks: List[Landmark]) -&gt; None:\n\t\"\"\"\n\tAdds multiple Landmark instances to the problem.\n\n\tArgs:\n\t\tlandmarks (List[Landmark]): List of landmarks to append.\n\t\"\"\"\n\tself.landmarks += landmarks\n</code></pre>"},{"location":"reference/#code.voltage.Problem.addLandmarksInRange","title":"<code>addLandmarksInRange(minRange, maxRange, voltage)</code>","text":"<p>Adds landmarks for all data points within a given coordinate range.</p> <p>Parameters:</p> Name Type Description Default <code>minRange</code> <code>array - like</code> <p>Minimum bounds per dimension.</p> required <code>maxRange</code> <code>array - like</code> <p>Maximum bounds per dimension.</p> required <code>voltage</code> <code>float</code> <p>Voltage to apply at each new landmark.</p> required <p>Returns:</p> Type Description <code>List[Landmark]</code> <p>List[Landmark]: The list of newly added landmarks.</p> Source code in <code>code\\voltage.py</code> <pre><code>def addLandmarksInRange(\n\tself, minRange: Union[List[float], np.ndarray],\n\tmaxRange: Union[List[float], np.ndarray],\n\tvoltage: float\n) -&gt; List[Landmark]:\n\t\"\"\"\n\tAdds landmarks for all data points within a given coordinate range.\n\n\tArgs:\n\t\tminRange (array-like): Minimum bounds per dimension.\n\t\tmaxRange (array-like): Maximum bounds per dimension.\n\t\tvoltage (float): Voltage to apply at each new landmark.\n\n\tReturns:\n\t\tList[Landmark]: The list of newly added landmarks.\n\t\"\"\"\n\tadding = []\n\tdata_np = self.data.getNumpy()\n\tfor idx, point in enumerate(data_np):\n\t\tif np.all(point &gt;= minRange) and np.all(point &lt;= maxRange):\n\t\t\tadding.append(Landmark(idx, voltage))\n\tself.addLandmarks(adding)\n\treturn adding\n</code></pre>"},{"location":"reference/#code.voltage.Problem.addUniversalGround","title":"<code>addUniversalGround(p_g=0.01)</code>","text":"<p>Adds (or updates) a 'universal ground' node connected uniformly to all others.</p> <p>Parameters:</p> Name Type Description Default <code>p_g</code> <code>float</code> <p>Total ground connection probability to distribute.</p> <code>0.01</code> <p>Returns:</p> Name Type Description <code>ndarray</code> <code>ndarray</code> <p>The updated normalized weight matrix including the ground node.</p> Source code in <code>code\\voltage.py</code> <pre><code>def addUniversalGround(self, p_g: float = 0.01) -&gt; np.ndarray:\n\t\"\"\"\n\tAdds (or updates) a 'universal ground' node connected uniformly to all others.\n\n\tArgs:\n\t\tp_g (float): Total ground connection probability to distribute.\n\n\tReturns:\n\t\tndarray: The updated normalized weight matrix including the ground node.\n\t\"\"\"\n\tif self.universalGround:\n\t\tn = self.weights.shape[0] - 1\n\t\tfor x in range(n):\n\t\t\tself.weights[x, n] = p_g / n\n\t\t\tself.weights[n, x] = p_g / n\n\telse:\n\t\tself.universalGround = True\n\t\tn = self.weights.shape[0]\n\t\tnewW = np.zeros([n + 1, n + 1])\n\t\tnewW[:n, :n] = self.weights\n\t\tfor x in range(n):\n\t\t\tnewW[x, n] = p_g / n\n\t\t\tnewW[n, x] = p_g / n\n\t\tself.weights = newW\n\t\tself.addLandmark(Landmark(n, 0))\n\tself.normalizeWeights()\n\treturn self.weights\n</code></pre>"},{"location":"reference/#code.voltage.Problem.efficientSquareDistance","title":"<code>efficientSquareDistance(data)</code>","text":"<p>Computes the pairwise squared Euclidean distances of the rows in <code>data</code>.</p> <p>Uses the identity \u2016x\u2212y\u2016\u00b2 = \u2016x\u2016\u00b2 + \u2016y\u2016\u00b2 \u2212 2 x\u00b7y for efficiency.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Array of shape (n, d).</p> required <p>Returns:</p> Name Type Description <code>ndarray</code> <code>ndarray</code> <p>Matrix of shape (n, n) where entry (i, j) is squared distance.</p> Source code in <code>code\\voltage.py</code> <pre><code>def efficientSquareDistance(self, data: np.ndarray) -&gt; np.ndarray:\n\t\"\"\"\n\tComputes the pairwise squared Euclidean distances of the rows in `data`.\n\n\tUses the identity \u2016x\u2212y\u2016\u00b2 = \u2016x\u2016\u00b2 + \u2016y\u2016\u00b2 \u2212 2 x\u00b7y for efficiency.\n\n\tArgs:\n\t\tdata (ndarray): Array of shape (n, d).\n\n\tReturns:\n\t\tndarray: Matrix of shape (n, n) where entry (i, j) is squared distance.\n\t\"\"\"\n\tdata_norm2 = np.sum(data**2, axis=1)\n\tx_norm2 = data_norm2.reshape(-1, 1)\n\ty_norm2 = data_norm2.reshape(1, -1)\n\treturn x_norm2 + y_norm2 - 2 * data @ data.T\n</code></pre>"},{"location":"reference/#code.voltage.Problem.gaussiankernel","title":"<code>gaussiankernel(data, std)</code>","text":"<p>Builds a Gaussian (RBF) kernel matrix.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Array of shape (n, d).</p> required <code>std</code> <code>float</code> <p>Standard deviation parameter for the Gaussian.</p> required <p>Returns:</p> Name Type Description <code>ndarray</code> <code>ndarray</code> <p>Kernel matrix of shape (n, n).</p> Source code in <code>code\\voltage.py</code> <pre><code>def gaussiankernel(self, data: np.ndarray, std: float) -&gt; np.ndarray:\n\t\"\"\"\n\tBuilds a Gaussian (RBF) kernel matrix.\n\n\tArgs:\n\t\tdata (ndarray): Array of shape (n, d).\n\t\tstd (float): Standard deviation parameter for the Gaussian.\n\n\tReturns:\n\t\tndarray: Kernel matrix of shape (n, n).\n\t\"\"\"\n\tdist2 = self.efficientSquareDistance(data)\n\treturn np.exp(-dist2 / (2 * std**2))\n</code></pre>"},{"location":"reference/#code.voltage.Problem.normalizeWeights","title":"<code>normalizeWeights()</code>","text":"<p>Normalizes each row of the weight matrix to sum to 1.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If any row sums to zero, resulting in NaNs.</p> Source code in <code>code\\voltage.py</code> <pre><code>def normalizeWeights(self) -&gt; None:\n\t\"\"\"\n\tNormalizes each row of the weight matrix to sum to 1.\n\n\tRaises:\n\t\tValueError: If any row sums to zero, resulting in NaNs.\n\t\"\"\"\n\tself.weights = self.weights / self.weights.sum(axis=1, keepdims=True)\n\tif np.isnan(self.weights).any():\n\t\traise ValueError(\"Array contains NaN values!\")\n</code></pre>"},{"location":"reference/#code.voltage.Problem.radialkernel","title":"<code>radialkernel(data, r)</code>","text":"<p>Builds a binary (0/1) radial kernel: 1 if distance \u2264 r, else 0.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Array of shape (n, d).</p> required <code>r</code> <code>float</code> <p>Radius threshold.</p> required <p>Returns:</p> Name Type Description <code>ndarray</code> <code>ndarray</code> <p>Adjacency-like matrix (n\u00d7n) of 0/1 floats.</p> Source code in <code>code\\voltage.py</code> <pre><code>def radialkernel(self, data: np.ndarray, r: float) -&gt; np.ndarray:\n\t\"\"\"\n\tBuilds a binary (0/1) radial kernel: 1 if distance \u2264 r, else 0.\n\n\tArgs:\n\t\tdata (ndarray): Array of shape (n, d).\n\t\tr (float): Radius threshold.\n\n\tReturns:\n\t\tndarray: Adjacency-like matrix (n\u00d7n) of 0/1 floats.\n\t\"\"\"\n\tdist2 = self.efficientSquareDistance(data)\n\treturn (dist2 &lt;= r**2).astype(float)\n</code></pre>"},{"location":"reference/#code.voltage.Problem.setKernel","title":"<code>setKernel(kernel)</code>","text":"<p>Sets the kernel function to use for weight computations.</p> <p>Parameters:</p> Name Type Description Default <code>kernel</code> <code>callable</code> <p>A function or callable object with signature                            kernel(X, Y, *params) \u2192 ndarray of shape (|X|, |Y|).</p> required Source code in <code>code\\voltage.py</code> <pre><code>def setKernel(self, kernel: Callable[..., np.ndarray]) -&gt; None:\n\t\"\"\"\n\tSets the kernel function to use for weight computations.\n\n\tArgs:\n\t\tkernel (callable): A function or callable object with signature\n\t\t\t\t\t\t   kernel(X, Y, *params) \u2192 ndarray of shape (|X|, |Y|).\n\t\"\"\"\n\tself.kernel = kernel\n</code></pre>"},{"location":"reference/#code.voltage.Problem.setPartitionWeights","title":"<code>setPartitionWeights(partition, *c)</code>","text":"<p>Computes and normalizes weights based on cluster centers and sizes.</p> <p>Parameters:</p> Name Type Description Default <code>partition</code> <code>Any</code> <p>An object with attributes <code>centers</code> (list of points)            and <code>point_counts</code> (counts per center).</p> required <code>*c</code> <code>Any</code> <p>Parameters to pass into the kernel function.</p> <code>()</code> <p>Returns:</p> Name Type Description <code>ndarray</code> <code>ndarray</code> <p>The normalized weight matrix for the partition block.</p> Source code in <code>code\\voltage.py</code> <pre><code>def setPartitionWeights(self, partition: Any, *c: Any) -&gt; np.ndarray:\n\t\"\"\"\n\tComputes and normalizes weights based on cluster centers and sizes.\n\n\tArgs:\n\t\tpartition: An object with attributes `centers` (list of points)\n\t\t\t\t   and `point_counts` (counts per center).\n\t\t*c: Parameters to pass into the kernel function.\n\n\tReturns:\n\t\tndarray: The normalized weight matrix for the partition block.\n\t\"\"\"\n\tcenters = np.array(partition.centers)\n\tcounts = np.array(partition.point_counts).reshape(-1, 1)\n\tK = self.kernel(centers[:, None], centers[None, :], *c)\n\tW = K * (counts @ counts.T)\n\tn = len(centers)\n\tself.weights[:n, :n] = W\n\tself.normalizeWeights()\n\treturn self.weights\n</code></pre>"},{"location":"reference/#code.voltage.Problem.setWeights","title":"<code>setWeights(*c)</code>","text":"<p>Computes and normalizes the weight matrix on the original data.</p> <p>Parameters:</p> Name Type Description Default <code>*c</code> <code>Any</code> <p>Parameters to pass into the currently set kernel function.</p> <code>()</code> <p>Returns:</p> Name Type Description <code>ndarray</code> <code>ndarray</code> <p>The normalized weight matrix (n\u00d7n).</p> Source code in <code>code\\voltage.py</code> <pre><code>def setWeights(self, *c: Any) -&gt; np.ndarray:\n\t\"\"\"\n\tComputes and normalizes the weight matrix on the original data.\n\n\tArgs:\n\t\t*c: Parameters to pass into the currently set kernel function.\n\n\tReturns:\n\t\tndarray: The normalized weight matrix (n\u00d7n).\n\t\"\"\"\n\tdata_np = self.data.getNumpy()\n\tn = len(self.data)\n\tself.weights[:n, :n] = self.kernel(data_np, *c)\n\tself.normalizeWeights()\n\treturn self.weights\n</code></pre>"},{"location":"reference/#code.voltage.Problem.timeEnd","title":"<code>timeEnd(replace=True)</code>","text":"<p>Computes the elapsed time since the last timeStart().</p> <p>Parameters:</p> Name Type Description Default <code>replace</code> <code>bool</code> <p>If True, resets the start time to now.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>Seconds elapsed since last start.</p> Source code in <code>code\\voltage.py</code> <pre><code>def timeEnd(self, replace: bool = True) -&gt; float:\n\t\"\"\"\n\tComputes the elapsed time since the last timeStart().\n\n\tArgs:\n\t\treplace (bool): If True, resets the start time to now.\n\n\tReturns:\n\t\tfloat: Seconds elapsed since last start.\n\t\"\"\"\n\tcur_time = time.time()\n\tdiff = cur_time - self.start\n\tif replace:\n\t\tself.start = cur_time\n\treturn diff\n</code></pre>"},{"location":"reference/#code.voltage.Problem.timeStart","title":"<code>timeStart()</code>","text":"<p>Records the current time to measure elapsed intervals.</p> Source code in <code>code\\voltage.py</code> <pre><code>def timeStart(self) -&gt; None:\n\t\"\"\"\n\tRecords the current time to measure elapsed intervals.\n\t\"\"\"\n\tself.start = time.time()\n</code></pre>"},{"location":"reference/#code.voltage.Solver","title":"<code>Solver</code>","text":"<p>               Bases: <code>DistanceBased</code></p> <p>Solves a given Problem</p> Source code in <code>code\\voltage.py</code> <pre><code>class Solver(kmeans.DistanceBased):\n\t\"\"\"Solves a given Problem\"\"\"\n\tdef __init__(self, problem):\n\t\tself.problem = problem\n\t\tsuper().__init__()\n\n\tdef compute_voltages(self):\n\t\tn = self.problem.weights.shape[0]\n\n\t\tconstrained_nodes =   [l.index for l in self.problem.landmarks]\n\t\tunconstrained_nodes = [i for i in range(n) if i not in constrained_nodes]\n\n\t\tb = np.zeros(n)\n\t\tfor landmark in self.problem.landmarks:\n\t\t\tfor y in range(0, n):\n\t\t\t\tb[y] += landmark.voltage * self.problem.weights[y][landmark.index]\n\n\t\tA_unconstrained = np.identity(len(unconstrained_nodes)) - self.problem.weights[np.ix_(unconstrained_nodes, unconstrained_nodes)]\n\n\t\tb_unconstrained = b[unconstrained_nodes]\n\n\t\t# print(self.problem.weights)\n\t\t# print(A_unconstrained)\n\t\t# print(b_unconstrained)\n\n\t\tv_unconstrained = solve(A_unconstrained, b_unconstrained)\n\n\t\t# print(v_unconstrained)\n\n\t\tself.voltages = np.zeros(n)\n\n\t\tfor landmark in self.problem.landmarks:\n\t\t\tself.voltages[landmark.index] = landmark.voltage\n\n\t\tself.voltages[unconstrained_nodes] = v_unconstrained\n\n\t\tif (self.problem.universalGround):\n\t\t\tself.voltages = self.voltages[:-1]\n\n\t\treturn self.voltages\n\n\tdef approximate_voltages(self, epsilon=None, max_iters=None):\n\t\tn = self.problem.weights.shape[0]\n\n\t\tif (epsilon == None):\n\t\t\tif (max_iters == None):\n\t\t\t\tepsilon = 1 / n\n\n\t\tconstrained_nodes =\t\t[l.index for l in self.problem.landmarks]\n\t\tconstraints = \t\t\t[l.voltage for l in self.problem.landmarks]\n\t\tunconstrained_nodes =\t[i for i in range(n) if i not in constrained_nodes]\n\n\t\tself.voltages = np.zeros(n)\n\t\tvoltages = np.zeros(n)\n\n\t\tfor landmark in self.problem.landmarks:\n\t\t\tself.voltages[landmark.index] = landmark.voltage\n\n\t\tdist = self.distance(self.voltages, voltages)\n\t\tprev_dist = float('inf')\n\n\t\titerations = 0\n\n\t\twhile (((epsilon != None and dist &gt; epsilon * len(self.problem.data)) or (max_iters != None and iterations &lt; max_iters)) and dist &lt; prev_dist):\n\t\t\tvoltages = np.matmul(self.problem.weights, self.voltages)\n\t\t\tvoltages[constrained_nodes] = constraints\n\t\t\tprev_dist = dist\n\t\t\tdist = self.distance(self.voltages, voltages)\n\n\t\t\t# print(prev_dist, dist)\n\n\t\t\tself.voltages = voltages\n\t\t\titerations += 1\n\n\t\t# print(iterations)\n\n\t\tif (self.problem.universalGround):\n\t\t\tself.voltages = self.voltages[:-1]\n\n\t\treturn self.voltages\n\n\tdef localSolver(self, partitions, c):\n\t\tvoltages = [0 for i in range(len(self.problem.data))]\n\n\t\tfor index in range(partitions.k):\n\t\t\tclosestIndicies = partitions.getClosestPoints(index)\n\t\t\tcloseproblem.LandmarksIndicies = []\n\n\t\t\tfor pair in partitions.voronoi.ridge_points:\n\t\t\t\tif pair[0] == index:\n\t\t\t\t\tcloseproblem.LandmarksIndicies.append(pair[1])\n\t\t\t\tif pair[1] == index:\n\t\t\t\t\tcloseproblem.LandmarksIndicies.append(pair[0])\n\n\t\t\tcloseproblem.Landmarks = []\n\t\t\tfor cli in closeproblem.LandmarksIndicies:\n\t\t\t\tcloseproblem.Landmarks.append(Landmark(cli, self.voltages[cli]))\n\n\t\t\tlocalSolver = Solver(self.problem.data.getSubSet(closestIndicies))\n\t\t\tlocalSolver.setKernel(self.problem.gaussiankernel)\n\t\t\tlocalSolver.setWeights(c)\n\t\t\tlocalSolver.addproblem.Landmarks(closeproblem.Landmarks)\n\t\t\tlocalVoltages = localSolver.compute_voltages()\n\n\t\t\tfor i, v in zip(closestIndicies, localVoltages):\n\t\t\t\tvoltages[i] = v\n\n\t\treturn voltages\n</code></pre>"}]}