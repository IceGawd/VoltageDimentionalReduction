{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"reference/","title":"Reference","text":""},{"location":"reference/#code.bpf.BestParameterFinder","title":"<code>BestParameterFinder</code>","text":"Source code in <code>code\\bpf.py</code> <pre><code>class BestParameterFinder:\n    def __init__(self, metric: Optional[Callable[[\"BestParameterFinder\", np.ndarray], float]] = None):\n        \"\"\"\n        Initializes the BestParameterFinder.\n\n        Args:\n            metric (Optional[Callable[[BestParameterFinder, np.ndarray], float]]):\n                A custom metric function. Defaults to `expWithStd`.\n        \"\"\"\n        self.metric = metric or self.expWithStd\n        self.p_g: Optional[float] = None\n        self.c: Optional[float] = None\n\n    def nInfUniform(self, voltages: np.ndarray) -&gt; float:\n        \"\"\"\n        Computes the infinity-norm distance between voltages and a uniform distribution.\n\n        Args:\n            voltages (np.ndarray): Array of voltage values.\n\n        Returns:\n            float: Infinity-norm distance.\n        \"\"\"\n        voltages.sort()\n        uniform = np.array([x / (len(voltages) - 1) for x in range(len(voltages))])\n        return np.linalg.norm(abs(voltages - uniform))\n\n    def nInfExp(self, voltages: np.ndarray, base: float = 10) -&gt; float:\n        \"\"\"\n        Computes the infinity-norm distance between voltages and an exponential distribution.\n\n        Args:\n            voltages (np.ndarray): Array of voltage values.\n            base (float): Base of the exponential function. Defaults to 10.\n\n        Returns:\n            float: Infinity-norm distance.\n        \"\"\"\n        global dist\n        voltages.sort()\n        if len(dist) != len(voltages):\n            dist = np.array([np.power(base, (x / (len(voltages) - 1)) - 1) for x in range(len(voltages))])\n        return np.linalg.norm(abs(voltages - dist))\n\n    def median(self, voltages: np.ndarray, value: float = 0.5) -&gt; float:\n        \"\"\"\n        Computes the absolute difference between the median voltage and a given value.\n\n        Args:\n            voltages (np.ndarray): Array of voltage values.\n            value (float): Value to compare the median to. Defaults to 0.5.\n\n        Returns:\n            float: Absolute difference from the median.\n        \"\"\"\n        voltages.sort()\n        return abs(voltages[int(len(voltages) / 2)] - value)\n\n    def minimum(self, voltages: np.ndarray, value: float = 0.1) -&gt; float:\n        \"\"\"\n        Computes the absolute difference between the minimum voltage and a given value.\n\n        Args:\n            voltages (np.ndarray): Array of voltage values.\n            value (float): Value to compare the minimum to. Defaults to 0.1.\n\n        Returns:\n            float: Absolute difference from the minimum.\n        \"\"\"\n        voltages.sort()\n        return abs(voltages[0] - value)\n\n    def minWithStd(self, voltages: np.ndarray, value: float = 0.1) -&gt; float:\n        \"\"\"\n        Computes the normalized difference between the minimum voltage and a given value.\n\n        Args:\n            voltages (np.ndarray): Array of voltage values.\n            value (float): Value to compare the minimum to. Defaults to 0.1.\n\n        Returns:\n            float: Normalized absolute difference using standard deviation.\n        \"\"\"\n        voltages.sort()\n        return abs(voltages[0] - value) / np.std(voltages)\n\n    def expWithStd(self, voltages: np.ndarray, base: float = 10) -&gt; float:\n        \"\"\"\n        Computes the normalized exponential distance.\n\n        Args:\n            voltages (np.ndarray): Array of voltage values.\n            base (float): Base of the exponential. Defaults to 10.\n\n        Returns:\n            float: Normalized exponential distance.\n        \"\"\"\n        return self.nInfExp(voltages, base) / np.std(voltages)\n\n    def setResistanceToGround(self, p_g: float) -&gt; None:\n        \"\"\"\n        Sets the resistance to ground parameter.\n\n        Args:\n            p_g (float): Resistance to ground value (logarithmic scale will be used).\n        \"\"\"\n        self.p_g = np.log(p_g)\n\n    def setKernelParameter(self, c: float) -&gt; None:\n        \"\"\"\n        Sets the kernel parameter.\n\n        Args:\n            c (float): Kernel parameter (logarithmic scale will be used).\n        \"\"\"\n        self.c = np.log(c)\n\n    def calculateFor(\n        self,\n        landmarks: List,\n        data: Union[create_data.Data, kmeans.Partitions],\n        c: float,\n        p_g: float,\n        approx: bool = False,\n        approx_epsilon: Optional[float] = None,\n        approx_iters: Optional[int] = None\n    ) -&gt; Union[float, tuple[np.ndarray, voltage.Problem]]:\n        \"\"\"\n        Calculates voltages and applies the metric.\n\n        Args:\n            landmarks (List): Landmarks to add to the problem.\n            data (Union[create_data.Data, kmeans.Partitions]): Input data.\n            c (float): Kernel parameter (log space).\n            p_g (float): Resistance to ground (log space).\n            approx (bool): Whether to use approximation. Defaults to False.\n            approx_epsilon (Optional[float]): Epsilon value for approximation.\n            approx_iters (Optional[int]): Number of approximation iterations.\n\n        Returns:\n            Union[float, tuple[np.ndarray, voltage.Problem]]: Metric value or voltages and problem.\n        \"\"\"\n\n    def bestParameterFinder(\n        self,\n        landmarks: List,\n        data: Union[create_data.Data, kmeans.Partitions],\n        minBound: float = -25,\n        maxBound: float = -1,\n        granularity: int = 5,\n        epsilon: float = 1,\n        approx: Optional[int] = None\n    ) -&gt; tuple[float, float]:\n        \"\"\"\n        Finds optimal (C, P_G) parameters minimizing the metric.\n\n        Args:\n            landmarks (List): Landmarks to use in solving.\n            data (Union[create_data.Data, kmeans.Partitions]): Input dataset.\n            minBound (float): Minimum log-bound for search. Defaults to -25.\n            maxBound (float): Maximum log-bound for search. Defaults to -1.\n            granularity (int): Granularity of grid search. Defaults to 5.\n            epsilon (float): Precision threshold. Defaults to 1.\n            approx (Optional[int]): Approximation iteration count. Defaults to None.\n\n        Returns:\n            tuple[float, float]: Best (C, P_G) parameters (in real scale).\n        \"\"\"\n\n    def visualizations(self, voltages: List[np.ndarray], fileStarter: str) -&gt; None:\n        \"\"\"\n        Generates and saves PCA and MDS visualizations of the voltage data.\n\n        Args:\n            voltages (List[np.ndarray]): List of voltage arrays.\n            fileStarter (str): File name prefix for saving plots.\n\n        Returns:\n            None\n        \"\"\"\n</code></pre>"},{"location":"reference/#code.bpf.BestParameterFinder.__init__","title":"<code>__init__(metric=None)</code>","text":"<p>Initializes the BestParameterFinder.</p> <p>Parameters:</p> Name Type Description Default <code>metric</code> <code>Optional[Callable[[BestParameterFinder, ndarray], float]]</code> <p>A custom metric function. Defaults to <code>expWithStd</code>.</p> <code>None</code> Source code in <code>code\\bpf.py</code> <pre><code>def __init__(self, metric: Optional[Callable[[\"BestParameterFinder\", np.ndarray], float]] = None):\n    \"\"\"\n    Initializes the BestParameterFinder.\n\n    Args:\n        metric (Optional[Callable[[BestParameterFinder, np.ndarray], float]]):\n            A custom metric function. Defaults to `expWithStd`.\n    \"\"\"\n    self.metric = metric or self.expWithStd\n    self.p_g: Optional[float] = None\n    self.c: Optional[float] = None\n</code></pre>"},{"location":"reference/#code.bpf.BestParameterFinder.bestParameterFinder","title":"<code>bestParameterFinder(landmarks, data, minBound=-25, maxBound=-1, granularity=5, epsilon=1, approx=None)</code>","text":"<p>Finds optimal (C, P_G) parameters minimizing the metric.</p> <p>Parameters:</p> Name Type Description Default <code>landmarks</code> <code>List</code> <p>Landmarks to use in solving.</p> required <code>data</code> <code>Union[Data, Partitions]</code> <p>Input dataset.</p> required <code>minBound</code> <code>float</code> <p>Minimum log-bound for search. Defaults to -25.</p> <code>-25</code> <code>maxBound</code> <code>float</code> <p>Maximum log-bound for search. Defaults to -1.</p> <code>-1</code> <code>granularity</code> <code>int</code> <p>Granularity of grid search. Defaults to 5.</p> <code>5</code> <code>epsilon</code> <code>float</code> <p>Precision threshold. Defaults to 1.</p> <code>1</code> <code>approx</code> <code>Optional[int]</code> <p>Approximation iteration count. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple[float, float]</code> <p>tuple[float, float]: Best (C, P_G) parameters (in real scale).</p> Source code in <code>code\\bpf.py</code> <pre><code>def bestParameterFinder(\n    self,\n    landmarks: List,\n    data: Union[create_data.Data, kmeans.Partitions],\n    minBound: float = -25,\n    maxBound: float = -1,\n    granularity: int = 5,\n    epsilon: float = 1,\n    approx: Optional[int] = None\n) -&gt; tuple[float, float]:\n    \"\"\"\n    Finds optimal (C, P_G) parameters minimizing the metric.\n\n    Args:\n        landmarks (List): Landmarks to use in solving.\n        data (Union[create_data.Data, kmeans.Partitions]): Input dataset.\n        minBound (float): Minimum log-bound for search. Defaults to -25.\n        maxBound (float): Maximum log-bound for search. Defaults to -1.\n        granularity (int): Granularity of grid search. Defaults to 5.\n        epsilon (float): Precision threshold. Defaults to 1.\n        approx (Optional[int]): Approximation iteration count. Defaults to None.\n\n    Returns:\n        tuple[float, float]: Best (C, P_G) parameters (in real scale).\n    \"\"\"\n</code></pre>"},{"location":"reference/#code.bpf.BestParameterFinder.calculateFor","title":"<code>calculateFor(landmarks, data, c, p_g, approx=False, approx_epsilon=None, approx_iters=None)</code>","text":"<p>Calculates voltages and applies the metric.</p> <p>Parameters:</p> Name Type Description Default <code>landmarks</code> <code>List</code> <p>Landmarks to add to the problem.</p> required <code>data</code> <code>Union[Data, Partitions]</code> <p>Input data.</p> required <code>c</code> <code>float</code> <p>Kernel parameter (log space).</p> required <code>p_g</code> <code>float</code> <p>Resistance to ground (log space).</p> required <code>approx</code> <code>bool</code> <p>Whether to use approximation. Defaults to False.</p> <code>False</code> <code>approx_epsilon</code> <code>Optional[float]</code> <p>Epsilon value for approximation.</p> <code>None</code> <code>approx_iters</code> <code>Optional[int]</code> <p>Number of approximation iterations.</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[float, tuple[ndarray, Problem]]</code> <p>Union[float, tuple[np.ndarray, voltage.Problem]]: Metric value or voltages and problem.</p> Source code in <code>code\\bpf.py</code> <pre><code>def calculateFor(\n    self,\n    landmarks: List,\n    data: Union[create_data.Data, kmeans.Partitions],\n    c: float,\n    p_g: float,\n    approx: bool = False,\n    approx_epsilon: Optional[float] = None,\n    approx_iters: Optional[int] = None\n) -&gt; Union[float, tuple[np.ndarray, voltage.Problem]]:\n    \"\"\"\n    Calculates voltages and applies the metric.\n\n    Args:\n        landmarks (List): Landmarks to add to the problem.\n        data (Union[create_data.Data, kmeans.Partitions]): Input data.\n        c (float): Kernel parameter (log space).\n        p_g (float): Resistance to ground (log space).\n        approx (bool): Whether to use approximation. Defaults to False.\n        approx_epsilon (Optional[float]): Epsilon value for approximation.\n        approx_iters (Optional[int]): Number of approximation iterations.\n\n    Returns:\n        Union[float, tuple[np.ndarray, voltage.Problem]]: Metric value or voltages and problem.\n    \"\"\"\n</code></pre>"},{"location":"reference/#code.bpf.BestParameterFinder.expWithStd","title":"<code>expWithStd(voltages, base=10)</code>","text":"<p>Computes the normalized exponential distance.</p> <p>Parameters:</p> Name Type Description Default <code>voltages</code> <code>ndarray</code> <p>Array of voltage values.</p> required <code>base</code> <code>float</code> <p>Base of the exponential. Defaults to 10.</p> <code>10</code> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>Normalized exponential distance.</p> Source code in <code>code\\bpf.py</code> <pre><code>def expWithStd(self, voltages: np.ndarray, base: float = 10) -&gt; float:\n    \"\"\"\n    Computes the normalized exponential distance.\n\n    Args:\n        voltages (np.ndarray): Array of voltage values.\n        base (float): Base of the exponential. Defaults to 10.\n\n    Returns:\n        float: Normalized exponential distance.\n    \"\"\"\n    return self.nInfExp(voltages, base) / np.std(voltages)\n</code></pre>"},{"location":"reference/#code.bpf.BestParameterFinder.median","title":"<code>median(voltages, value=0.5)</code>","text":"<p>Computes the absolute difference between the median voltage and a given value.</p> <p>Parameters:</p> Name Type Description Default <code>voltages</code> <code>ndarray</code> <p>Array of voltage values.</p> required <code>value</code> <code>float</code> <p>Value to compare the median to. Defaults to 0.5.</p> <code>0.5</code> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>Absolute difference from the median.</p> Source code in <code>code\\bpf.py</code> <pre><code>def median(self, voltages: np.ndarray, value: float = 0.5) -&gt; float:\n    \"\"\"\n    Computes the absolute difference between the median voltage and a given value.\n\n    Args:\n        voltages (np.ndarray): Array of voltage values.\n        value (float): Value to compare the median to. Defaults to 0.5.\n\n    Returns:\n        float: Absolute difference from the median.\n    \"\"\"\n    voltages.sort()\n    return abs(voltages[int(len(voltages) / 2)] - value)\n</code></pre>"},{"location":"reference/#code.bpf.BestParameterFinder.minWithStd","title":"<code>minWithStd(voltages, value=0.1)</code>","text":"<p>Computes the normalized difference between the minimum voltage and a given value.</p> <p>Parameters:</p> Name Type Description Default <code>voltages</code> <code>ndarray</code> <p>Array of voltage values.</p> required <code>value</code> <code>float</code> <p>Value to compare the minimum to. Defaults to 0.1.</p> <code>0.1</code> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>Normalized absolute difference using standard deviation.</p> Source code in <code>code\\bpf.py</code> <pre><code>def minWithStd(self, voltages: np.ndarray, value: float = 0.1) -&gt; float:\n    \"\"\"\n    Computes the normalized difference between the minimum voltage and a given value.\n\n    Args:\n        voltages (np.ndarray): Array of voltage values.\n        value (float): Value to compare the minimum to. Defaults to 0.1.\n\n    Returns:\n        float: Normalized absolute difference using standard deviation.\n    \"\"\"\n    voltages.sort()\n    return abs(voltages[0] - value) / np.std(voltages)\n</code></pre>"},{"location":"reference/#code.bpf.BestParameterFinder.minimum","title":"<code>minimum(voltages, value=0.1)</code>","text":"<p>Computes the absolute difference between the minimum voltage and a given value.</p> <p>Parameters:</p> Name Type Description Default <code>voltages</code> <code>ndarray</code> <p>Array of voltage values.</p> required <code>value</code> <code>float</code> <p>Value to compare the minimum to. Defaults to 0.1.</p> <code>0.1</code> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>Absolute difference from the minimum.</p> Source code in <code>code\\bpf.py</code> <pre><code>def minimum(self, voltages: np.ndarray, value: float = 0.1) -&gt; float:\n    \"\"\"\n    Computes the absolute difference between the minimum voltage and a given value.\n\n    Args:\n        voltages (np.ndarray): Array of voltage values.\n        value (float): Value to compare the minimum to. Defaults to 0.1.\n\n    Returns:\n        float: Absolute difference from the minimum.\n    \"\"\"\n    voltages.sort()\n    return abs(voltages[0] - value)\n</code></pre>"},{"location":"reference/#code.bpf.BestParameterFinder.nInfExp","title":"<code>nInfExp(voltages, base=10)</code>","text":"<p>Computes the infinity-norm distance between voltages and an exponential distribution.</p> <p>Parameters:</p> Name Type Description Default <code>voltages</code> <code>ndarray</code> <p>Array of voltage values.</p> required <code>base</code> <code>float</code> <p>Base of the exponential function. Defaults to 10.</p> <code>10</code> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>Infinity-norm distance.</p> Source code in <code>code\\bpf.py</code> <pre><code>def nInfExp(self, voltages: np.ndarray, base: float = 10) -&gt; float:\n    \"\"\"\n    Computes the infinity-norm distance between voltages and an exponential distribution.\n\n    Args:\n        voltages (np.ndarray): Array of voltage values.\n        base (float): Base of the exponential function. Defaults to 10.\n\n    Returns:\n        float: Infinity-norm distance.\n    \"\"\"\n    global dist\n    voltages.sort()\n    if len(dist) != len(voltages):\n        dist = np.array([np.power(base, (x / (len(voltages) - 1)) - 1) for x in range(len(voltages))])\n    return np.linalg.norm(abs(voltages - dist))\n</code></pre>"},{"location":"reference/#code.bpf.BestParameterFinder.nInfUniform","title":"<code>nInfUniform(voltages)</code>","text":"<p>Computes the infinity-norm distance between voltages and a uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>voltages</code> <code>ndarray</code> <p>Array of voltage values.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>Infinity-norm distance.</p> Source code in <code>code\\bpf.py</code> <pre><code>def nInfUniform(self, voltages: np.ndarray) -&gt; float:\n    \"\"\"\n    Computes the infinity-norm distance between voltages and a uniform distribution.\n\n    Args:\n        voltages (np.ndarray): Array of voltage values.\n\n    Returns:\n        float: Infinity-norm distance.\n    \"\"\"\n    voltages.sort()\n    uniform = np.array([x / (len(voltages) - 1) for x in range(len(voltages))])\n    return np.linalg.norm(abs(voltages - uniform))\n</code></pre>"},{"location":"reference/#code.bpf.BestParameterFinder.setKernelParameter","title":"<code>setKernelParameter(c)</code>","text":"<p>Sets the kernel parameter.</p> <p>Parameters:</p> Name Type Description Default <code>c</code> <code>float</code> <p>Kernel parameter (logarithmic scale will be used).</p> required Source code in <code>code\\bpf.py</code> <pre><code>def setKernelParameter(self, c: float) -&gt; None:\n    \"\"\"\n    Sets the kernel parameter.\n\n    Args:\n        c (float): Kernel parameter (logarithmic scale will be used).\n    \"\"\"\n    self.c = np.log(c)\n</code></pre>"},{"location":"reference/#code.bpf.BestParameterFinder.setResistanceToGround","title":"<code>setResistanceToGround(p_g)</code>","text":"<p>Sets the resistance to ground parameter.</p> <p>Parameters:</p> Name Type Description Default <code>p_g</code> <code>float</code> <p>Resistance to ground value (logarithmic scale will be used).</p> required Source code in <code>code\\bpf.py</code> <pre><code>def setResistanceToGround(self, p_g: float) -&gt; None:\n    \"\"\"\n    Sets the resistance to ground parameter.\n\n    Args:\n        p_g (float): Resistance to ground value (logarithmic scale will be used).\n    \"\"\"\n    self.p_g = np.log(p_g)\n</code></pre>"},{"location":"reference/#code.bpf.BestParameterFinder.visualizations","title":"<code>visualizations(voltages, fileStarter)</code>","text":"<p>Generates and saves PCA and MDS visualizations of the voltage data.</p> <p>Parameters:</p> Name Type Description Default <code>voltages</code> <code>List[ndarray]</code> <p>List of voltage arrays.</p> required <code>fileStarter</code> <code>str</code> <p>File name prefix for saving plots.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>code\\bpf.py</code> <pre><code>def visualizations(self, voltages: List[np.ndarray], fileStarter: str) -&gt; None:\n    \"\"\"\n    Generates and saves PCA and MDS visualizations of the voltage data.\n\n    Args:\n        voltages (List[np.ndarray]): List of voltage arrays.\n        fileStarter (str): File name prefix for saving plots.\n\n    Returns:\n        None\n    \"\"\"\n</code></pre>"},{"location":"reference/#code.create_data.Data","title":"<code>Data</code>","text":"<p>Class for handling and processing data sets.</p> Source code in <code>code\\create_data.py</code> <pre><code>class Data():\n\t\"\"\"Class for handling and processing data sets.\"\"\"\n\tdef __init__(self, arg=None, stream=False):\n\t\tself.stream = stream\n\n\t\tif isinstance(arg, list):\n\t\t\tself.data = np.array(arg)\n\t\t\tself.length = len(self.data)\n\t\telif isinstance(arg, str):\n\t\t\tif (stream):\n\t\t\t\tself.data = self.stream_data_json(arg)\n\t\t\t\tself.length = next(self.data)\n\t\t\t\tself.i = 0\n\t\t\telse:\n\t\t\t\tself.load_data(arg)\n\t\t\t\tself.length = len(self.data)\n\n\t\t\tself.input_file = arg\n\t\telse:\n\t\t\tself.data = arg\n\t\t\tself.length = len(self.data)\n\n\t# Len can run on Data\n\tdef __len__(self):\n\t\treturn self.length\n\n\t# Data can be get indexed\n\tdef __getitem__(self, index):\n\t\tif (self.stream):\n\t\t\tif (index &lt; self.i):\n\t\t\t\tself.data = self.stream_data_json(self.input_file)\n\t\t\t\tnext(self.data)\n\t\t\t\tself.i = 0\n\n\t\t\twhile (self.i &lt;= index):\n\t\t\t\tvalue = next(self.data)\n\t\t\t\tself.i += 1\n\n\t\t\treturn value\n\t\telse:\n\t\t\treturn self.data[index]\n\n\t# \"\"\"\n\tdef __setitem__(self, index, value):\n\t\tself.data[index] = value\n\t# \"\"\"\n\n\t# Make Data able to be for looped\n\tdef __iter__(self):\n\t\tif (hasattr(self, 'input_file')):\n\t\t\tself.streaming_data = self.stream_data_json(self.input_file)\n\t\t\tnext(self.streaming_data)\n\t\telse:\n\t\t\tself.streaming_data = 0\n\n\t\treturn self\n\n\tdef __next__(self):\n\t\ttry:\n\t\t\tif (hasattr(self, 'input_file')):\n\t\t\t\treturn np.array(next(self.streaming_data))\n\t\t\telse:\n\t\t\t\tif (self.streaming_data == self.length):\n\t\t\t\t\traise\n\t\t\t\telse:\n\t\t\t\t\treturn np.array(self.data[self.streaming_data])\n\n\t\t\t\tself.streaming_data += 1\n\t\texcept StopIteration:\n\t\t\traise\n\n\tdef getSubSet(self, indexList):\n\t\t\"\"\"Returns a subset of the data given a list of indices.\"\"\"\n\t\tsubset = []\n\t\tfor index in indexList:\n\t\t\tsubset.append(self.data[index])\n\t\treturn Data(subset)\n\n\tdef save_data_json(self, output_file):\n\t\tfg = FileGenerator()\n\t\tfg.setGenerator(fg.linear_generator)\n\t\tfg.stream_save(output_file, self.data)\n\n\tdef save_data_pickle(self, output_file):\n\t\twith open(output_file, 'wb') as f: \n\t\t\tpickle.dump(self.data, f) \n\n\tdef load_data_json(self, input_file):\n\t\twith open(input_file, 'r') as f:\n\t\t\tself.input_file = input_file\n\n\t\t\tdata = json.load(f)\n\t\t\tself.data = data[\"data\"]\n\t\t\tself.length = data[\"length\"]\n\t\t\tfor i, point in enumerate(self.data):\n\t\t\t\tself.data[i] = np.array(point)\n\n\t\t\treturn self.data\n\n\tdef load_data_pickle(self, input_file):\n\t\twith open(input_file, 'r') as f:\n\t\t\tself.input_file = input_file\n\t\t\tself.data = pickle.load(f)\n\n\t\t\treturn self.data\n\n\tdef stream_data_json(self, input_file):\n\t\t\"\"\"Stream the dataset if its saved in a json file\"\"\"\n\t\twith open(input_file, 'rb') as f:\n\t\t\tf.seek(0, 2)\n\t\t\tposition = f.tell()\n\n\t\t\tvalue = \"\"\n\t\t\tread = False\n\t\t\twhile position &gt; 0:\n\t\t\t\tposition -= 1\n\t\t\t\tf.seek(position)\n\t\t\t\tbyte = f.read(1)\n\n\t\t\t\tif byte == b' ':\n\t\t\t\t\t# print(value)\n\t\t\t\t\tyield int(value)\n\t\t\t\t\tbreak\n\n\t\t\t\tif (read):\n\t\t\t\t\tvalue = byte.decode() + value\n\n\t\t\t\tif byte == b'}':\n\t\t\t\t\tread = True\n\n\t\twith open(input_file, 'r') as f:\n\t\t\tf.readline()\n\n\t\t\tfor line in f:\n\t\t\t\tif (\"length\" in line):\n\t\t\t\t\tbreak\n\n\t\t\t\tdata = json.loads(line.strip().split(']')[0] + ']')\n\t\t\t\tyield np.array(data)\n\n\tfile_function_pairs = [[\"json\", save_data_json, load_data_json], [\"pkl\", save_data_pickle, load_data_pickle]]\n\n\tdef data_function(self, file, save_or_load):\n\t\t\"\"\"Used for saving and loading the dataset\"\"\"\n\t\tif (file == None):\n\t\t\treturn\n\n\t\tfor ffp in self.file_function_pairs:\n\t\t\tif file[-len(ffp[0]):] == ffp[0]:\n\t\t\t\tif save_or_load == 1:\n\t\t\t\t\tffp[save_or_load](self.data, file)\n\t\t\t\telse:\n\t\t\t\t\treturn ffp[save_or_load](self, file)\n\n\tdef save_data(self, output_file):\n\t\tself.data_function(output_file, 1)\n\t\treturn self\n\n\tdef load_data(self, input_file):\n\t\tself.data_function(input_file, 2)\n\t\treturn self\n\n\tdef get_random_point(self):\n\t\t\"\"\"Returns a random point from the dataset.\"\"\"\n\t\treturn select_random(self.data)\n\n\tdef plot(self, name=None):\n\t\t\"\"\"Plots the dataset.\"\"\"\n\t\tPlotter().plotPoints(self.data, name)\n\n\tdef getNumpy(self):\n\t\tif isinstance(self.data, np.ndarray):\n\t\t\t# print(self.data.shape)\n\t\t\treturn self.data\n\t\telse:\n\t\t\ttemp = []\n\t\t\tfor x in self.data:\n\t\t\t\ttemp.append(np.array(x))\n\n\t\t\t# print(np.array(temp).shape)\n\t\t\treturn np.array(temp)\n</code></pre>"},{"location":"reference/#code.create_data.Data.data_function","title":"<code>data_function(file, save_or_load)</code>","text":"<p>Used for saving and loading the dataset</p> Source code in <code>code\\create_data.py</code> <pre><code>def data_function(self, file, save_or_load):\n\t\"\"\"Used for saving and loading the dataset\"\"\"\n\tif (file == None):\n\t\treturn\n\n\tfor ffp in self.file_function_pairs:\n\t\tif file[-len(ffp[0]):] == ffp[0]:\n\t\t\tif save_or_load == 1:\n\t\t\t\tffp[save_or_load](self.data, file)\n\t\t\telse:\n\t\t\t\treturn ffp[save_or_load](self, file)\n</code></pre>"},{"location":"reference/#code.create_data.Data.getSubSet","title":"<code>getSubSet(indexList)</code>","text":"<p>Returns a subset of the data given a list of indices.</p> Source code in <code>code\\create_data.py</code> <pre><code>def getSubSet(self, indexList):\n\t\"\"\"Returns a subset of the data given a list of indices.\"\"\"\n\tsubset = []\n\tfor index in indexList:\n\t\tsubset.append(self.data[index])\n\treturn Data(subset)\n</code></pre>"},{"location":"reference/#code.create_data.Data.get_random_point","title":"<code>get_random_point()</code>","text":"<p>Returns a random point from the dataset.</p> Source code in <code>code\\create_data.py</code> <pre><code>def get_random_point(self):\n\t\"\"\"Returns a random point from the dataset.\"\"\"\n\treturn select_random(self.data)\n</code></pre>"},{"location":"reference/#code.create_data.Data.plot","title":"<code>plot(name=None)</code>","text":"<p>Plots the dataset.</p> Source code in <code>code\\create_data.py</code> <pre><code>def plot(self, name=None):\n\t\"\"\"Plots the dataset.\"\"\"\n\tPlotter().plotPoints(self.data, name)\n</code></pre>"},{"location":"reference/#code.create_data.Data.stream_data_json","title":"<code>stream_data_json(input_file)</code>","text":"<p>Stream the dataset if its saved in a json file</p> Source code in <code>code\\create_data.py</code> <pre><code>def stream_data_json(self, input_file):\n\t\"\"\"Stream the dataset if its saved in a json file\"\"\"\n\twith open(input_file, 'rb') as f:\n\t\tf.seek(0, 2)\n\t\tposition = f.tell()\n\n\t\tvalue = \"\"\n\t\tread = False\n\t\twhile position &gt; 0:\n\t\t\tposition -= 1\n\t\t\tf.seek(position)\n\t\t\tbyte = f.read(1)\n\n\t\t\tif byte == b' ':\n\t\t\t\t# print(value)\n\t\t\t\tyield int(value)\n\t\t\t\tbreak\n\n\t\t\tif (read):\n\t\t\t\tvalue = byte.decode() + value\n\n\t\t\tif byte == b'}':\n\t\t\t\tread = True\n\n\twith open(input_file, 'r') as f:\n\t\tf.readline()\n\n\t\tfor line in f:\n\t\t\tif (\"length\" in line):\n\t\t\t\tbreak\n\n\t\t\tdata = json.loads(line.strip().split(']')[0] + ']')\n\t\t\tyield np.array(data)\n</code></pre>"},{"location":"reference/#code.create_data.DataCreator","title":"<code>DataCreator</code>","text":"<p>A utility class to create various synthetic datasets for testing and analysis. Interfaces with FileGenerator to optionally stream data to file.</p> <p>Attributes:</p> Name Type Description <code>fg</code> <code>FileGenerator</code> <p>An instance of FileGenerator used for generating data points.</p> Source code in <code>code\\create_data.py</code> <pre><code>class DataCreator:\n    \"\"\"\n    A utility class to create various synthetic datasets for testing and analysis.\n    Interfaces with FileGenerator to optionally stream data to file.\n\n    Attributes:\n        fg (FileGenerator): An instance of FileGenerator used for generating data points.\n    \"\"\"\n\n    def __init__(self):\n        self.fg = FileGenerator()\n\n    def stream_dataset_creator(self, output_file: str, function: callable, seed: int, stream: bool, *args) -&gt; 'Data':\n        \"\"\"\n        Creates a dataset using the specified generator function, supporting streamed or non-streamed output.\n\n        Args:\n            output_file (str): File path to save the dataset.\n            function (callable): Generator function to create data points.\n            seed (int): Random seed for reproducibility.\n            stream (bool): If True, streams data directly to the file.\n            *args: Additional arguments passed to the generator function.\n\n        Returns:\n            Data: The created dataset, either streamed or in-memory.\n        \"\"\"\n        random.seed(seed)\n\n        if stream:\n            self.fg.setGenerator(function)\n            self.fg.stream_save(output_file, *args)\n            data = Data(output_file, stream=True)\n        else:\n            data = [point for point in function(*args)]\n            data = Data(data)\n            data.save_data(output_file)\n\n        return data\n\n    def create_dataset_line(self, output_file: str = None, start: float = 0, end: float = 1, points: int = 1000, seed: int = 42, stream: bool = False) -&gt; 'Data':\n        \"\"\"\n        Creates a 1D line dataset.\n\n        Args:\n            output_file (str): File path to save the dataset.\n            start (float): Starting point of the line.\n            end (float): Ending point of the line.\n            points (int): Number of data points.\n            seed (int): Random seed.\n            stream (bool): Whether to stream to file.\n\n        Returns:\n            Data: The generated dataset.\n        \"\"\"\n        return self.stream_dataset_creator(output_file, self.fg.line_generator, seed, stream, start, end, points)\n\n    def create_dataset_square_edge(self, output_file: str = None, p1: tuple = (0, 0), p2: tuple = (1, 1), points: int = 1000, seed: int = 42) -&gt; 'Data':\n        \"\"\"\n        Creates a dataset of points along the edges of a square.\n\n        Args:\n            output_file (str): File path to save the dataset.\n            p1 (tuple): Bottom-left corner.\n            p2 (tuple): Top-right corner.\n            points (int): Number of data points.\n            seed (int): Random seed.\n\n        Returns:\n            Data: The generated dataset.\n        \"\"\"\n        data = []\n        random.seed(seed)\n\n        x_diff = p2[0] - p1[0]\n        y_diff = p2[1] - p1[1]\n\n        for _ in range(points):\n            r = random.random() * 4\n            side = int(r)\n            var = r - side\n\n            x_side = side % 2\n            y_side = side &gt;&gt; 1\n\n            x_rev = 1 - x_side\n            y_rev = 1 - y_side\n\n            variation = np.array([var * x_side * x_diff, var * x_rev * y_diff])\n            offset = np.array([x_rev * y_side * x_diff, x_side * y_rev * y_diff])\n            shift = np.array(p1)\n\n            data.append(variation + offset + shift)\n\n        data = Data(data)\n        data.save_data(output_file)\n        return data\n\n    def create_dataset_square_fill(self, output_file: str = None, p1: tuple = (0, 0), p2: tuple = (1, 1), points: int = 1000, seed: int = 42) -&gt; 'Data':\n        \"\"\"\n        Creates a dataset of points filling a square area.\n\n        Args:\n            output_file (str): File path to save the dataset.\n            p1 (tuple): Bottom-left corner.\n            p2 (tuple): Top-right corner.\n            points (int): Number of data points.\n            seed (int): Random seed.\n\n        Returns:\n            Data: The generated dataset.\n        \"\"\"\n        data = []\n        random.seed(seed)\n\n        x_diff = p2[0] - p1[0]\n        y_diff = p2[1] - p1[1]\n\n        for _ in range(points):\n            x_rand = random.random()\n            y_rand = random.random()\n            data.append(np.array([x_diff * x_rand + p1[0], y_diff * y_rand + p1[1]]))\n\n        data = Data(data)\n        data.save_data(output_file)\n        return data\n\n    def create_dataset_eigth_sphere(self, output_file: str = None, radius: float = 1, x_pos: bool = True, y_pos: bool = True, z_pos: bool = True, points: int = 1000, seed: int = 42, stream: bool = False) -&gt; 'Data':\n        \"\"\"\n        Creates a dataset on an eighth of a sphere.\n\n        Args:\n            output_file (str): File path to save the dataset.\n            radius (float): Radius of the sphere.\n            x_pos (bool): Use positive x.\n            y_pos (bool): Use positive y.\n            z_pos (bool): Use positive z.\n            points (int): Number of data points.\n            seed (int): Random seed.\n            stream (bool): Whether to stream to file.\n\n        Returns:\n            Data: The generated dataset.\n        \"\"\"\n        return self.stream_dataset_creator(output_file, self.fg.eigth_sphere_generator, seed, stream, radius, x_pos, y_pos, z_pos, points)\n\n    def create_dataset_triangle(self, output_file: str = None, edges: list = [[0, 0], [1, 1], [2, 0]], points: int = 1000, seed: int = 42, stream: bool = False) -&gt; 'Data':\n        \"\"\"\n        Creates a dataset of points on a triangle.\n\n        Args:\n            output_file (str): File path to save the dataset.\n            edges (list): Three vertices of the triangle.\n            points (int): Number of data points.\n            seed (int): Random seed.\n            stream (bool): Whether to stream to file.\n\n        Returns:\n            Data: The generated dataset.\n        \"\"\"\n        return self.stream_dataset_creator(output_file, self.fg.triangle_generator, seed, stream, edges, points)\n\n    def create_dataset_strong_clusters(self, output_file: str = None, internal_std: float = 1, external_std: float = 10, mean: list = [0, 0], clusters: int = 10, points: int = 1000, seed: int = 42, stream: bool = False) -&gt; 'Data':\n        \"\"\"\n        Creates a clustered dataset with multiple clusters.\n\n        Args:\n            output_file (str): File path to save the dataset.\n            internal_std (float): Standard deviation inside a cluster.\n            external_std (float): Spread of cluster centers.\n            mean (list): Mean location for generating cluster centers.\n            clusters (int): Number of clusters.\n            points (int): Number of data points.\n            seed (int): Random seed.\n            stream (bool): Whether to stream to file.\n\n        Returns:\n            Data: The generated dataset.\n        \"\"\"\n        data = []\n        random.seed(seed)\n        np_mean = np.array(mean)\n\n        cluster_centers = [varied_point(np_mean, external_std) for _ in range(clusters)]\n\n        if stream:\n            self.fg.setGenerator(self.fg.strong_cluster_generator)\n            self.fg.stream_save(output_file, internal_std, cluster_centers, points)\n            data = Data(output_file, stream=True)\n        else:\n            for p in self.fg.strong_cluster_generator(internal_std, cluster_centers, points):\n                data.append(p)\n            data = Data(data)\n            data.save_data(output_file)\n\n        return data\n\n    def rotate_into_dimention(self, data: 'Data', higher_dim: int = 3, seed: int = 42) -&gt; 'Data':\n        \"\"\"\n        Rotates dataset into a higher dimensional space using random rotations.\n\n        Args:\n            data (Data): The dataset to rotate.\n            higher_dim (int): Dimension to rotate into.\n            seed (int): Random seed.\n\n        Returns:\n            Data: The rotated dataset.\n        \"\"\"\n        rotation_matrix = np.identity(higher_dim)\n        if seed != -1:\n            random.seed(seed)\n\n        for x1 in range(higher_dim - 1):\n            for x2 in range(x1 + 1, higher_dim):\n                angle = 2 * np.pi * random.random()\n                rot = np.identity(higher_dim)\n                rot[x1, x1] = np.cos(angle)\n                rot[x2, x2] = np.cos(angle)\n                rot[x1, x2] = np.sin(angle)\n                rot[x2, x1] = -np.sin(angle)\n                rotation_matrix = np.matmul(rotation_matrix, rot)\n\n        data.data = list(data.data)\n        for i in range(len(data)):\n            extended = np.zeros(higher_dim)\n            extended[:len(data[i])] = data[i]\n            data[i] = np.matmul(rotation_matrix, extended)\n\n        data.data = np.array(data.data)\n        return data\n\n    def create_dataset_spiral(self, output_file: str = None, radius: float = 1, center: list = [0, 0], rotations: int = 3, height: float = 10, points: int = 1000, seed: int = 42, stream: bool = False) -&gt; 'Data':\n        \"\"\"\n        Creates a 3D spiral dataset.\n\n        Args:\n            output_file (str): File path to save the dataset.\n            radius (float): Radius of the spiral.\n            center (list): Center offset.\n            rotations (int): Number of rotations.\n            height (float): Height of the spiral.\n            points (int): Number of data points.\n            seed (int): Random seed.\n            stream (bool): Whether to stream to file.\n\n        Returns:\n            Data: The generated dataset.\n        \"\"\"\n        return self.stream_dataset_creator(output_file, self.fg.spiral_generator, seed, stream, radius, center, rotations, height, points)\n</code></pre>"},{"location":"reference/#code.create_data.DataCreator.create_dataset_eigth_sphere","title":"<code>create_dataset_eigth_sphere(output_file=None, radius=1, x_pos=True, y_pos=True, z_pos=True, points=1000, seed=42, stream=False)</code>","text":"<p>Creates a dataset on an eighth of a sphere.</p> <p>Parameters:</p> Name Type Description Default <code>output_file</code> <code>str</code> <p>File path to save the dataset.</p> <code>None</code> <code>radius</code> <code>float</code> <p>Radius of the sphere.</p> <code>1</code> <code>x_pos</code> <code>bool</code> <p>Use positive x.</p> <code>True</code> <code>y_pos</code> <code>bool</code> <p>Use positive y.</p> <code>True</code> <code>z_pos</code> <code>bool</code> <p>Use positive z.</p> <code>True</code> <code>points</code> <code>int</code> <p>Number of data points.</p> <code>1000</code> <code>seed</code> <code>int</code> <p>Random seed.</p> <code>42</code> <code>stream</code> <code>bool</code> <p>Whether to stream to file.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>Data</code> <code>Data</code> <p>The generated dataset.</p> Source code in <code>code\\create_data.py</code> <pre><code>def create_dataset_eigth_sphere(self, output_file: str = None, radius: float = 1, x_pos: bool = True, y_pos: bool = True, z_pos: bool = True, points: int = 1000, seed: int = 42, stream: bool = False) -&gt; 'Data':\n    \"\"\"\n    Creates a dataset on an eighth of a sphere.\n\n    Args:\n        output_file (str): File path to save the dataset.\n        radius (float): Radius of the sphere.\n        x_pos (bool): Use positive x.\n        y_pos (bool): Use positive y.\n        z_pos (bool): Use positive z.\n        points (int): Number of data points.\n        seed (int): Random seed.\n        stream (bool): Whether to stream to file.\n\n    Returns:\n        Data: The generated dataset.\n    \"\"\"\n    return self.stream_dataset_creator(output_file, self.fg.eigth_sphere_generator, seed, stream, radius, x_pos, y_pos, z_pos, points)\n</code></pre>"},{"location":"reference/#code.create_data.DataCreator.create_dataset_line","title":"<code>create_dataset_line(output_file=None, start=0, end=1, points=1000, seed=42, stream=False)</code>","text":"<p>Creates a 1D line dataset.</p> <p>Parameters:</p> Name Type Description Default <code>output_file</code> <code>str</code> <p>File path to save the dataset.</p> <code>None</code> <code>start</code> <code>float</code> <p>Starting point of the line.</p> <code>0</code> <code>end</code> <code>float</code> <p>Ending point of the line.</p> <code>1</code> <code>points</code> <code>int</code> <p>Number of data points.</p> <code>1000</code> <code>seed</code> <code>int</code> <p>Random seed.</p> <code>42</code> <code>stream</code> <code>bool</code> <p>Whether to stream to file.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>Data</code> <code>Data</code> <p>The generated dataset.</p> Source code in <code>code\\create_data.py</code> <pre><code>def create_dataset_line(self, output_file: str = None, start: float = 0, end: float = 1, points: int = 1000, seed: int = 42, stream: bool = False) -&gt; 'Data':\n    \"\"\"\n    Creates a 1D line dataset.\n\n    Args:\n        output_file (str): File path to save the dataset.\n        start (float): Starting point of the line.\n        end (float): Ending point of the line.\n        points (int): Number of data points.\n        seed (int): Random seed.\n        stream (bool): Whether to stream to file.\n\n    Returns:\n        Data: The generated dataset.\n    \"\"\"\n    return self.stream_dataset_creator(output_file, self.fg.line_generator, seed, stream, start, end, points)\n</code></pre>"},{"location":"reference/#code.create_data.DataCreator.create_dataset_spiral","title":"<code>create_dataset_spiral(output_file=None, radius=1, center=[0, 0], rotations=3, height=10, points=1000, seed=42, stream=False)</code>","text":"<p>Creates a 3D spiral dataset.</p> <p>Parameters:</p> Name Type Description Default <code>output_file</code> <code>str</code> <p>File path to save the dataset.</p> <code>None</code> <code>radius</code> <code>float</code> <p>Radius of the spiral.</p> <code>1</code> <code>center</code> <code>list</code> <p>Center offset.</p> <code>[0, 0]</code> <code>rotations</code> <code>int</code> <p>Number of rotations.</p> <code>3</code> <code>height</code> <code>float</code> <p>Height of the spiral.</p> <code>10</code> <code>points</code> <code>int</code> <p>Number of data points.</p> <code>1000</code> <code>seed</code> <code>int</code> <p>Random seed.</p> <code>42</code> <code>stream</code> <code>bool</code> <p>Whether to stream to file.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>Data</code> <code>Data</code> <p>The generated dataset.</p> Source code in <code>code\\create_data.py</code> <pre><code>def create_dataset_spiral(self, output_file: str = None, radius: float = 1, center: list = [0, 0], rotations: int = 3, height: float = 10, points: int = 1000, seed: int = 42, stream: bool = False) -&gt; 'Data':\n    \"\"\"\n    Creates a 3D spiral dataset.\n\n    Args:\n        output_file (str): File path to save the dataset.\n        radius (float): Radius of the spiral.\n        center (list): Center offset.\n        rotations (int): Number of rotations.\n        height (float): Height of the spiral.\n        points (int): Number of data points.\n        seed (int): Random seed.\n        stream (bool): Whether to stream to file.\n\n    Returns:\n        Data: The generated dataset.\n    \"\"\"\n    return self.stream_dataset_creator(output_file, self.fg.spiral_generator, seed, stream, radius, center, rotations, height, points)\n</code></pre>"},{"location":"reference/#code.create_data.DataCreator.create_dataset_square_edge","title":"<code>create_dataset_square_edge(output_file=None, p1=(0, 0), p2=(1, 1), points=1000, seed=42)</code>","text":"<p>Creates a dataset of points along the edges of a square.</p> <p>Parameters:</p> Name Type Description Default <code>output_file</code> <code>str</code> <p>File path to save the dataset.</p> <code>None</code> <code>p1</code> <code>tuple</code> <p>Bottom-left corner.</p> <code>(0, 0)</code> <code>p2</code> <code>tuple</code> <p>Top-right corner.</p> <code>(1, 1)</code> <code>points</code> <code>int</code> <p>Number of data points.</p> <code>1000</code> <code>seed</code> <code>int</code> <p>Random seed.</p> <code>42</code> <p>Returns:</p> Name Type Description <code>Data</code> <code>Data</code> <p>The generated dataset.</p> Source code in <code>code\\create_data.py</code> <pre><code>def create_dataset_square_edge(self, output_file: str = None, p1: tuple = (0, 0), p2: tuple = (1, 1), points: int = 1000, seed: int = 42) -&gt; 'Data':\n    \"\"\"\n    Creates a dataset of points along the edges of a square.\n\n    Args:\n        output_file (str): File path to save the dataset.\n        p1 (tuple): Bottom-left corner.\n        p2 (tuple): Top-right corner.\n        points (int): Number of data points.\n        seed (int): Random seed.\n\n    Returns:\n        Data: The generated dataset.\n    \"\"\"\n    data = []\n    random.seed(seed)\n\n    x_diff = p2[0] - p1[0]\n    y_diff = p2[1] - p1[1]\n\n    for _ in range(points):\n        r = random.random() * 4\n        side = int(r)\n        var = r - side\n\n        x_side = side % 2\n        y_side = side &gt;&gt; 1\n\n        x_rev = 1 - x_side\n        y_rev = 1 - y_side\n\n        variation = np.array([var * x_side * x_diff, var * x_rev * y_diff])\n        offset = np.array([x_rev * y_side * x_diff, x_side * y_rev * y_diff])\n        shift = np.array(p1)\n\n        data.append(variation + offset + shift)\n\n    data = Data(data)\n    data.save_data(output_file)\n    return data\n</code></pre>"},{"location":"reference/#code.create_data.DataCreator.create_dataset_square_fill","title":"<code>create_dataset_square_fill(output_file=None, p1=(0, 0), p2=(1, 1), points=1000, seed=42)</code>","text":"<p>Creates a dataset of points filling a square area.</p> <p>Parameters:</p> Name Type Description Default <code>output_file</code> <code>str</code> <p>File path to save the dataset.</p> <code>None</code> <code>p1</code> <code>tuple</code> <p>Bottom-left corner.</p> <code>(0, 0)</code> <code>p2</code> <code>tuple</code> <p>Top-right corner.</p> <code>(1, 1)</code> <code>points</code> <code>int</code> <p>Number of data points.</p> <code>1000</code> <code>seed</code> <code>int</code> <p>Random seed.</p> <code>42</code> <p>Returns:</p> Name Type Description <code>Data</code> <code>Data</code> <p>The generated dataset.</p> Source code in <code>code\\create_data.py</code> <pre><code>def create_dataset_square_fill(self, output_file: str = None, p1: tuple = (0, 0), p2: tuple = (1, 1), points: int = 1000, seed: int = 42) -&gt; 'Data':\n    \"\"\"\n    Creates a dataset of points filling a square area.\n\n    Args:\n        output_file (str): File path to save the dataset.\n        p1 (tuple): Bottom-left corner.\n        p2 (tuple): Top-right corner.\n        points (int): Number of data points.\n        seed (int): Random seed.\n\n    Returns:\n        Data: The generated dataset.\n    \"\"\"\n    data = []\n    random.seed(seed)\n\n    x_diff = p2[0] - p1[0]\n    y_diff = p2[1] - p1[1]\n\n    for _ in range(points):\n        x_rand = random.random()\n        y_rand = random.random()\n        data.append(np.array([x_diff * x_rand + p1[0], y_diff * y_rand + p1[1]]))\n\n    data = Data(data)\n    data.save_data(output_file)\n    return data\n</code></pre>"},{"location":"reference/#code.create_data.DataCreator.create_dataset_strong_clusters","title":"<code>create_dataset_strong_clusters(output_file=None, internal_std=1, external_std=10, mean=[0, 0], clusters=10, points=1000, seed=42, stream=False)</code>","text":"<p>Creates a clustered dataset with multiple clusters.</p> <p>Parameters:</p> Name Type Description Default <code>output_file</code> <code>str</code> <p>File path to save the dataset.</p> <code>None</code> <code>internal_std</code> <code>float</code> <p>Standard deviation inside a cluster.</p> <code>1</code> <code>external_std</code> <code>float</code> <p>Spread of cluster centers.</p> <code>10</code> <code>mean</code> <code>list</code> <p>Mean location for generating cluster centers.</p> <code>[0, 0]</code> <code>clusters</code> <code>int</code> <p>Number of clusters.</p> <code>10</code> <code>points</code> <code>int</code> <p>Number of data points.</p> <code>1000</code> <code>seed</code> <code>int</code> <p>Random seed.</p> <code>42</code> <code>stream</code> <code>bool</code> <p>Whether to stream to file.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>Data</code> <code>Data</code> <p>The generated dataset.</p> Source code in <code>code\\create_data.py</code> <pre><code>def create_dataset_strong_clusters(self, output_file: str = None, internal_std: float = 1, external_std: float = 10, mean: list = [0, 0], clusters: int = 10, points: int = 1000, seed: int = 42, stream: bool = False) -&gt; 'Data':\n    \"\"\"\n    Creates a clustered dataset with multiple clusters.\n\n    Args:\n        output_file (str): File path to save the dataset.\n        internal_std (float): Standard deviation inside a cluster.\n        external_std (float): Spread of cluster centers.\n        mean (list): Mean location for generating cluster centers.\n        clusters (int): Number of clusters.\n        points (int): Number of data points.\n        seed (int): Random seed.\n        stream (bool): Whether to stream to file.\n\n    Returns:\n        Data: The generated dataset.\n    \"\"\"\n    data = []\n    random.seed(seed)\n    np_mean = np.array(mean)\n\n    cluster_centers = [varied_point(np_mean, external_std) for _ in range(clusters)]\n\n    if stream:\n        self.fg.setGenerator(self.fg.strong_cluster_generator)\n        self.fg.stream_save(output_file, internal_std, cluster_centers, points)\n        data = Data(output_file, stream=True)\n    else:\n        for p in self.fg.strong_cluster_generator(internal_std, cluster_centers, points):\n            data.append(p)\n        data = Data(data)\n        data.save_data(output_file)\n\n    return data\n</code></pre>"},{"location":"reference/#code.create_data.DataCreator.create_dataset_triangle","title":"<code>create_dataset_triangle(output_file=None, edges=[[0, 0], [1, 1], [2, 0]], points=1000, seed=42, stream=False)</code>","text":"<p>Creates a dataset of points on a triangle.</p> <p>Parameters:</p> Name Type Description Default <code>output_file</code> <code>str</code> <p>File path to save the dataset.</p> <code>None</code> <code>edges</code> <code>list</code> <p>Three vertices of the triangle.</p> <code>[[0, 0], [1, 1], [2, 0]]</code> <code>points</code> <code>int</code> <p>Number of data points.</p> <code>1000</code> <code>seed</code> <code>int</code> <p>Random seed.</p> <code>42</code> <code>stream</code> <code>bool</code> <p>Whether to stream to file.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>Data</code> <code>Data</code> <p>The generated dataset.</p> Source code in <code>code\\create_data.py</code> <pre><code>def create_dataset_triangle(self, output_file: str = None, edges: list = [[0, 0], [1, 1], [2, 0]], points: int = 1000, seed: int = 42, stream: bool = False) -&gt; 'Data':\n    \"\"\"\n    Creates a dataset of points on a triangle.\n\n    Args:\n        output_file (str): File path to save the dataset.\n        edges (list): Three vertices of the triangle.\n        points (int): Number of data points.\n        seed (int): Random seed.\n        stream (bool): Whether to stream to file.\n\n    Returns:\n        Data: The generated dataset.\n    \"\"\"\n    return self.stream_dataset_creator(output_file, self.fg.triangle_generator, seed, stream, edges, points)\n</code></pre>"},{"location":"reference/#code.create_data.DataCreator.rotate_into_dimention","title":"<code>rotate_into_dimention(data, higher_dim=3, seed=42)</code>","text":"<p>Rotates dataset into a higher dimensional space using random rotations.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Data</code> <p>The dataset to rotate.</p> required <code>higher_dim</code> <code>int</code> <p>Dimension to rotate into.</p> <code>3</code> <code>seed</code> <code>int</code> <p>Random seed.</p> <code>42</code> <p>Returns:</p> Name Type Description <code>Data</code> <code>Data</code> <p>The rotated dataset.</p> Source code in <code>code\\create_data.py</code> <pre><code>def rotate_into_dimention(self, data: 'Data', higher_dim: int = 3, seed: int = 42) -&gt; 'Data':\n    \"\"\"\n    Rotates dataset into a higher dimensional space using random rotations.\n\n    Args:\n        data (Data): The dataset to rotate.\n        higher_dim (int): Dimension to rotate into.\n        seed (int): Random seed.\n\n    Returns:\n        Data: The rotated dataset.\n    \"\"\"\n    rotation_matrix = np.identity(higher_dim)\n    if seed != -1:\n        random.seed(seed)\n\n    for x1 in range(higher_dim - 1):\n        for x2 in range(x1 + 1, higher_dim):\n            angle = 2 * np.pi * random.random()\n            rot = np.identity(higher_dim)\n            rot[x1, x1] = np.cos(angle)\n            rot[x2, x2] = np.cos(angle)\n            rot[x1, x2] = np.sin(angle)\n            rot[x2, x1] = -np.sin(angle)\n            rotation_matrix = np.matmul(rotation_matrix, rot)\n\n    data.data = list(data.data)\n    for i in range(len(data)):\n        extended = np.zeros(higher_dim)\n        extended[:len(data[i])] = data[i]\n        data[i] = np.matmul(rotation_matrix, extended)\n\n    data.data = np.array(data.data)\n    return data\n</code></pre>"},{"location":"reference/#code.create_data.DataCreator.stream_dataset_creator","title":"<code>stream_dataset_creator(output_file, function, seed, stream, *args)</code>","text":"<p>Creates a dataset using the specified generator function, supporting streamed or non-streamed output.</p> <p>Parameters:</p> Name Type Description Default <code>output_file</code> <code>str</code> <p>File path to save the dataset.</p> required <code>function</code> <code>callable</code> <p>Generator function to create data points.</p> required <code>seed</code> <code>int</code> <p>Random seed for reproducibility.</p> required <code>stream</code> <code>bool</code> <p>If True, streams data directly to the file.</p> required <code>*args</code> <p>Additional arguments passed to the generator function.</p> <code>()</code> <p>Returns:</p> Name Type Description <code>Data</code> <code>Data</code> <p>The created dataset, either streamed or in-memory.</p> Source code in <code>code\\create_data.py</code> <pre><code>def stream_dataset_creator(self, output_file: str, function: callable, seed: int, stream: bool, *args) -&gt; 'Data':\n    \"\"\"\n    Creates a dataset using the specified generator function, supporting streamed or non-streamed output.\n\n    Args:\n        output_file (str): File path to save the dataset.\n        function (callable): Generator function to create data points.\n        seed (int): Random seed for reproducibility.\n        stream (bool): If True, streams data directly to the file.\n        *args: Additional arguments passed to the generator function.\n\n    Returns:\n        Data: The created dataset, either streamed or in-memory.\n    \"\"\"\n    random.seed(seed)\n\n    if stream:\n        self.fg.setGenerator(function)\n        self.fg.stream_save(output_file, *args)\n        data = Data(output_file, stream=True)\n    else:\n        data = [point for point in function(*args)]\n        data = Data(data)\n        data.save_data(output_file)\n\n    return data\n</code></pre>"},{"location":"reference/#code.create_data.FileGenerator","title":"<code>FileGenerator</code>","text":"<p>Generates files for saved data.</p> <p>This class is designed to assist in saving generated datasets in a streaming fashion. It provides several built-in generators to create synthetic datasets for use with <code>Data</code> and <code>DataCreator</code> classes.</p> Source code in <code>code\\create_data.py</code> <pre><code>class FileGenerator:\n    \"\"\"\n    Generates files for saved data.\n\n    This class is designed to assist in saving generated datasets in a streaming\n    fashion. It provides several built-in generators to create synthetic datasets\n    for use with `Data` and `DataCreator` classes.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"Initializes the FileGenerator.\"\"\"\n        pass\n\n    def setGenerator(self, fn):\n        \"\"\"\n        Sets the generator function to be used when saving data.\n\n        Args:\n            fn (Callable): A generator function that yields data points.\n        \"\"\"\n        self.data_generator = fn\n\n    def stream_save(self, output_file: str, *args):\n        \"\"\"\n        Saves data to a JSON file in a streaming manner.\n\n        Args:\n            output_file (str): Path to the file where data will be saved.\n            *args: Arguments to pass to the generator function.\n\n        Returns:\n            None\n        \"\"\"\n        with open(output_file, \"w\") as f:\n            f.write(\"{\\\"data\\\": [\\n\")\n            first = True\n            length = 0\n            for array in self.data_generator(*args):\n                if not first:\n                    f.write(\", \\n\")\n                json.dump(list(array), f)\n                length += 1\n                first = False\n            f.write(\"], \\n\\\"length\\\": \" + str(length) + \"}\")\n\n    def linear_generator(self, data: np.ndarray):\n        \"\"\"\n        Yields data points one by one from a NumPy array.\n\n        Args:\n            data (np.ndarray): Input data.\n\n        Yields:\n            np.ndarray: Single data points from the array.\n        \"\"\"\n        for d in data.tolist():\n            yield d\n\n    def line_generator(self, start: float, end: float, points: int):\n        \"\"\"\n        Generates points along a line in 1D space.\n\n        Args:\n            start (float): Starting point of the line.\n            end (float): Ending point of the line.\n            points (int): Number of points to generate.\n\n        Yields:\n            np.ndarray: Single-point arrays sampled along the line.\n        \"\"\"\n        for _ in range(points):\n            yield np.array([random.random() * (end - start) + start])\n\n    def eigth_sphere_generator(self, radius: float, x_pos: int, y_pos: int, z_pos: int, points: int):\n        \"\"\"\n        Generates points on an eighth of a sphere surface.\n\n        Args:\n            radius (float): Radius of the sphere.\n            x_pos (int): Hemisphere direction for X (0 or 1).\n            y_pos (int): Hemisphere direction for Y (0 or 1).\n            z_pos (int): Hemisphere direction for Z (0 or 1).\n            points (int): Number of points to generate.\n\n        Yields:\n            np.ndarray: Points on the eighth sphere surface.\n        \"\"\"\n        for _ in range(points):\n            z = random.random()\n            angleXY = np.pi * random.random() / 2\n            yield np.array([\n                radius * np.sqrt(1 - z**2) * np.cos(angleXY) * (2 * x_pos - 1),\n                radius * np.sqrt(1 - z**2) * np.sin(angleXY) * (2 * y_pos - 1),\n                radius * z * (2 * z_pos - 1)\n            ])\n\n    def triangle_generator(self, edges: list, points: int):\n        \"\"\"\n        Generates points uniformly within a triangle defined by three vertices.\n\n        Args:\n            edges (list): A list of three points (each a list or np.ndarray) defining the triangle.\n            points (int): Number of points to generate.\n\n        Yields:\n            np.ndarray: Points uniformly sampled inside the triangle.\n        \"\"\"\n        base = np.array(edges[0])\n        edgeDiff1 = np.array(edges[1]) - base\n        edgeDiff2 = np.array(edges[2]) - base\n        for _ in range(points):\n            d1 = random.random()\n            d2 = random.random()\n            if d1 + d2 &gt; 1:\n                d1 = 1 - d1\n                d2 = 1 - d2\n            yield base + d1 * edgeDiff1 + d2 * edgeDiff2\n\n    def strong_cluster_generator(self, internal_std: float, cluster_centers: list, points: int):\n        \"\"\"\n        Generates clustered points around multiple centers with specified standard deviation.\n\n        Args:\n            internal_std (float): Standard deviation within each cluster.\n            cluster_centers (list): A list of cluster center points.\n            points (int): Number of points to generate.\n\n        Yields:\n            np.ndarray: Points sampled from the clusters.\n        \"\"\"\n        c = -1\n        for p in range(points):\n            if (p / points &gt;= c / 100):\n                c += 1\n            yield varied_point(select_random(cluster_centers), internal_std)\n\n    def spiral_generator(self, radius: float, center: list, rotations: int, height: float, points: int):\n        \"\"\"\n        Generates points forming a 3D spiral (helix).\n\n        Args:\n            radius (float): Radius of the spiral.\n            center (list): Center offset of the spiral (not used directly in current implementation).\n            rotations (int): Number of full 360\u00b0 turns.\n            height (float): Total height of the spiral.\n            points (int): Number of points to generate.\n\n        Yields:\n            np.ndarray: Points along the spiral.\n        \"\"\"\n        line = 2 * np.pi * rotations\n        heightPerRadian = height / line\n        for _ in range(points):\n            d = random.random() * line\n            yield np.array([\n                radius * np.cos(d),\n                radius * np.sin(d),\n                heightPerRadian * d\n            ])\n</code></pre>"},{"location":"reference/#code.create_data.FileGenerator.__init__","title":"<code>__init__()</code>","text":"<p>Initializes the FileGenerator.</p> Source code in <code>code\\create_data.py</code> <pre><code>def __init__(self):\n    \"\"\"Initializes the FileGenerator.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/#code.create_data.FileGenerator.eigth_sphere_generator","title":"<code>eigth_sphere_generator(radius, x_pos, y_pos, z_pos, points)</code>","text":"<p>Generates points on an eighth of a sphere surface.</p> <p>Parameters:</p> Name Type Description Default <code>radius</code> <code>float</code> <p>Radius of the sphere.</p> required <code>x_pos</code> <code>int</code> <p>Hemisphere direction for X (0 or 1).</p> required <code>y_pos</code> <code>int</code> <p>Hemisphere direction for Y (0 or 1).</p> required <code>z_pos</code> <code>int</code> <p>Hemisphere direction for Z (0 or 1).</p> required <code>points</code> <code>int</code> <p>Number of points to generate.</p> required <p>Yields:</p> Type Description <p>np.ndarray: Points on the eighth sphere surface.</p> Source code in <code>code\\create_data.py</code> <pre><code>def eigth_sphere_generator(self, radius: float, x_pos: int, y_pos: int, z_pos: int, points: int):\n    \"\"\"\n    Generates points on an eighth of a sphere surface.\n\n    Args:\n        radius (float): Radius of the sphere.\n        x_pos (int): Hemisphere direction for X (0 or 1).\n        y_pos (int): Hemisphere direction for Y (0 or 1).\n        z_pos (int): Hemisphere direction for Z (0 or 1).\n        points (int): Number of points to generate.\n\n    Yields:\n        np.ndarray: Points on the eighth sphere surface.\n    \"\"\"\n    for _ in range(points):\n        z = random.random()\n        angleXY = np.pi * random.random() / 2\n        yield np.array([\n            radius * np.sqrt(1 - z**2) * np.cos(angleXY) * (2 * x_pos - 1),\n            radius * np.sqrt(1 - z**2) * np.sin(angleXY) * (2 * y_pos - 1),\n            radius * z * (2 * z_pos - 1)\n        ])\n</code></pre>"},{"location":"reference/#code.create_data.FileGenerator.line_generator","title":"<code>line_generator(start, end, points)</code>","text":"<p>Generates points along a line in 1D space.</p> <p>Parameters:</p> Name Type Description Default <code>start</code> <code>float</code> <p>Starting point of the line.</p> required <code>end</code> <code>float</code> <p>Ending point of the line.</p> required <code>points</code> <code>int</code> <p>Number of points to generate.</p> required <p>Yields:</p> Type Description <p>np.ndarray: Single-point arrays sampled along the line.</p> Source code in <code>code\\create_data.py</code> <pre><code>def line_generator(self, start: float, end: float, points: int):\n    \"\"\"\n    Generates points along a line in 1D space.\n\n    Args:\n        start (float): Starting point of the line.\n        end (float): Ending point of the line.\n        points (int): Number of points to generate.\n\n    Yields:\n        np.ndarray: Single-point arrays sampled along the line.\n    \"\"\"\n    for _ in range(points):\n        yield np.array([random.random() * (end - start) + start])\n</code></pre>"},{"location":"reference/#code.create_data.FileGenerator.linear_generator","title":"<code>linear_generator(data)</code>","text":"<p>Yields data points one by one from a NumPy array.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input data.</p> required <p>Yields:</p> Type Description <p>np.ndarray: Single data points from the array.</p> Source code in <code>code\\create_data.py</code> <pre><code>def linear_generator(self, data: np.ndarray):\n    \"\"\"\n    Yields data points one by one from a NumPy array.\n\n    Args:\n        data (np.ndarray): Input data.\n\n    Yields:\n        np.ndarray: Single data points from the array.\n    \"\"\"\n    for d in data.tolist():\n        yield d\n</code></pre>"},{"location":"reference/#code.create_data.FileGenerator.setGenerator","title":"<code>setGenerator(fn)</code>","text":"<p>Sets the generator function to be used when saving data.</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>Callable</code> <p>A generator function that yields data points.</p> required Source code in <code>code\\create_data.py</code> <pre><code>def setGenerator(self, fn):\n    \"\"\"\n    Sets the generator function to be used when saving data.\n\n    Args:\n        fn (Callable): A generator function that yields data points.\n    \"\"\"\n    self.data_generator = fn\n</code></pre>"},{"location":"reference/#code.create_data.FileGenerator.spiral_generator","title":"<code>spiral_generator(radius, center, rotations, height, points)</code>","text":"<p>Generates points forming a 3D spiral (helix).</p> <p>Parameters:</p> Name Type Description Default <code>radius</code> <code>float</code> <p>Radius of the spiral.</p> required <code>center</code> <code>list</code> <p>Center offset of the spiral (not used directly in current implementation).</p> required <code>rotations</code> <code>int</code> <p>Number of full 360\u00b0 turns.</p> required <code>height</code> <code>float</code> <p>Total height of the spiral.</p> required <code>points</code> <code>int</code> <p>Number of points to generate.</p> required <p>Yields:</p> Type Description <p>np.ndarray: Points along the spiral.</p> Source code in <code>code\\create_data.py</code> <pre><code>def spiral_generator(self, radius: float, center: list, rotations: int, height: float, points: int):\n    \"\"\"\n    Generates points forming a 3D spiral (helix).\n\n    Args:\n        radius (float): Radius of the spiral.\n        center (list): Center offset of the spiral (not used directly in current implementation).\n        rotations (int): Number of full 360\u00b0 turns.\n        height (float): Total height of the spiral.\n        points (int): Number of points to generate.\n\n    Yields:\n        np.ndarray: Points along the spiral.\n    \"\"\"\n    line = 2 * np.pi * rotations\n    heightPerRadian = height / line\n    for _ in range(points):\n        d = random.random() * line\n        yield np.array([\n            radius * np.cos(d),\n            radius * np.sin(d),\n            heightPerRadian * d\n        ])\n</code></pre>"},{"location":"reference/#code.create_data.FileGenerator.stream_save","title":"<code>stream_save(output_file, *args)</code>","text":"<p>Saves data to a JSON file in a streaming manner.</p> <p>Parameters:</p> Name Type Description Default <code>output_file</code> <code>str</code> <p>Path to the file where data will be saved.</p> required <code>*args</code> <p>Arguments to pass to the generator function.</p> <code>()</code> <p>Returns:</p> Type Description <p>None</p> Source code in <code>code\\create_data.py</code> <pre><code>def stream_save(self, output_file: str, *args):\n    \"\"\"\n    Saves data to a JSON file in a streaming manner.\n\n    Args:\n        output_file (str): Path to the file where data will be saved.\n        *args: Arguments to pass to the generator function.\n\n    Returns:\n        None\n    \"\"\"\n    with open(output_file, \"w\") as f:\n        f.write(\"{\\\"data\\\": [\\n\")\n        first = True\n        length = 0\n        for array in self.data_generator(*args):\n            if not first:\n                f.write(\", \\n\")\n            json.dump(list(array), f)\n            length += 1\n            first = False\n        f.write(\"], \\n\\\"length\\\": \" + str(length) + \"}\")\n</code></pre>"},{"location":"reference/#code.create_data.FileGenerator.strong_cluster_generator","title":"<code>strong_cluster_generator(internal_std, cluster_centers, points)</code>","text":"<p>Generates clustered points around multiple centers with specified standard deviation.</p> <p>Parameters:</p> Name Type Description Default <code>internal_std</code> <code>float</code> <p>Standard deviation within each cluster.</p> required <code>cluster_centers</code> <code>list</code> <p>A list of cluster center points.</p> required <code>points</code> <code>int</code> <p>Number of points to generate.</p> required <p>Yields:</p> Type Description <p>np.ndarray: Points sampled from the clusters.</p> Source code in <code>code\\create_data.py</code> <pre><code>def strong_cluster_generator(self, internal_std: float, cluster_centers: list, points: int):\n    \"\"\"\n    Generates clustered points around multiple centers with specified standard deviation.\n\n    Args:\n        internal_std (float): Standard deviation within each cluster.\n        cluster_centers (list): A list of cluster center points.\n        points (int): Number of points to generate.\n\n    Yields:\n        np.ndarray: Points sampled from the clusters.\n    \"\"\"\n    c = -1\n    for p in range(points):\n        if (p / points &gt;= c / 100):\n            c += 1\n        yield varied_point(select_random(cluster_centers), internal_std)\n</code></pre>"},{"location":"reference/#code.create_data.FileGenerator.triangle_generator","title":"<code>triangle_generator(edges, points)</code>","text":"<p>Generates points uniformly within a triangle defined by three vertices.</p> <p>Parameters:</p> Name Type Description Default <code>edges</code> <code>list</code> <p>A list of three points (each a list or np.ndarray) defining the triangle.</p> required <code>points</code> <code>int</code> <p>Number of points to generate.</p> required <p>Yields:</p> Type Description <p>np.ndarray: Points uniformly sampled inside the triangle.</p> Source code in <code>code\\create_data.py</code> <pre><code>def triangle_generator(self, edges: list, points: int):\n    \"\"\"\n    Generates points uniformly within a triangle defined by three vertices.\n\n    Args:\n        edges (list): A list of three points (each a list or np.ndarray) defining the triangle.\n        points (int): Number of points to generate.\n\n    Yields:\n        np.ndarray: Points uniformly sampled inside the triangle.\n    \"\"\"\n    base = np.array(edges[0])\n    edgeDiff1 = np.array(edges[1]) - base\n    edgeDiff2 = np.array(edges[2]) - base\n    for _ in range(points):\n        d1 = random.random()\n        d2 = random.random()\n        if d1 + d2 &gt; 1:\n            d1 = 1 - d1\n            d2 = 1 - d2\n        yield base + d1 * edgeDiff1 + d2 * edgeDiff2\n</code></pre>"},{"location":"reference/#code.create_data.Plotter","title":"<code>Plotter</code>","text":"<p>Graphs the data into different formats.</p> Source code in <code>code\\create_data.py</code> <pre><code>class Plotter:\n\t\"\"\"\n\tGraphs the data into different formats.\n\t\"\"\"\n\n\tdef pointFormatting(self, points: list[np.ndarray]) -&gt; tuple[list[float], list[float], Optional[list[float]]]:\n\t\t\"\"\"\n\t\tFormats points into separate coordinate lists for plotting.\n\n\t\tArgs:\n\t\t\tpoints (list[np.ndarray]): A list of points as NumPy arrays.\n\n\t\tReturns:\n\t\t\ttuple: x, y, and optionally z coordinate lists.\n\t\t\"\"\"\n\t\tsize = len(points[0])\n\t\tx_coords = [point[0] for point in points]\n\t\tz_coords = None\n\t\tif size &gt; 1:\n\t\t\ty_coords = [point[1] for point in points]\n\t\t\tif size &gt; 2:\n\t\t\t\tz_coords = [point[2] for point in points]\n\t\telse:\n\t\t\ty_coords = [0 for point in points]\n\t\treturn (x_coords, y_coords, z_coords)\n\n\tdef plotPoints(self, points: list[np.ndarray], name: Optional[str] = None) -&gt; None:\n\t\t\"\"\"\n\t\tPlots a single set of points in 2D or 3D.\n\n\t\tArgs:\n\t\t\tpoints (list[np.ndarray]): A list of points to plot.\n\t\t\tname (Optional[str]): Optional filename to save the plot.\n\t\t\"\"\"\n\t\tself.plotPointSets([points], name)\n\n\tdef plotPointSets(self, sets: list[list[np.ndarray]], name: Optional[str] = None) -&gt; None:\n\t\t\"\"\"\n\t\tPlots multiple sets of points in different colors.\n\n\t\tArgs:\n\t\t\tsets (list[list[np.ndarray]]): A list of point sets.\n\t\t\tname (Optional[str]): Optional filename to save the plot.\n\t\t\"\"\"\n\t\tmarkers = ['o', 'v', '*']\n\t\tcolor = ['r', 'g', 'b']\n\t\tsize = len(sets[0][0])\n\t\tfig = plt.figure()\n\t\tif size == 3:\n\t\t\tax = fig.add_subplot(111, projection='3d')\n\t\telse:\n\t\t\tax = fig.add_subplot(111)\n\t\tfor i, points in enumerate(sets):\n\t\t\t(x_coords, y_coords, z_coords) = self.pointFormatting(points)\n\t\t\tif size == 3:\n\t\t\t\tax.scatter(x_coords, y_coords, z_coords, c=color[i], marker=markers[i], label='Points')\n\t\t\telse:\n\t\t\t\tax.scatter(x_coords, y_coords, c=color[i], marker=markers[i], label='Points')\n\t\tax.legend()\n\t\tif name:\n\t\t\tplt.savefig(name)\n\t\tplt.show()\n\n\tdef voltage_plot(\n\t\tself,\n\t\tsolver,\n\t\tcolor: str = 'r',\n\t\tax = None,\n\t\tshow: bool = True,\n\t\tlabel: str = \"\",\n\t\tcolored: bool = False,\n\t\tname: Optional[str] = None\n\t):\n\t\t\"\"\"\n\t\tPlots voltage data overlaid on input data using optional PCA projection.\n\n\t\tArgs:\n\t\t\tsolver: A voltage solver instance with `.problem.data` and `.voltages`.\n\t\t\tcolor (str): Color for the points if `colored` is False.\n\t\t\tax: Matplotlib axis to plot on (if provided).\n\t\t\tshow (bool): Whether to show the plot.\n\t\t\tlabel (str): Label for the legend.\n\t\t\tcolored (bool): Whether to color the points by voltage values.\n\t\t\tname (Optional[str]): Optional filename to save the plot.\n\n\t\tReturns:\n\t\t\tThe axis with the plotted data.\n\t\t\"\"\"\n\t\tdim = len(solver.problem.data[0])\n\n\t\tif ax is None:\n\t\t\tfig = plt.figure()\n\t\t\tif (dim + (not colored)) == 3:\n\t\t\t\tax = fig.add_subplot(111, projection=\"3d\")\n\t\t\telse:\n\t\t\t\tax = fig.add_subplot(111)\n\n\t\tif dim &gt; 3:\n\t\t\tpca = PCA(n_components=2)\n\t\t\tpoints_2d = pca.fit_transform(solver.problem.data)\n\t\t\tx_coords, y_coords, z_coords = points_2d[:, 0], points_2d[:, 1], None\n\t\t\tdim = 2\n\t\telse:\n\t\t\tx_coords, y_coords, z_coords = self.pointFormatting(solver.problem.data)\n\n\t\tcmap = None\n\t\tc = color\n\t\targs = [x_coords, y_coords, z_coords][:dim]\n\t\targs.append(solver.voltages)\n\n\t\tif colored:\n\t\t\tcmap = 'viridis'\n\t\t\tc = solver.voltages\n\t\t\targs = args[:-1]\n\n\t\tax.scatter(*args, c=c, cmap=cmap, marker='o', label=label)\n\n\t\tif name:\n\t\t\tplt.savefig(name)\n\t\tif show:\n\t\t\tplt.show()\n\n\t\treturn ax\n</code></pre>"},{"location":"reference/#code.create_data.Plotter.plotPointSets","title":"<code>plotPointSets(sets, name=None)</code>","text":"<p>Plots multiple sets of points in different colors.</p> <p>Parameters:</p> Name Type Description Default <code>sets</code> <code>list[list[ndarray]]</code> <p>A list of point sets.</p> required <code>name</code> <code>Optional[str]</code> <p>Optional filename to save the plot.</p> <code>None</code> Source code in <code>code\\create_data.py</code> <pre><code>def plotPointSets(self, sets: list[list[np.ndarray]], name: Optional[str] = None) -&gt; None:\n\t\"\"\"\n\tPlots multiple sets of points in different colors.\n\n\tArgs:\n\t\tsets (list[list[np.ndarray]]): A list of point sets.\n\t\tname (Optional[str]): Optional filename to save the plot.\n\t\"\"\"\n\tmarkers = ['o', 'v', '*']\n\tcolor = ['r', 'g', 'b']\n\tsize = len(sets[0][0])\n\tfig = plt.figure()\n\tif size == 3:\n\t\tax = fig.add_subplot(111, projection='3d')\n\telse:\n\t\tax = fig.add_subplot(111)\n\tfor i, points in enumerate(sets):\n\t\t(x_coords, y_coords, z_coords) = self.pointFormatting(points)\n\t\tif size == 3:\n\t\t\tax.scatter(x_coords, y_coords, z_coords, c=color[i], marker=markers[i], label='Points')\n\t\telse:\n\t\t\tax.scatter(x_coords, y_coords, c=color[i], marker=markers[i], label='Points')\n\tax.legend()\n\tif name:\n\t\tplt.savefig(name)\n\tplt.show()\n</code></pre>"},{"location":"reference/#code.create_data.Plotter.plotPoints","title":"<code>plotPoints(points, name=None)</code>","text":"<p>Plots a single set of points in 2D or 3D.</p> <p>Parameters:</p> Name Type Description Default <code>points</code> <code>list[ndarray]</code> <p>A list of points to plot.</p> required <code>name</code> <code>Optional[str]</code> <p>Optional filename to save the plot.</p> <code>None</code> Source code in <code>code\\create_data.py</code> <pre><code>def plotPoints(self, points: list[np.ndarray], name: Optional[str] = None) -&gt; None:\n\t\"\"\"\n\tPlots a single set of points in 2D or 3D.\n\n\tArgs:\n\t\tpoints (list[np.ndarray]): A list of points to plot.\n\t\tname (Optional[str]): Optional filename to save the plot.\n\t\"\"\"\n\tself.plotPointSets([points], name)\n</code></pre>"},{"location":"reference/#code.create_data.Plotter.pointFormatting","title":"<code>pointFormatting(points)</code>","text":"<p>Formats points into separate coordinate lists for plotting.</p> <p>Parameters:</p> Name Type Description Default <code>points</code> <code>list[ndarray]</code> <p>A list of points as NumPy arrays.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple[list[float], list[float], Optional[list[float]]]</code> <p>x, y, and optionally z coordinate lists.</p> Source code in <code>code\\create_data.py</code> <pre><code>def pointFormatting(self, points: list[np.ndarray]) -&gt; tuple[list[float], list[float], Optional[list[float]]]:\n\t\"\"\"\n\tFormats points into separate coordinate lists for plotting.\n\n\tArgs:\n\t\tpoints (list[np.ndarray]): A list of points as NumPy arrays.\n\n\tReturns:\n\t\ttuple: x, y, and optionally z coordinate lists.\n\t\"\"\"\n\tsize = len(points[0])\n\tx_coords = [point[0] for point in points]\n\tz_coords = None\n\tif size &gt; 1:\n\t\ty_coords = [point[1] for point in points]\n\t\tif size &gt; 2:\n\t\t\tz_coords = [point[2] for point in points]\n\telse:\n\t\ty_coords = [0 for point in points]\n\treturn (x_coords, y_coords, z_coords)\n</code></pre>"},{"location":"reference/#code.create_data.Plotter.voltage_plot","title":"<code>voltage_plot(solver, color='r', ax=None, show=True, label='', colored=False, name=None)</code>","text":"<p>Plots voltage data overlaid on input data using optional PCA projection.</p> <p>Parameters:</p> Name Type Description Default <code>solver</code> <p>A voltage solver instance with <code>.problem.data</code> and <code>.voltages</code>.</p> required <code>color</code> <code>str</code> <p>Color for the points if <code>colored</code> is False.</p> <code>'r'</code> <code>ax</code> <p>Matplotlib axis to plot on (if provided).</p> <code>None</code> <code>show</code> <code>bool</code> <p>Whether to show the plot.</p> <code>True</code> <code>label</code> <code>str</code> <p>Label for the legend.</p> <code>''</code> <code>colored</code> <code>bool</code> <p>Whether to color the points by voltage values.</p> <code>False</code> <code>name</code> <code>Optional[str]</code> <p>Optional filename to save the plot.</p> <code>None</code> <p>Returns:</p> Type Description <p>The axis with the plotted data.</p> Source code in <code>code\\create_data.py</code> <pre><code>def voltage_plot(\n\tself,\n\tsolver,\n\tcolor: str = 'r',\n\tax = None,\n\tshow: bool = True,\n\tlabel: str = \"\",\n\tcolored: bool = False,\n\tname: Optional[str] = None\n):\n\t\"\"\"\n\tPlots voltage data overlaid on input data using optional PCA projection.\n\n\tArgs:\n\t\tsolver: A voltage solver instance with `.problem.data` and `.voltages`.\n\t\tcolor (str): Color for the points if `colored` is False.\n\t\tax: Matplotlib axis to plot on (if provided).\n\t\tshow (bool): Whether to show the plot.\n\t\tlabel (str): Label for the legend.\n\t\tcolored (bool): Whether to color the points by voltage values.\n\t\tname (Optional[str]): Optional filename to save the plot.\n\n\tReturns:\n\t\tThe axis with the plotted data.\n\t\"\"\"\n\tdim = len(solver.problem.data[0])\n\n\tif ax is None:\n\t\tfig = plt.figure()\n\t\tif (dim + (not colored)) == 3:\n\t\t\tax = fig.add_subplot(111, projection=\"3d\")\n\t\telse:\n\t\t\tax = fig.add_subplot(111)\n\n\tif dim &gt; 3:\n\t\tpca = PCA(n_components=2)\n\t\tpoints_2d = pca.fit_transform(solver.problem.data)\n\t\tx_coords, y_coords, z_coords = points_2d[:, 0], points_2d[:, 1], None\n\t\tdim = 2\n\telse:\n\t\tx_coords, y_coords, z_coords = self.pointFormatting(solver.problem.data)\n\n\tcmap = None\n\tc = color\n\targs = [x_coords, y_coords, z_coords][:dim]\n\targs.append(solver.voltages)\n\n\tif colored:\n\t\tcmap = 'viridis'\n\t\tc = solver.voltages\n\t\targs = args[:-1]\n\n\tax.scatter(*args, c=c, cmap=cmap, marker='o', label=label)\n\n\tif name:\n\t\tplt.savefig(name)\n\tif show:\n\t\tplt.show()\n\n\treturn ax\n</code></pre>"},{"location":"reference/#code.create_data.dimentional_variation","title":"<code>dimentional_variation(dimentions)</code>","text":"<p>Returns a NumPy array of random values from a standard normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>dimentions</code> <code>int</code> <p>Number of dimensions/values to return.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Array of random values sampled from the standard normal distribution.</p> Source code in <code>code\\create_data.py</code> <pre><code>def dimentional_variation(dimentions: int) -&gt; np.ndarray:\n\t\"\"\"\n\tReturns a NumPy array of random values from a standard normal distribution.\n\n\tArgs:\n\t\tdimentions (int): Number of dimensions/values to return.\n\n\tReturns:\n\t\tnp.ndarray: Array of random values sampled from the standard normal distribution.\n\t\"\"\"\n\tz_vals = []\n\tfor d in range(dimentions):\n\t\tz_vals.append(stats.norm.ppf(random.random()))\n\n\treturn np.array(z_vals)\n</code></pre>"},{"location":"reference/#code.create_data.select_random","title":"<code>select_random(array)</code>","text":"<p>Selects a random element from an array.</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>list</code> <p>The array to select from.</p> required <p>Returns:</p> Name Type Description <code>Any</code> <code>any</code> <p>A random element from the array.</p> Source code in <code>code\\create_data.py</code> <pre><code>def select_random(array: list) -&gt; any:\n\t\"\"\"\n\tSelects a random element from an array.\n\n\tArgs:\n\t\tarray (list): The array to select from.\n\n\tReturns:\n\t\tAny: A random element from the array.\n\t\"\"\"\n\treturn array[int(len(array) * random.random())]\n</code></pre>"},{"location":"reference/#code.create_data.varied_point","title":"<code>varied_point(mean, std)</code>","text":"<p>Returns a point that is randomly offset from the mean based on standard deviation.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>ndarray</code> <p>The mean location of the point.</p> required <code>std</code> <code>float</code> <p>Standard deviation to apply.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: A randomly varied point.</p> Source code in <code>code\\create_data.py</code> <pre><code>def varied_point(mean: np.ndarray, std: float) -&gt; np.ndarray:\n\t\"\"\"\n\tReturns a point that is randomly offset from the mean based on standard deviation.\n\n\tArgs:\n\t\tmean (np.ndarray): The mean location of the point.\n\t\tstd (float): Standard deviation to apply.\n\n\tReturns:\n\t\tnp.ndarray: A randomly varied point.\n\t\"\"\"\n\treturn mean + std * dimentional_variation(len(mean))\n</code></pre>"},{"location":"reference/#code.kmeans.Partitions","title":"<code>Partitions</code>","text":"<p>               Bases: <code>DistanceBased</code></p> <p>Using K-means to partition a large dataset</p> Source code in <code>code\\kmeans.py</code> <pre><code>class Partitions(DistanceBased):\n\t\"\"\"Using K-means to partition a large dataset\"\"\"\n\tdef __init__(self, data):\n\t\tself.data = data\n\t\tsuper().__init__()\n\n\tdef k_means_plus_plus(self, k):\n\t\t\"\"\"The old k-means++ algorithm before using sci-kit\"\"\"\n\n\t\t# print(self.data.data)\n\t\tself.centers = [create_data.select_random(self.data)]\n\n\t\tfor i in range(k - 1):\n\t\t\tdistances = []\n\n\t\t\tfor point in self.data:\n\t\t\t\t# print(type(point))\n\t\t\t\t# print(type(self.centers[0]))\n\n\t\t\t\t# print(point)\n\t\t\t\t# print(self.centers[0])\n\n\t\t\t\td = self.distance(point, self.centers[0])\n\t\t\t\tfor center in self.centers:\n\t\t\t\t\td = min(d, self.distance(point, center))\n\n\t\t\t\tdistances.append(d)\n\n\t\t\tdistances = np.array(distances)\n\t\t\tdistances /= np.sum(distances)\n\n\t\t\tself.centers.append(weighted_random(self.data, distances))\n\n\t\treturn self.centers\n\n\tdef k_means(self, k, seed=42, savePointAssignments=False):\n\t\t\"\"\"Runs k-means and saves the centers and point counts. With option to save pointAssignments for voronoi drawing\"\"\"\n\t\tif (seed == -1):\n\t\t\tkmeans = KMeans(n_clusters=k, init=\"k-means++\").fit(self.data)\n\t\telse:\n\t\t\tkmeans = KMeans(n_clusters=k, random_state=int(seed), init=\"k-means++\", n_init=1).fit(self.data)\n\n\t\tself.k = k\n\t\tself.centers = kmeans.cluster_centers_\n\t\tself.point_counts = np.bincount(kmeans.labels_).tolist()\n\n\t\tif savePointAssignments:\n\t\t\tself.point_assignments = [[] for i in range(k)]\n\t\t\tfor i, point in enumerate(data):\n\t\t\t\tlabel = kmeans.labels_[i]\n\n\t\t\t\t# print(point)\n\t\t\t\t# print(self.centers[label])\n\t\t\t\t# print(self.distance(point, self.centers[label]))\n\t\t\t\tself.point_assignments[label].append([point, self.distance(point, self.centers[label])])\n\n\t\t\t# self.point_assignments = [data[kmeans.labels_ == i] for i in range(k)]\t# k times less efficient\n\t\t# self.voronoi = Voronoi(self.centers)\n\n\tdef my_k_means(self, k, seed=42, savePointAssignments=False):\n\t\t\"\"\"The old k-means algorithm\"\"\"\n\n\t\tif (seed != -1):\n\t\t\trandom.seed(seed)\n\n\t\tself.centers = self.k_means_plus_plus(k)\n\n\t\tpoint_accumulator = [np.zeros(len(self.data[0])) for i in range(k)]\n\t\tpoint_counts = [0 for i in range(k)]\n\n\t\tif (savePointAssignments):\t\t\t\t\t\t\t\t\t\t\t\t\t\t# This removes the benefit of streaming\n\t\t\tself.point_assignments = [[] for i in range(k)]\n\n\t\tfor i, point in enumerate(self.data):\n\t\t\tmin_index = 0\n\t\t\tmin_dist = self.distance(point, self.centers[0])\n\n\t\t\tfor c in range(k - 1):\n\t\t\t\tdist = self.distance(point, self.centers[c + 1])\n\t\t\t\tif (min_dist &gt; dist):\n\t\t\t\t\tmin_index = c + 1\n\t\t\t\t\tmin_dist = dist\n\n\t\t\tif (savePointAssignments):\n\t\t\t\tself.point_assignments[min_index].append([point, min_dist])\n\n\t\t\tpoint_accumulator[min_index] += point\n\t\t\tpoint_counts[min_index] += 1\n\n\t\tupdated_centers = []\n\t\tself.point_counts = []\n\n\t\tfor acc, count in zip(point_accumulator, point_counts):\n\t\t\tif (count != 0):\n\t\t\t\tupdated_centers.append(acc / count)\n\t\t\t\tself.point_counts.append(count)\n\n\t\tself.centers = updated_centers\n\t\tself.voronoi = Voronoi(self.centers)\n\n\tdef getClosestPoints(self, index):\n\t\t\"\"\"\n\t\tFinds the points whose closest points are the point indicated by the index\n\n\t\tArgs:\n\t\t\tindex (int): the index of the point\n\n\t\tReturns:\n\t\t\tList[np.ndarray]: All the points whose closest point is data[index]\n\n\t\t\"\"\"\n\t\tclosest = []\n\t\tfor i, point in enumerate(self.data):\n\t\t\tmin_index = 0\n\t\t\tmin_dist = self.distance(point, self.centers[0])\n\n\t\t\tfor c in range(len(self.centers) - 1):\n\t\t\t\tdist = self.distance(point, self.centers[c + 1])\n\t\t\t\tif (min_dist &gt; dist):\n\t\t\t\t\tmin_index = c + 1\n\t\t\t\t\tmin_dist = dist\n\n\t\t\tif (min_index == index):\n\t\t\t\tclosest.append(i)\n\n\t\treturn closest\n\n\tdef plot(self, color='r', marker='o', ax=None, name=None):\n\t\t\"\"\"Plot the kmeans\"\"\"\n\t\tplot = create_data.Plotter()\n\n\t\tsize = len(self.centers[0])\n\n\t\tif (ax == None):\n\t\t\tfig = plt.figure()\n\n\t\t\tif (size == 3):\n\t\t\t\tax = fig.add_subplot(111, projection='3d')\n\t\t\telse:\n\t\t\t\tax = fig.add_subplot(111)\n\n\t\tif (size == 3):\n\t\t\t(x_coords, y_coords, z_coords) = plot.pointFormatting(self.centers)\n\t\t\tax.scatter(x_coords, y_coords, z_coords, c=color, marker=marker, label='Centers')\n\t\telse:\n\t\t\t(x_coords, y_coords, z_coords) = plot.pointFormatting(self.data)\n\t\t\tax.scatter(x_coords, y_coords, c=color, marker=marker, label='Points')\n\n\t\t\t# voronoi_plot_2d(self.voronoi, ax=ax, show_vertices=False, line_colors='blue', line_width=1, line_alpha=0.6)\n\n\t\tax.legend()\n\n\t\tif (name):\n\t\t\tplt.savefig(name)\n\n\t\tplt.show()\n</code></pre>"},{"location":"reference/#code.kmeans.Partitions.getClosestPoints","title":"<code>getClosestPoints(index)</code>","text":"<p>Finds the points whose closest points are the point indicated by the index</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>int</code> <p>the index of the point</p> required <p>Returns:</p> Type Description <p>List[np.ndarray]: All the points whose closest point is data[index]</p> Source code in <code>code\\kmeans.py</code> <pre><code>def getClosestPoints(self, index):\n\t\"\"\"\n\tFinds the points whose closest points are the point indicated by the index\n\n\tArgs:\n\t\tindex (int): the index of the point\n\n\tReturns:\n\t\tList[np.ndarray]: All the points whose closest point is data[index]\n\n\t\"\"\"\n\tclosest = []\n\tfor i, point in enumerate(self.data):\n\t\tmin_index = 0\n\t\tmin_dist = self.distance(point, self.centers[0])\n\n\t\tfor c in range(len(self.centers) - 1):\n\t\t\tdist = self.distance(point, self.centers[c + 1])\n\t\t\tif (min_dist &gt; dist):\n\t\t\t\tmin_index = c + 1\n\t\t\t\tmin_dist = dist\n\n\t\tif (min_index == index):\n\t\t\tclosest.append(i)\n\n\treturn closest\n</code></pre>"},{"location":"reference/#code.kmeans.Partitions.k_means","title":"<code>k_means(k, seed=42, savePointAssignments=False)</code>","text":"<p>Runs k-means and saves the centers and point counts. With option to save pointAssignments for voronoi drawing</p> Source code in <code>code\\kmeans.py</code> <pre><code>def k_means(self, k, seed=42, savePointAssignments=False):\n\t\"\"\"Runs k-means and saves the centers and point counts. With option to save pointAssignments for voronoi drawing\"\"\"\n\tif (seed == -1):\n\t\tkmeans = KMeans(n_clusters=k, init=\"k-means++\").fit(self.data)\n\telse:\n\t\tkmeans = KMeans(n_clusters=k, random_state=int(seed), init=\"k-means++\", n_init=1).fit(self.data)\n\n\tself.k = k\n\tself.centers = kmeans.cluster_centers_\n\tself.point_counts = np.bincount(kmeans.labels_).tolist()\n\n\tif savePointAssignments:\n\t\tself.point_assignments = [[] for i in range(k)]\n\t\tfor i, point in enumerate(data):\n\t\t\tlabel = kmeans.labels_[i]\n\n\t\t\t# print(point)\n\t\t\t# print(self.centers[label])\n\t\t\t# print(self.distance(point, self.centers[label]))\n\t\t\tself.point_assignments[label].append([point, self.distance(point, self.centers[label])])\n</code></pre>"},{"location":"reference/#code.kmeans.Partitions.k_means_plus_plus","title":"<code>k_means_plus_plus(k)</code>","text":"<p>The old k-means++ algorithm before using sci-kit</p> Source code in <code>code\\kmeans.py</code> <pre><code>def k_means_plus_plus(self, k):\n\t\"\"\"The old k-means++ algorithm before using sci-kit\"\"\"\n\n\t# print(self.data.data)\n\tself.centers = [create_data.select_random(self.data)]\n\n\tfor i in range(k - 1):\n\t\tdistances = []\n\n\t\tfor point in self.data:\n\t\t\t# print(type(point))\n\t\t\t# print(type(self.centers[0]))\n\n\t\t\t# print(point)\n\t\t\t# print(self.centers[0])\n\n\t\t\td = self.distance(point, self.centers[0])\n\t\t\tfor center in self.centers:\n\t\t\t\td = min(d, self.distance(point, center))\n\n\t\t\tdistances.append(d)\n\n\t\tdistances = np.array(distances)\n\t\tdistances /= np.sum(distances)\n\n\t\tself.centers.append(weighted_random(self.data, distances))\n\n\treturn self.centers\n</code></pre>"},{"location":"reference/#code.kmeans.Partitions.my_k_means","title":"<code>my_k_means(k, seed=42, savePointAssignments=False)</code>","text":"<p>The old k-means algorithm</p> Source code in <code>code\\kmeans.py</code> <pre><code>def my_k_means(self, k, seed=42, savePointAssignments=False):\n\t\"\"\"The old k-means algorithm\"\"\"\n\n\tif (seed != -1):\n\t\trandom.seed(seed)\n\n\tself.centers = self.k_means_plus_plus(k)\n\n\tpoint_accumulator = [np.zeros(len(self.data[0])) for i in range(k)]\n\tpoint_counts = [0 for i in range(k)]\n\n\tif (savePointAssignments):\t\t\t\t\t\t\t\t\t\t\t\t\t\t# This removes the benefit of streaming\n\t\tself.point_assignments = [[] for i in range(k)]\n\n\tfor i, point in enumerate(self.data):\n\t\tmin_index = 0\n\t\tmin_dist = self.distance(point, self.centers[0])\n\n\t\tfor c in range(k - 1):\n\t\t\tdist = self.distance(point, self.centers[c + 1])\n\t\t\tif (min_dist &gt; dist):\n\t\t\t\tmin_index = c + 1\n\t\t\t\tmin_dist = dist\n\n\t\tif (savePointAssignments):\n\t\t\tself.point_assignments[min_index].append([point, min_dist])\n\n\t\tpoint_accumulator[min_index] += point\n\t\tpoint_counts[min_index] += 1\n\n\tupdated_centers = []\n\tself.point_counts = []\n\n\tfor acc, count in zip(point_accumulator, point_counts):\n\t\tif (count != 0):\n\t\t\tupdated_centers.append(acc / count)\n\t\t\tself.point_counts.append(count)\n\n\tself.centers = updated_centers\n\tself.voronoi = Voronoi(self.centers)\n</code></pre>"},{"location":"reference/#code.kmeans.Partitions.plot","title":"<code>plot(color='r', marker='o', ax=None, name=None)</code>","text":"<p>Plot the kmeans</p> Source code in <code>code\\kmeans.py</code> <pre><code>def plot(self, color='r', marker='o', ax=None, name=None):\n\t\"\"\"Plot the kmeans\"\"\"\n\tplot = create_data.Plotter()\n\n\tsize = len(self.centers[0])\n\n\tif (ax == None):\n\t\tfig = plt.figure()\n\n\t\tif (size == 3):\n\t\t\tax = fig.add_subplot(111, projection='3d')\n\t\telse:\n\t\t\tax = fig.add_subplot(111)\n\n\tif (size == 3):\n\t\t(x_coords, y_coords, z_coords) = plot.pointFormatting(self.centers)\n\t\tax.scatter(x_coords, y_coords, z_coords, c=color, marker=marker, label='Centers')\n\telse:\n\t\t(x_coords, y_coords, z_coords) = plot.pointFormatting(self.data)\n\t\tax.scatter(x_coords, y_coords, c=color, marker=marker, label='Points')\n\n\t\t# voronoi_plot_2d(self.voronoi, ax=ax, show_vertices=False, line_colors='blue', line_width=1, line_alpha=0.6)\n\n\tax.legend()\n\n\tif (name):\n\t\tplt.savefig(name)\n\n\tplt.show()\n</code></pre>"},{"location":"reference/#code.voltage.Landmark","title":"<code>Landmark</code>","text":"<p>Represents a location in the dataset where a voltage will be applied.</p> <p>The <code>index</code> can refer either to an individual datapoint or a partition center.</p> Source code in <code>code\\voltage.py</code> <pre><code>class Landmark:\n\t\"\"\"\n\tRepresents a location in the dataset where a voltage will be applied.\n\n\tThe `index` can refer either to an individual datapoint or a partition center.\n\t\"\"\"\n\n\tdef __init__(self, index: int, voltage: float) -&gt; None:\n\t\t\"\"\"\n\t\tInitializes a Landmark.\n\n\t\tArgs:\n\t\t\tindex (int): Index of the datapoint or partition center.\n\t\t\tvoltage (float): Voltage to be applied at the specified index.\n\t\t\"\"\"\n\t\tself.index = index\n\t\tself.voltage = voltage\n\n\t@staticmethod\n\tdef createLandmarkClosestTo(\n\t\tdata: List[Any],\n\t\tpoint: Any,\n\t\tvoltage: float,\n\t\tdistanceFn: Optional[object] = None,\n\t\tignore: List[int] = []\n\t) -&gt; \"Landmark\":\n\t\t\"\"\"\n\t\tCreates a Landmark at the index of the datapoint in `data` closest to `point`.\n\n\t\tArgs:\n\t\t\tdata (List[Any]): The dataset to search over.\n\t\t\tpoint (Any): The reference point to find the closest datapoint to.\n\t\t\tvoltage (float): The voltage to assign to the resulting Landmark.\n\t\t\tdistanceFn (Optional[object]): A distance function with a `.distance(a, b)` method.\n\t\t\t\t\t\t\t\t\t\t   Defaults to `kmeans.DistanceBased()` if None.\n\t\t\tignore (List[int], optional): List of indices to skip during the search. Defaults to empty list.\n\n\t\tReturns:\n\t\t\tLandmark: A Landmark instance corresponding to the closest datapoint.\n\t\t\"\"\"\n\t\tif distanceFn is None:\n\t\t\tdistanceFn = kmeans.DistanceBased()\n\n\t\tmost_central_index = 0\n\t\tmindist = distanceFn.distance(data[0], point)\n\n\t\tfor index in range(1, len(data)):\n\t\t\tif index in ignore:\n\t\t\t\tcontinue\n\n\t\t\tdist = distanceFn.distance(data[index], point)\n\t\t\tif dist &lt; mindist:\n\t\t\t\tmost_central_index = index\n\t\t\t\tmindist = dist\n\n\t\treturn Landmark(most_central_index, voltage)\n</code></pre>"},{"location":"reference/#code.voltage.Landmark.__init__","title":"<code>__init__(index, voltage)</code>","text":"<p>Initializes a Landmark.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>int</code> <p>Index of the datapoint or partition center.</p> required <code>voltage</code> <code>float</code> <p>Voltage to be applied at the specified index.</p> required Source code in <code>code\\voltage.py</code> <pre><code>def __init__(self, index: int, voltage: float) -&gt; None:\n\t\"\"\"\n\tInitializes a Landmark.\n\n\tArgs:\n\t\tindex (int): Index of the datapoint or partition center.\n\t\tvoltage (float): Voltage to be applied at the specified index.\n\t\"\"\"\n\tself.index = index\n\tself.voltage = voltage\n</code></pre>"},{"location":"reference/#code.voltage.Landmark.createLandmarkClosestTo","title":"<code>createLandmarkClosestTo(data, point, voltage, distanceFn=None, ignore=[])</code>  <code>staticmethod</code>","text":"<p>Creates a Landmark at the index of the datapoint in <code>data</code> closest to <code>point</code>.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>List[Any]</code> <p>The dataset to search over.</p> required <code>point</code> <code>Any</code> <p>The reference point to find the closest datapoint to.</p> required <code>voltage</code> <code>float</code> <p>The voltage to assign to the resulting Landmark.</p> required <code>distanceFn</code> <code>Optional[object]</code> <p>A distance function with a <code>.distance(a, b)</code> method.                                                    Defaults to <code>kmeans.DistanceBased()</code> if None.</p> <code>None</code> <code>ignore</code> <code>List[int]</code> <p>List of indices to skip during the search. Defaults to empty list.</p> <code>[]</code> <p>Returns:</p> Name Type Description <code>Landmark</code> <code>Landmark</code> <p>A Landmark instance corresponding to the closest datapoint.</p> Source code in <code>code\\voltage.py</code> <pre><code>@staticmethod\ndef createLandmarkClosestTo(\n\tdata: List[Any],\n\tpoint: Any,\n\tvoltage: float,\n\tdistanceFn: Optional[object] = None,\n\tignore: List[int] = []\n) -&gt; \"Landmark\":\n\t\"\"\"\n\tCreates a Landmark at the index of the datapoint in `data` closest to `point`.\n\n\tArgs:\n\t\tdata (List[Any]): The dataset to search over.\n\t\tpoint (Any): The reference point to find the closest datapoint to.\n\t\tvoltage (float): The voltage to assign to the resulting Landmark.\n\t\tdistanceFn (Optional[object]): A distance function with a `.distance(a, b)` method.\n\t\t\t\t\t\t\t\t\t   Defaults to `kmeans.DistanceBased()` if None.\n\t\tignore (List[int], optional): List of indices to skip during the search. Defaults to empty list.\n\n\tReturns:\n\t\tLandmark: A Landmark instance corresponding to the closest datapoint.\n\t\"\"\"\n\tif distanceFn is None:\n\t\tdistanceFn = kmeans.DistanceBased()\n\n\tmost_central_index = 0\n\tmindist = distanceFn.distance(data[0], point)\n\n\tfor index in range(1, len(data)):\n\t\tif index in ignore:\n\t\t\tcontinue\n\n\t\tdist = distanceFn.distance(data[index], point)\n\t\tif dist &lt; mindist:\n\t\t\tmost_central_index = index\n\t\t\tmindist = dist\n\n\treturn Landmark(most_central_index, voltage)\n</code></pre>"},{"location":"reference/#code.voltage.Problem","title":"<code>Problem</code>","text":"<p>               Bases: <code>DistanceBased</code></p> <p>Represents the clustering/graph problem to be solved,  extending a distance-based kernel with landmarks and weights.</p> Source code in <code>code\\voltage.py</code> <pre><code>class Problem(kmeans.DistanceBased):\n\t\"\"\"\n\tRepresents the clustering/graph problem to be solved, \n\textending a distance-based kernel with landmarks and weights.\n\t\"\"\"\n\n\tdef __init__(self, data: Any) -&gt; None:\n\t\t\"\"\"\n\t\tInitializes the Problem instance.\n\n\t\tArgs:\n\t\t\tdata: An object containing your dataset. Must support len(data) \n\t\t\t\t  and data.getNumpy() to return an (n, d) numpy array.\n\t\t\"\"\"\n\t\tsuper().__init__()\n\t\tself.data = data\n\t\tself.landmarks = []\n\t\tn = len(data)\n\t\tself.weights = np.zeros([n, n])\n\t\tself.universalGround = False\n\n\tdef timeStart(self) -&gt; None:\n\t\t\"\"\"\n\t\tRecords the current time to measure elapsed intervals.\n\t\t\"\"\"\n\t\tself.start = time.time()\n\n\tdef timeEnd(self, replace: bool = True) -&gt; float:\n\t\t\"\"\"\n\t\tComputes the elapsed time since the last timeStart().\n\n\t\tArgs:\n\t\t\treplace (bool): If True, resets the start time to now.\n\n\t\tReturns:\n\t\t\tfloat: Seconds elapsed since last start.\n\t\t\"\"\"\n\t\tcur_time = time.time()\n\t\tdiff = cur_time - self.start\n\t\tif replace:\n\t\t\tself.start = cur_time\n\t\treturn diff\n\n\tdef setKernel(self, kernel: Callable[..., np.ndarray]) -&gt; None:\n\t\t\"\"\"\n\t\tSets the kernel function to use for weight computations.\n\n\t\tArgs:\n\t\t\tkernel (callable): A function or callable object with signature\n\t\t\t\t\t\t\t   kernel(X, Y, *params) \u2192 ndarray of shape (|X|, |Y|).\n\t\t\"\"\"\n\t\tself.kernel = kernel\n\n\tdef efficientSquareDistance(self, data: np.ndarray) -&gt; np.ndarray:\n\t\t\"\"\"\n\t\tComputes the pairwise squared Euclidean distances of the rows in `data`.\n\n\t\tUses the identity \u2016x\u2212y\u2016\u00b2 = \u2016x\u2016\u00b2 + \u2016y\u2016\u00b2 \u2212 2 x\u00b7y for efficiency.\n\n\t\tArgs:\n\t\t\tdata (ndarray): Array of shape (n, d).\n\n\t\tReturns:\n\t\t\tndarray: Matrix of shape (n, n) where entry (i, j) is squared distance.\n\t\t\"\"\"\n\t\tdata_norm2 = np.sum(data**2, axis=1)\n\t\tx_norm2 = data_norm2.reshape(-1, 1)\n\t\ty_norm2 = data_norm2.reshape(1, -1)\n\t\treturn x_norm2 + y_norm2 - 2 * data @ data.T\n\n\tdef radialkernel(self, data: np.ndarray, r: float) -&gt; np.ndarray:\n\t\t\"\"\"\n\t\tBuilds a binary (0/1) radial kernel: 1 if distance \u2264 r, else 0.\n\n\t\tArgs:\n\t\t\tdata (ndarray): Array of shape (n, d).\n\t\t\tr (float): Radius threshold.\n\n\t\tReturns:\n\t\t\tndarray: Adjacency-like matrix (n\u00d7n) of 0/1 floats.\n\t\t\"\"\"\n\t\tdist2 = self.efficientSquareDistance(data)\n\t\treturn (dist2 &lt;= r**2).astype(float)\n\n\tdef gaussiankernel(self, data: np.ndarray, std: float) -&gt; np.ndarray:\n\t\t\"\"\"\n\t\tBuilds a Gaussian (RBF) kernel matrix.\n\n\t\tArgs:\n\t\t\tdata (ndarray): Array of shape (n, d).\n\t\t\tstd (float): Standard deviation parameter for the Gaussian.\n\n\t\tReturns:\n\t\t\tndarray: Kernel matrix of shape (n, n).\n\t\t\"\"\"\n\t\tdist2 = self.efficientSquareDistance(data)\n\t\treturn np.exp(-dist2 / (2 * std**2))\n\n\tdef setWeights(self, *c: Any) -&gt; np.ndarray:\n\t\t\"\"\"\n\t\tComputes and normalizes the weight matrix on the original data.\n\n\t\tArgs:\n\t\t\t*c: Parameters to pass into the currently set kernel function.\n\n\t\tReturns:\n\t\t\tndarray: The normalized weight matrix (n\u00d7n).\n\t\t\"\"\"\n\t\tdata_np = self.data.getNumpy()\n\t\tn = len(self.data)\n\t\tself.weights[:n, :n] = self.kernel(data_np, *c)\n\t\tself.normalizeWeights()\n\t\treturn self.weights\n\n\tdef normalizeWeights(self) -&gt; None:\n\t\t\"\"\"\n\t\tNormalizes each row of the weight matrix to sum to 1.\n\n\t\tRaises:\n\t\t\tValueError: If any row sums to zero, resulting in NaNs.\n\t\t\"\"\"\n\t\tself.weights = self.weights / self.weights.sum(axis=1, keepdims=True)\n\t\tif np.isnan(self.weights).any():\n\t\t\traise ValueError(\"Array contains NaN values!\")\n\n\tdef setPartitionWeights(self, partition: Any, *c: Any) -&gt; np.ndarray:\n\t\t\"\"\"\n\t\tComputes and normalizes weights based on cluster centers and sizes.\n\n\t\tArgs:\n\t\t\tpartition: An object with attributes `centers` (list of points)\n\t\t\t\t\t   and `point_counts` (counts per center).\n\t\t\t*c: Parameters to pass into the kernel function.\n\n\t\tReturns:\n\t\t\tndarray: The normalized weight matrix for the partition block.\n\t\t\"\"\"\n\t\tcenters = np.array(partition.centers)\n\t\tcounts = np.array(partition.point_counts).reshape(-1, 1)\n\t\tK = self.kernel(centers[:, None], centers[None, :], *c)\n\t\tW = K * (counts @ counts.T)\n\t\tn = len(centers)\n\t\tself.weights[:n, :n] = W\n\t\tself.normalizeWeights()\n\t\treturn self.weights\n\n\tdef addUniversalGround(self, p_g: float = 0.01) -&gt; np.ndarray:\n\t\t\"\"\"\n\t\tAdds (or updates) a 'universal ground' node connected uniformly to all others.\n\n\t\tArgs:\n\t\t\tp_g (float): Total ground connection probability to distribute.\n\n\t\tReturns:\n\t\t\tndarray: The updated normalized weight matrix including the ground node.\n\t\t\"\"\"\n\t\tif self.universalGround:\n\t\t\tn = self.weights.shape[0] - 1\n\t\t\tfor x in range(n):\n\t\t\t\tself.weights[x, n] = p_g / n\n\t\t\t\tself.weights[n, x] = p_g / n\n\t\telse:\n\t\t\tself.universalGround = True\n\t\t\tn = self.weights.shape[0]\n\t\t\tnewW = np.zeros([n + 1, n + 1])\n\t\t\tnewW[:n, :n] = self.weights\n\t\t\tfor x in range(n):\n\t\t\t\tnewW[x, n] = p_g / n\n\t\t\t\tnewW[n, x] = p_g / n\n\t\t\tself.weights = newW\n\t\t\tself.addLandmark(Landmark(n, 0))\n\t\tself.normalizeWeights()\n\t\treturn self.weights\n\n\tdef addLandmark(self, landmark: Landmark) -&gt; None:\n\t\t\"\"\"\n\t\tAdds a single Landmark to the problem.\n\n\t\tArgs:\n\t\t\tlandmark (Landmark): The landmark instance to append.\n\t\t\"\"\"\n\t\tself.landmarks.append(landmark)\n\n\tdef addLandmarks(self, landmarks: List[Landmark]) -&gt; None:\n\t\t\"\"\"\n\t\tAdds multiple Landmark instances to the problem.\n\n\t\tArgs:\n\t\t\tlandmarks (List[Landmark]): List of landmarks to append.\n\t\t\"\"\"\n\t\tself.landmarks += landmarks\n\n\tdef addLandmarksInRange(\n\t\tself, minRange: Union[List[float], np.ndarray],\n\t\tmaxRange: Union[List[float], np.ndarray],\n\t\tvoltage: float\n\t) -&gt; List[Landmark]:\n\t\t\"\"\"\n\t\tAdds landmarks for all data points within a given coordinate range.\n\n\t\tArgs:\n\t\t\tminRange (array-like): Minimum bounds per dimension.\n\t\t\tmaxRange (array-like): Maximum bounds per dimension.\n\t\t\tvoltage (float): Voltage to apply at each new landmark.\n\n\t\tReturns:\n\t\t\tList[Landmark]: The list of newly added landmarks.\n\t\t\"\"\"\n\t\tadding = []\n\t\tdata_np = self.data.getNumpy()\n\t\tfor idx, point in enumerate(data_np):\n\t\t\tif np.all(point &gt;= minRange) and np.all(point &lt;= maxRange):\n\t\t\t\tadding.append(Landmark(idx, voltage))\n\t\tself.addLandmarks(adding)\n\t\treturn adding\n</code></pre>"},{"location":"reference/#code.voltage.Problem.__init__","title":"<code>__init__(data)</code>","text":"<p>Initializes the Problem instance.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Any</code> <p>An object containing your dataset. Must support len(data)    and data.getNumpy() to return an (n, d) numpy array.</p> required Source code in <code>code\\voltage.py</code> <pre><code>def __init__(self, data: Any) -&gt; None:\n\t\"\"\"\n\tInitializes the Problem instance.\n\n\tArgs:\n\t\tdata: An object containing your dataset. Must support len(data) \n\t\t\t  and data.getNumpy() to return an (n, d) numpy array.\n\t\"\"\"\n\tsuper().__init__()\n\tself.data = data\n\tself.landmarks = []\n\tn = len(data)\n\tself.weights = np.zeros([n, n])\n\tself.universalGround = False\n</code></pre>"},{"location":"reference/#code.voltage.Problem.addLandmark","title":"<code>addLandmark(landmark)</code>","text":"<p>Adds a single Landmark to the problem.</p> <p>Parameters:</p> Name Type Description Default <code>landmark</code> <code>Landmark</code> <p>The landmark instance to append.</p> required Source code in <code>code\\voltage.py</code> <pre><code>def addLandmark(self, landmark: Landmark) -&gt; None:\n\t\"\"\"\n\tAdds a single Landmark to the problem.\n\n\tArgs:\n\t\tlandmark (Landmark): The landmark instance to append.\n\t\"\"\"\n\tself.landmarks.append(landmark)\n</code></pre>"},{"location":"reference/#code.voltage.Problem.addLandmarks","title":"<code>addLandmarks(landmarks)</code>","text":"<p>Adds multiple Landmark instances to the problem.</p> <p>Parameters:</p> Name Type Description Default <code>landmarks</code> <code>List[Landmark]</code> <p>List of landmarks to append.</p> required Source code in <code>code\\voltage.py</code> <pre><code>def addLandmarks(self, landmarks: List[Landmark]) -&gt; None:\n\t\"\"\"\n\tAdds multiple Landmark instances to the problem.\n\n\tArgs:\n\t\tlandmarks (List[Landmark]): List of landmarks to append.\n\t\"\"\"\n\tself.landmarks += landmarks\n</code></pre>"},{"location":"reference/#code.voltage.Problem.addLandmarksInRange","title":"<code>addLandmarksInRange(minRange, maxRange, voltage)</code>","text":"<p>Adds landmarks for all data points within a given coordinate range.</p> <p>Parameters:</p> Name Type Description Default <code>minRange</code> <code>array - like</code> <p>Minimum bounds per dimension.</p> required <code>maxRange</code> <code>array - like</code> <p>Maximum bounds per dimension.</p> required <code>voltage</code> <code>float</code> <p>Voltage to apply at each new landmark.</p> required <p>Returns:</p> Type Description <code>List[Landmark]</code> <p>List[Landmark]: The list of newly added landmarks.</p> Source code in <code>code\\voltage.py</code> <pre><code>def addLandmarksInRange(\n\tself, minRange: Union[List[float], np.ndarray],\n\tmaxRange: Union[List[float], np.ndarray],\n\tvoltage: float\n) -&gt; List[Landmark]:\n\t\"\"\"\n\tAdds landmarks for all data points within a given coordinate range.\n\n\tArgs:\n\t\tminRange (array-like): Minimum bounds per dimension.\n\t\tmaxRange (array-like): Maximum bounds per dimension.\n\t\tvoltage (float): Voltage to apply at each new landmark.\n\n\tReturns:\n\t\tList[Landmark]: The list of newly added landmarks.\n\t\"\"\"\n\tadding = []\n\tdata_np = self.data.getNumpy()\n\tfor idx, point in enumerate(data_np):\n\t\tif np.all(point &gt;= minRange) and np.all(point &lt;= maxRange):\n\t\t\tadding.append(Landmark(idx, voltage))\n\tself.addLandmarks(adding)\n\treturn adding\n</code></pre>"},{"location":"reference/#code.voltage.Problem.addUniversalGround","title":"<code>addUniversalGround(p_g=0.01)</code>","text":"<p>Adds (or updates) a 'universal ground' node connected uniformly to all others.</p> <p>Parameters:</p> Name Type Description Default <code>p_g</code> <code>float</code> <p>Total ground connection probability to distribute.</p> <code>0.01</code> <p>Returns:</p> Name Type Description <code>ndarray</code> <code>ndarray</code> <p>The updated normalized weight matrix including the ground node.</p> Source code in <code>code\\voltage.py</code> <pre><code>def addUniversalGround(self, p_g: float = 0.01) -&gt; np.ndarray:\n\t\"\"\"\n\tAdds (or updates) a 'universal ground' node connected uniformly to all others.\n\n\tArgs:\n\t\tp_g (float): Total ground connection probability to distribute.\n\n\tReturns:\n\t\tndarray: The updated normalized weight matrix including the ground node.\n\t\"\"\"\n\tif self.universalGround:\n\t\tn = self.weights.shape[0] - 1\n\t\tfor x in range(n):\n\t\t\tself.weights[x, n] = p_g / n\n\t\t\tself.weights[n, x] = p_g / n\n\telse:\n\t\tself.universalGround = True\n\t\tn = self.weights.shape[0]\n\t\tnewW = np.zeros([n + 1, n + 1])\n\t\tnewW[:n, :n] = self.weights\n\t\tfor x in range(n):\n\t\t\tnewW[x, n] = p_g / n\n\t\t\tnewW[n, x] = p_g / n\n\t\tself.weights = newW\n\t\tself.addLandmark(Landmark(n, 0))\n\tself.normalizeWeights()\n\treturn self.weights\n</code></pre>"},{"location":"reference/#code.voltage.Problem.efficientSquareDistance","title":"<code>efficientSquareDistance(data)</code>","text":"<p>Computes the pairwise squared Euclidean distances of the rows in <code>data</code>.</p> <p>Uses the identity \u2016x\u2212y\u2016\u00b2 = \u2016x\u2016\u00b2 + \u2016y\u2016\u00b2 \u2212 2 x\u00b7y for efficiency.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Array of shape (n, d).</p> required <p>Returns:</p> Name Type Description <code>ndarray</code> <code>ndarray</code> <p>Matrix of shape (n, n) where entry (i, j) is squared distance.</p> Source code in <code>code\\voltage.py</code> <pre><code>def efficientSquareDistance(self, data: np.ndarray) -&gt; np.ndarray:\n\t\"\"\"\n\tComputes the pairwise squared Euclidean distances of the rows in `data`.\n\n\tUses the identity \u2016x\u2212y\u2016\u00b2 = \u2016x\u2016\u00b2 + \u2016y\u2016\u00b2 \u2212 2 x\u00b7y for efficiency.\n\n\tArgs:\n\t\tdata (ndarray): Array of shape (n, d).\n\n\tReturns:\n\t\tndarray: Matrix of shape (n, n) where entry (i, j) is squared distance.\n\t\"\"\"\n\tdata_norm2 = np.sum(data**2, axis=1)\n\tx_norm2 = data_norm2.reshape(-1, 1)\n\ty_norm2 = data_norm2.reshape(1, -1)\n\treturn x_norm2 + y_norm2 - 2 * data @ data.T\n</code></pre>"},{"location":"reference/#code.voltage.Problem.gaussiankernel","title":"<code>gaussiankernel(data, std)</code>","text":"<p>Builds a Gaussian (RBF) kernel matrix.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Array of shape (n, d).</p> required <code>std</code> <code>float</code> <p>Standard deviation parameter for the Gaussian.</p> required <p>Returns:</p> Name Type Description <code>ndarray</code> <code>ndarray</code> <p>Kernel matrix of shape (n, n).</p> Source code in <code>code\\voltage.py</code> <pre><code>def gaussiankernel(self, data: np.ndarray, std: float) -&gt; np.ndarray:\n\t\"\"\"\n\tBuilds a Gaussian (RBF) kernel matrix.\n\n\tArgs:\n\t\tdata (ndarray): Array of shape (n, d).\n\t\tstd (float): Standard deviation parameter for the Gaussian.\n\n\tReturns:\n\t\tndarray: Kernel matrix of shape (n, n).\n\t\"\"\"\n\tdist2 = self.efficientSquareDistance(data)\n\treturn np.exp(-dist2 / (2 * std**2))\n</code></pre>"},{"location":"reference/#code.voltage.Problem.normalizeWeights","title":"<code>normalizeWeights()</code>","text":"<p>Normalizes each row of the weight matrix to sum to 1.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If any row sums to zero, resulting in NaNs.</p> Source code in <code>code\\voltage.py</code> <pre><code>def normalizeWeights(self) -&gt; None:\n\t\"\"\"\n\tNormalizes each row of the weight matrix to sum to 1.\n\n\tRaises:\n\t\tValueError: If any row sums to zero, resulting in NaNs.\n\t\"\"\"\n\tself.weights = self.weights / self.weights.sum(axis=1, keepdims=True)\n\tif np.isnan(self.weights).any():\n\t\traise ValueError(\"Array contains NaN values!\")\n</code></pre>"},{"location":"reference/#code.voltage.Problem.radialkernel","title":"<code>radialkernel(data, r)</code>","text":"<p>Builds a binary (0/1) radial kernel: 1 if distance \u2264 r, else 0.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Array of shape (n, d).</p> required <code>r</code> <code>float</code> <p>Radius threshold.</p> required <p>Returns:</p> Name Type Description <code>ndarray</code> <code>ndarray</code> <p>Adjacency-like matrix (n\u00d7n) of 0/1 floats.</p> Source code in <code>code\\voltage.py</code> <pre><code>def radialkernel(self, data: np.ndarray, r: float) -&gt; np.ndarray:\n\t\"\"\"\n\tBuilds a binary (0/1) radial kernel: 1 if distance \u2264 r, else 0.\n\n\tArgs:\n\t\tdata (ndarray): Array of shape (n, d).\n\t\tr (float): Radius threshold.\n\n\tReturns:\n\t\tndarray: Adjacency-like matrix (n\u00d7n) of 0/1 floats.\n\t\"\"\"\n\tdist2 = self.efficientSquareDistance(data)\n\treturn (dist2 &lt;= r**2).astype(float)\n</code></pre>"},{"location":"reference/#code.voltage.Problem.setKernel","title":"<code>setKernel(kernel)</code>","text":"<p>Sets the kernel function to use for weight computations.</p> <p>Parameters:</p> Name Type Description Default <code>kernel</code> <code>callable</code> <p>A function or callable object with signature                            kernel(X, Y, *params) \u2192 ndarray of shape (|X|, |Y|).</p> required Source code in <code>code\\voltage.py</code> <pre><code>def setKernel(self, kernel: Callable[..., np.ndarray]) -&gt; None:\n\t\"\"\"\n\tSets the kernel function to use for weight computations.\n\n\tArgs:\n\t\tkernel (callable): A function or callable object with signature\n\t\t\t\t\t\t   kernel(X, Y, *params) \u2192 ndarray of shape (|X|, |Y|).\n\t\"\"\"\n\tself.kernel = kernel\n</code></pre>"},{"location":"reference/#code.voltage.Problem.setPartitionWeights","title":"<code>setPartitionWeights(partition, *c)</code>","text":"<p>Computes and normalizes weights based on cluster centers and sizes.</p> <p>Parameters:</p> Name Type Description Default <code>partition</code> <code>Any</code> <p>An object with attributes <code>centers</code> (list of points)            and <code>point_counts</code> (counts per center).</p> required <code>*c</code> <code>Any</code> <p>Parameters to pass into the kernel function.</p> <code>()</code> <p>Returns:</p> Name Type Description <code>ndarray</code> <code>ndarray</code> <p>The normalized weight matrix for the partition block.</p> Source code in <code>code\\voltage.py</code> <pre><code>def setPartitionWeights(self, partition: Any, *c: Any) -&gt; np.ndarray:\n\t\"\"\"\n\tComputes and normalizes weights based on cluster centers and sizes.\n\n\tArgs:\n\t\tpartition: An object with attributes `centers` (list of points)\n\t\t\t\t   and `point_counts` (counts per center).\n\t\t*c: Parameters to pass into the kernel function.\n\n\tReturns:\n\t\tndarray: The normalized weight matrix for the partition block.\n\t\"\"\"\n\tcenters = np.array(partition.centers)\n\tcounts = np.array(partition.point_counts).reshape(-1, 1)\n\tK = self.kernel(centers[:, None], centers[None, :], *c)\n\tW = K * (counts @ counts.T)\n\tn = len(centers)\n\tself.weights[:n, :n] = W\n\tself.normalizeWeights()\n\treturn self.weights\n</code></pre>"},{"location":"reference/#code.voltage.Problem.setWeights","title":"<code>setWeights(*c)</code>","text":"<p>Computes and normalizes the weight matrix on the original data.</p> <p>Parameters:</p> Name Type Description Default <code>*c</code> <code>Any</code> <p>Parameters to pass into the currently set kernel function.</p> <code>()</code> <p>Returns:</p> Name Type Description <code>ndarray</code> <code>ndarray</code> <p>The normalized weight matrix (n\u00d7n).</p> Source code in <code>code\\voltage.py</code> <pre><code>def setWeights(self, *c: Any) -&gt; np.ndarray:\n\t\"\"\"\n\tComputes and normalizes the weight matrix on the original data.\n\n\tArgs:\n\t\t*c: Parameters to pass into the currently set kernel function.\n\n\tReturns:\n\t\tndarray: The normalized weight matrix (n\u00d7n).\n\t\"\"\"\n\tdata_np = self.data.getNumpy()\n\tn = len(self.data)\n\tself.weights[:n, :n] = self.kernel(data_np, *c)\n\tself.normalizeWeights()\n\treturn self.weights\n</code></pre>"},{"location":"reference/#code.voltage.Problem.timeEnd","title":"<code>timeEnd(replace=True)</code>","text":"<p>Computes the elapsed time since the last timeStart().</p> <p>Parameters:</p> Name Type Description Default <code>replace</code> <code>bool</code> <p>If True, resets the start time to now.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>Seconds elapsed since last start.</p> Source code in <code>code\\voltage.py</code> <pre><code>def timeEnd(self, replace: bool = True) -&gt; float:\n\t\"\"\"\n\tComputes the elapsed time since the last timeStart().\n\n\tArgs:\n\t\treplace (bool): If True, resets the start time to now.\n\n\tReturns:\n\t\tfloat: Seconds elapsed since last start.\n\t\"\"\"\n\tcur_time = time.time()\n\tdiff = cur_time - self.start\n\tif replace:\n\t\tself.start = cur_time\n\treturn diff\n</code></pre>"},{"location":"reference/#code.voltage.Problem.timeStart","title":"<code>timeStart()</code>","text":"<p>Records the current time to measure elapsed intervals.</p> Source code in <code>code\\voltage.py</code> <pre><code>def timeStart(self) -&gt; None:\n\t\"\"\"\n\tRecords the current time to measure elapsed intervals.\n\t\"\"\"\n\tself.start = time.time()\n</code></pre>"},{"location":"reference/#code.voltage.Solver","title":"<code>Solver</code>","text":"<p>               Bases: <code>DistanceBased</code></p> <p>Solves a given Problem</p> Source code in <code>code\\voltage.py</code> <pre><code>class Solver(kmeans.DistanceBased):\n\t\"\"\"Solves a given Problem\"\"\"\n\tdef __init__(self, problem):\n\t\tself.problem = problem\n\t\tsuper().__init__()\n\n\tdef compute_voltages(self):\n\t\tn = self.problem.weights.shape[0]\n\n\t\tconstrained_nodes =   [l.index for l in self.problem.landmarks]\n\t\tunconstrained_nodes = [i for i in range(n) if i not in constrained_nodes]\n\n\t\tb = np.zeros(n)\n\t\tfor landmark in self.problem.landmarks:\n\t\t\tfor y in range(0, n):\n\t\t\t\tb[y] += landmark.voltage * self.problem.weights[y][landmark.index]\n\n\t\tA_unconstrained = np.identity(len(unconstrained_nodes)) - self.problem.weights[np.ix_(unconstrained_nodes, unconstrained_nodes)]\n\n\t\tb_unconstrained = b[unconstrained_nodes]\n\n\t\t# print(self.problem.weights)\n\t\t# print(A_unconstrained)\n\t\t# print(b_unconstrained)\n\n\t\tv_unconstrained = solve(A_unconstrained, b_unconstrained)\n\n\t\t# print(v_unconstrained)\n\n\t\tself.voltages = np.zeros(n)\n\n\t\tfor landmark in self.problem.landmarks:\n\t\t\tself.voltages[landmark.index] = landmark.voltage\n\n\t\tself.voltages[unconstrained_nodes] = v_unconstrained\n\n\t\tif (self.problem.universalGround):\n\t\t\tself.voltages = self.voltages[:-1]\n\n\t\treturn self.voltages\n\n\tdef approximate_voltages(self, epsilon=None, max_iters=None):\n\t\tn = self.problem.weights.shape[0]\n\n\t\tif (epsilon == None):\n\t\t\tif (max_iters == None):\n\t\t\t\tepsilon = 1 / n\n\n\t\tconstrained_nodes =\t\t[l.index for l in self.problem.landmarks]\n\t\tconstraints = \t\t\t[l.voltage for l in self.problem.landmarks]\n\t\tunconstrained_nodes =\t[i for i in range(n) if i not in constrained_nodes]\n\n\t\tself.voltages = np.zeros(n)\n\t\tvoltages = np.zeros(n)\n\n\t\tfor landmark in self.problem.landmarks:\n\t\t\tself.voltages[landmark.index] = landmark.voltage\n\n\t\tdist = self.distance(self.voltages, voltages)\n\t\tprev_dist = float('inf')\n\n\t\titerations = 0\n\n\t\twhile (((epsilon != None and dist &gt; epsilon * len(self.problem.data)) or (max_iters != None and iterations &lt; max_iters)) and dist &lt; prev_dist):\n\t\t\tvoltages = np.matmul(self.problem.weights, self.voltages)\n\t\t\tvoltages[constrained_nodes] = constraints\n\t\t\tprev_dist = dist\n\t\t\tdist = self.distance(self.voltages, voltages)\n\n\t\t\t# print(prev_dist, dist)\n\n\t\t\tself.voltages = voltages\n\t\t\titerations += 1\n\n\t\t# print(iterations)\n\n\t\tif (self.problem.universalGround):\n\t\t\tself.voltages = self.voltages[:-1]\n\n\t\treturn self.voltages\n\n\tdef localSolver(self, partitions, c):\n\t\tvoltages = [0 for i in range(len(self.problem.data))]\n\n\t\tfor index in range(partitions.k):\n\t\t\tclosestIndicies = partitions.getClosestPoints(index)\n\t\t\tcloseproblem.LandmarksIndicies = []\n\n\t\t\tfor pair in partitions.voronoi.ridge_points:\n\t\t\t\tif pair[0] == index:\n\t\t\t\t\tcloseproblem.LandmarksIndicies.append(pair[1])\n\t\t\t\tif pair[1] == index:\n\t\t\t\t\tcloseproblem.LandmarksIndicies.append(pair[0])\n\n\t\t\tcloseproblem.Landmarks = []\n\t\t\tfor cli in closeproblem.LandmarksIndicies:\n\t\t\t\tcloseproblem.Landmarks.append(Landmark(cli, self.voltages[cli]))\n\n\t\t\tlocalSolver = Solver(self.problem.data.getSubSet(closestIndicies))\n\t\t\tlocalSolver.setKernel(self.problem.gaussiankernel)\n\t\t\tlocalSolver.setWeights(c)\n\t\t\tlocalSolver.addproblem.Landmarks(closeproblem.Landmarks)\n\t\t\tlocalVoltages = localSolver.compute_voltages()\n\n\t\t\tfor i, v in zip(closestIndicies, localVoltages):\n\t\t\t\tvoltages[i] = v\n\n\t\treturn voltages\n</code></pre>"}]}